{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy, copy\n",
    "import functools\n",
    "import os\n",
    "import cProfile\n",
    "import pstats\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 18\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transfer from dBW to W (power)\n",
    "def db2pow(db: float) -> float:\n",
    "    return 10**(db/10)\n",
    "\n",
    "# Function to transfer from W to dBW (power)\n",
    "def pow2db(pow: float) -> float:\n",
    "    return 10*np.log10(pow)\n",
    "\n",
    "# Hermitian transpose of a matrix\n",
    "def HermTranspose(x: np.ndarray) -> np.ndarray:\n",
    "    return x.conj().T\n",
    "\n",
    "def chanGen(zeta: float, d: float, dim1: int, dim2: int) -> np.ndarray:\n",
    "    \"\"\"Function to generate Rayleigh fading channel coefficients\n",
    "\n",
    "    Args:\n",
    "        zeta: Î¾ is the path loss exponent\n",
    "        d: the distance between the transmitter and the receiver\n",
    "        dim1: the number of rows in the channel matrix\n",
    "        dim2: the number of columns in the channel matrix\n",
    "    \"\"\"\n",
    "    pl_ref: float = -30                                    # pathloss (dBW) at reference distance\n",
    "    pl: float = db2pow(pl_ref - 10*zeta*np.log10(d))       # pathloss model at distance d\n",
    "    y: np.ndarray = np.sqrt(0.5*pl)*(np.random.randn(dim1,dim2)\\\n",
    "        + 1j*np.random.randn(dim1,dim2))            # Rayleigh distribution\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input data & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = db2pow(-75)                                                                 # noise power\n",
    "N = 10                                                                              # number of transmit antennas\n",
    "gamma = 0.8 # Lower bound for user's link quality\n",
    "pmax = 1000  # Maximum transmit power of Alice\n",
    "\n",
    "# Channel generation\n",
    "def read_generate_channel() -> tuple:\n",
    "    filepath = './data/general/'\n",
    "    Hai = np.load(filepath + 'Hai.npy')\n",
    "    hib = np.load(filepath + 'hib.npy')\n",
    "    hab = np.load(filepath + 'hab.npy')\n",
    "    hie = np.load(filepath + 'hie.npy')\n",
    "    hae = np.load(filepath + 'hae.npy')\n",
    "    return Hai, hib, hie, hab, hae\n",
    "\n",
    "def read_fixed_eaves(num_of_users, num_of_eavesdroppers) -> tuple:\n",
    "    filepath = f'./data/fixed_eaves/data_{num_of_users}users_{num_of_eavesdroppers}eaves/'\n",
    "    Hai = np.load(filepath + 'Hai.npy')\n",
    "    hib = np.load(filepath + 'hib.npy')\n",
    "    hab = np.load(filepath + 'hab.npy')\n",
    "    hie = np.load(filepath + 'hie.npy')\n",
    "    hae = np.load(filepath + 'hae.npy')\n",
    "    return Hai, hib, hie, hab, hae\n",
    "\n",
    "def read_fixed_users(num_of_users, num_of_eavesdroppers) -> tuple:\n",
    "    filepath = f'./data/fixed_users/data_{num_of_users}users_{num_of_eavesdroppers}eaves/'\n",
    "    Hai = np.load(filepath + 'Hai.npy')\n",
    "    hib = np.load(filepath + 'hib.npy')\n",
    "    hab = np.load(filepath + 'hab.npy')\n",
    "    hie = np.load(filepath + 'hie.npy')\n",
    "    hae = np.load(filepath + 'hae.npy')\n",
    "    return Hai, hib, hie, hab, hae\n",
    "\n",
    "#Hai: Channel between Alice and RIS: Nris x N  \n",
    "#hib: Channel between RIS and users: List of length number_of_users, elements are 1 x Nris\n",
    "#hab: Channel between Alice and users: List of length number_of_users, elements are 1 x N\n",
    "#hie: Channel between RIS and eavesdroppers: List of length number_of_eavesdroppers, elements are 1 x Nris\n",
    "#hae: Channel between Alice and eavesdroppers: List of length number_of_eavesdroppers, elements are 1 x N\n",
    "\n",
    "Hai, hib, hie, hab, hae = read_generate_channel()\n",
    "\n",
    "Nris = Hai.shape[0]                                                                       \n",
    "number_of_users = len(hib)\n",
    "number_of_eavesdroppers = len(hie)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beamforming vectors and RIS functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_beamforming_vectors(w: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Function to normalise the beamforming vectors\n",
    "\n",
    "    Args:\n",
    "        w: the beamforming vectors\n",
    "    \"\"\"\n",
    "    total_norm_squared = 0\n",
    "    for i in range(number_of_users):\n",
    "        total_norm_squared += (np.linalg.norm(w[i]) ** 2)\n",
    "    if total_norm_squared <= pmax:\n",
    "        return w\n",
    "    for i in range(number_of_users):\n",
    "        w[i] = w[i] / (total_norm_squared ** 0.5) * np.sqrt(pmax)\n",
    "    return w\n",
    "\n",
    "def generate_random_beamforming_vector():\n",
    "  '''\n",
    "  Generate one random beamforming vector\n",
    "  '''\n",
    "  return np.random.uniform(-1, 1, (N, 1)) + 1j * np.random.uniform(-1, 1, (N, 1))\n",
    "\n",
    "def generate_random_beamforming_vectors():\n",
    "    # Generate random complex numbers for each element of the beamforming vector\n",
    "    beamforming_vectors = [generate_random_beamforming_vector() for _ in range (number_of_users)]\n",
    "    \n",
    "    # Normalize the vectors\n",
    "    beamforming_vectors = normalise_beamforming_vectors(beamforming_vectors)\n",
    "    return beamforming_vectors\n",
    "    #w: list of beamforming vectors, length = number of users, elements are N x 1\n",
    "\n",
    "def generate_random_theta():\n",
    "    theta = np.random.uniform(-np.pi, np.pi, (1, Nris))\n",
    "    theta = np.exp(1j * theta)\n",
    "    return theta\n",
    "    #theta: phase shift of RIS, size 1 x Nris\n",
    "\n",
    "def generate_random_theta_angles(size: int):\n",
    "  \"\"\"\n",
    "    Generate a random vector of angles from -pi to pi\n",
    "  \"\"\"\n",
    "  return np.random.uniform(-np.pi, np.pi, size=(1, size))\n",
    "\n",
    "def theta_angles_to_theta_vector(angles: np.ndarray[np.float64]) -> np.ndarray[np.complex128]:\n",
    "  \"\"\"\n",
    "    Convert a vector of angles to a vector of complex numbers on the unit circle\n",
    "  \"\"\"\n",
    "  return np.exp(1j * angles)\n",
    "\n",
    "def theta_vector_to_theta_angles(theta: np.ndarray[np.complex128]) -> np.ndarray[np.float64]:\n",
    "  \"\"\"\n",
    "    Convert a vector of complex numbers on the unit circle to a vector of angles\n",
    "  \"\"\"\n",
    "  return np.angle(theta)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secrecy_rate_objective_function(theta, w) -> float:\n",
    "    secrecy_rate: float = 0\n",
    "    for k in range(number_of_users):\n",
    "        R_bk = []\n",
    "        # Legitimate user k\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        C_bk = np.log2(1 + gamma_bk)\n",
    "        \n",
    "        for m in range(number_of_eavesdroppers):\n",
    "            # Eavesdropper i\n",
    "            Z_em = hie[m] @ np.diag(theta.flatten()) @ Hai + hae[m]\n",
    "            numGamma_em = np.abs(Z_em @ w[k])**2\n",
    "            denGamma_em = 1 + np.sum([np.abs(Z_em @ w[j])**2 for j in range(number_of_users) if j != k])\n",
    "            gamma_em = numGamma_em/denGamma_em\n",
    "            C_em = np.log2(1 + gamma_em)\n",
    "            R_bk.append(C_bk - C_em)\n",
    "        \n",
    "        secrecy_rate += max(min(R_bk),0)\n",
    "\n",
    "    # Return the only element in the matrix as it is currently a 1x1 np array\n",
    "    return secrecy_rate[0, 0]\n",
    "\n",
    "# Check if the current set up is valid (every users' C_bk >= gamma)\n",
    "# Returns the index of the invalid user whose C_bk is highest among the invalid or -1 if all users are valid\n",
    "def check_validity(theta, w) -> int:\n",
    "    user = -1\n",
    "    maxx = 0\n",
    "    for k in range(number_of_users):\n",
    "        # Legitimate user k\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        C_bk = np.log2(1 + gamma_bk)\n",
    "        \n",
    "        if (C_bk < gamma):\n",
    "            if C_bk > maxx:\n",
    "                maxx = C_bk\n",
    "                user = k\n",
    "    return user\n",
    "\n",
    "# Print the C_bk of each user\n",
    "def print_users_Cbk(theta, w) -> None:\n",
    "    for k in range(number_of_users):\n",
    "        # Legitimate user k\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        C_bk = np.log2(1 + gamma_bk)\n",
    "        print(float(C_bk), end = \" \")\n",
    "    print()\n",
    "\n",
    "# Calculate the C_bk of a user\n",
    "def calculate_user_Cbk(theta, w, user) -> float:\n",
    "    Z_bk = hib[user] @ np.diag(theta.flatten()) @ Hai + hab[user]\n",
    "    numGamma_bk = np.abs(Z_bk @ w[user])**2\n",
    "    denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != user])\n",
    "    gamma_bk = numGamma_bk/denGamma_bk\n",
    "    C_bk = np.log2(1 + gamma_bk)\n",
    "    return C_bk\n",
    "\n",
    "# Using gradient descent to repair the beamforming vector of a user\n",
    "# Try to make that user's C_bk >= gamma\n",
    "def repair_beamforming_vectors(theta, w, user, learning_rate = 0.01, max_iter = 500):\n",
    "    #print(\"Initial norm of user beamforming vector: \", np.linalg.norm(w[user]))\n",
    "    #print(\"Before update beamforming of user \", user, \": \")\n",
    "    #print_users_Cbk(theta, w)\n",
    "    while (calculate_user_Cbk(theta, w, user) < gamma + 0.2 and max_iter > 0):\n",
    "        Z_bk = hib[user] @ np.diag(theta.flatten()) @ Hai + hab[user]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[user])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != user])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        \n",
    "        num_grad_C_bk_to_w_k = 2 * (HermTranspose(Z_bk) @ Z_bk @ w[user])\n",
    "        den_grad_C_bk_to_w_k = (1 + gamma_bk) * np.log(2) * (1 + sum([abs(Z_bk @ w[j]) for j in range (number_of_users) if j != user]))\n",
    "        grad_C_bk_to_w_k = num_grad_C_bk_to_w_k / den_grad_C_bk_to_w_k\n",
    "        w[user] = w[user] + learning_rate * grad_C_bk_to_w_k\n",
    "        #w[user] *= 2\n",
    "        max_iter -= 1\n",
    "\n",
    "        w = normalise_beamforming_vectors(w)\n",
    "    #print(\"New norm of user beamforming vector: \", np.linalg.norm(w[user]))\n",
    "    #print(\"After update beamforming of user \", user, \": \")\n",
    "    #print_users_Cbk(theta, w)\n",
    "    return w\n",
    "\n",
    "# Using gradient descent to repair the whole (theta, w) set up\n",
    "def repair(theta, w, iter = 100):\n",
    "    invalid_user = check_validity(theta, w)\n",
    "    while (invalid_user != -1 and iter > 0):\n",
    "        w = repair_beamforming_vectors(theta, w, invalid_user)\n",
    "        invalid_user = check_validity(theta, w)\n",
    "        iter -= 1\n",
    "    if (invalid_user != -1):\n",
    "        theta, w = generate_random_theta(), generate_random_beamforming_vectors()\n",
    "        return repair(theta, w)\n",
    "    return theta, w\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent for Maximization (GD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_w(theta, w):\n",
    "    grad_w = []\n",
    "    Z_e_max = [] #Z_e_max[k] = Z_e_max for user k\n",
    "    gamma_e_max = [] #gamma_e_max[k] = gamma_e_max for user k\n",
    "    Z_b = [] #Z_b[k] = Z_bk\n",
    "    gamma_b = [] #gamma_b[k] = gamma_bk\n",
    "    counted = [] #counted[k] = true if gamma_k > gamma_e_max[k]\n",
    "    \n",
    "    #Precalculation \n",
    "    for k in range(number_of_users):\n",
    "        gamma_e = []\n",
    "        for m in range (number_of_eavesdroppers):\n",
    "            Z_em = hie[m] @ np.diag(theta.flatten()) @ Hai + hae[m]\n",
    "            numGamma_em = np.abs(Z_em @ w[k])**2\n",
    "            denGamma_em = 1 + np.sum([np.abs(Z_em @ w[j])**2 for j in range(number_of_users) if j != k])\n",
    "            gamma_em = numGamma_em/denGamma_em\n",
    "            gamma_e.append(gamma_em)\n",
    "        \n",
    "        gamma_e_max.append(max(gamma_e))\n",
    "        index_e_max = gamma_e.index(max(gamma_e))\n",
    "        Z_e = hie[index_e_max] @ np.diag(theta.flatten()) @ Hai + hae[index_e_max]\n",
    "        Z_e_max.append(Z_e)\n",
    "\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "\n",
    "        Z_b.append(Z_bk)\n",
    "        gamma_b.append(gamma_bk)\n",
    "\n",
    "        counted.append(gamma_bk > gamma_e[index_e_max])\n",
    "\n",
    "\n",
    "    #Calculating grad for i-th beamforming vector\n",
    "    for i in range(number_of_users):\n",
    "        grad = np.zeros((N, 1))\n",
    "        for k in range (number_of_users):\n",
    "            if (counted[k] == False):\n",
    "                continue\n",
    "            if (k == i):\n",
    "                num_grad_C_bk_to_w_k = 2 * (HermTranspose(Z_b[k]) @ Z_b[k] @ w[k])\n",
    "                den_grad_C_bk_to_w_k = (1 + gamma_b[k]) * np.log(2) * (1 + sum([abs(Z_b[k] @ w[j]) for j in range (number_of_users) if j != k]))\n",
    "                grad_C_bk_to_w_k = num_grad_C_bk_to_w_k / den_grad_C_bk_to_w_k\n",
    "\n",
    "                num_grad_C_e_max_to_w_k = 2 * (HermTranspose(Z_e_max[k]) @ Z_e_max[k] @ w[k])\n",
    "                den_grad_C_e_max_to_w_k = (1 + gamma_e_max[k]) * np.log(2) * (1 + sum([abs(Z_e_max[k] @ w[j]) for j in range (number_of_users) if j != k]))\n",
    "                grad_C_e_max_to_w_k = num_grad_C_e_max_to_w_k / den_grad_C_e_max_to_w_k\n",
    "                \n",
    "                grad = grad - (grad_C_bk_to_w_k - grad_C_e_max_to_w_k)\n",
    "            else:\n",
    "                num_grad_C_bk_to_w_i = -2 * abs(Z_b[k] @ w[k]) * (HermTranspose(Z_b[k]) @ Z_b[k] @ w[i])\n",
    "                den_grad_C_bk_to_w_i = (1 + gamma_b[k]) * np.log(2) * (1 + sum([abs(Z_b[k] @ w[j]) for j in range (number_of_users) if j != k])) ** 2\n",
    "                grad_C_bk_to_w_i = num_grad_C_bk_to_w_i / den_grad_C_bk_to_w_i\n",
    "\n",
    "                num_grad_C_e_max_to_w_i = -2 * abs(Z_e_max[k] @ w[k]) * (HermTranspose(Z_e_max[k]) @ Z_e_max[k] @ w[i])\n",
    "                den_grad_C_e_max_to_w_i = (1 + gamma_e_max[k]) * np.log(2) * (1 + sum([abs(Z_e_max[k] @ w[j]) for j in range (number_of_users) if j != k])) ** 2\n",
    "                grad_C_e_max_to_w_i = num_grad_C_e_max_to_w_i / den_grad_C_e_max_to_w_i\n",
    "\n",
    "                grad = grad - (grad_C_bk_to_w_i - grad_C_e_max_to_w_i)\n",
    "            \n",
    "        grad_w.append(grad)\n",
    "    return grad_w\n",
    "\n",
    "def compute_gradient_theta_central(theta, w, epsilon=1e-3):\n",
    "    perturbation = epsilon #+ epsilon * 1j\n",
    "    grad_theta = []\n",
    "    for i in range(Nris):\n",
    "        theta_plus = copy(theta)\n",
    "        theta_plus[0, i] += perturbation\n",
    "        theta_minus = copy(theta)\n",
    "        theta_minus[0, i] -= perturbation\n",
    "        grad_theta_i = (secrecy_rate_objective_function(theta_plus, w) - secrecy_rate_objective_function(theta_minus, w)) / (2*epsilon)\n",
    "        grad_theta.append(grad_theta_i)\n",
    "            \n",
    "    return np.array(grad_theta)\n",
    "\n",
    "def compute_gradient_theta_forward(theta, w, original_secrecy_rate=None, epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Faster implementation of the gradient calculation\n",
    "\n",
    "    Improvements:\n",
    "    - Use forward difference instead of central difference\n",
    "    \"\"\"\n",
    "    perturbation = epsilon + epsilon * 1j\n",
    "    grad_theta = []\n",
    "    for i in range(Nris):\n",
    "        theta_plus = copy(theta)\n",
    "        theta_plus[0, i] += perturbation\n",
    "        grad_theta_i = (secrecy_rate_objective_function(theta_plus, w) - original_secrecy_rate) / epsilon\n",
    "        grad_theta.append(grad_theta_i)\n",
    "\n",
    "    return np.array(grad_theta)\n",
    "\n",
    "def compute_gradient_theta(theta, w):\n",
    "    Z_e_max = [] #Z_e_max[k] = Z_e_max for user k\n",
    "    gamma_e_max = [] #gamma_e_max[k] = gamma_e_max for user k\n",
    "    Z_b = [] #Z_b[k] = Z_bk\n",
    "    gamma_b = [] #gamma_b[k] = gamma_bk\n",
    "    counted = [] #counted[k] = true if gamma_k > gamma_e_max[k]\n",
    "    index_e_max_list = []\n",
    "    #Precalculation\n",
    "    for k in range(number_of_users):\n",
    "        gamma_e = []\n",
    "        for m in range (number_of_eavesdroppers):\n",
    "            Z_em = hie[m] @ np.diag(theta.flatten()) @ Hai + hae[m]\n",
    "            numGamma_em = np.abs(Z_em @ w[k])**2\n",
    "            denGamma_em = 1 + np.sum([np.abs(Z_em @ w[j])**2 for j in range(number_of_users) if j != k])\n",
    "            gamma_em = numGamma_em/denGamma_em\n",
    "            gamma_e.append(gamma_em)\n",
    "        \n",
    "        gamma_e_max.append(max(gamma_e))\n",
    "        index_e_max = gamma_e.index(max(gamma_e))\n",
    "        index_e_max_list.append(index_e_max)\n",
    "        Z_e = hie[index_e_max] @ np.diag(theta.flatten()) @ Hai + hae[index_e_max]\n",
    "        Z_e_max.append(Z_e)\n",
    "\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "\n",
    "        Z_b.append(Z_bk)\n",
    "        gamma_b.append(gamma_bk)\n",
    "\n",
    "        counted.append(gamma_bk > gamma_e[index_e_max])\n",
    "\n",
    "\n",
    "    grad_theta = 0\n",
    "\n",
    "\n",
    "    for k in range(number_of_users):\n",
    "        if (counted[k] == False):\n",
    "            continue\n",
    "\n",
    "        grad_Z_bk_wk_to_theta = (1/sigma) * np.diag(hib[k].flatten()) @ Hai @ w[k]\n",
    "        grad_gamma_bk_to_theta_first_term = (2 * (Z_b[k] @ w[k]) * grad_Z_bk_wk_to_theta) * (1 + sum([np.linalg.norm(Z_b[k] @ w[j])**2 for j in range (number_of_users) if j != k]))\n",
    "        grad_gamma_bk_to_theta_second_term = sum([2 * (Z_b[k] @ w[j]) * grad_Z_bk_wk_to_theta for j in range(number_of_users) if j != k]) * (np.linalg.norm(Z_b[k] @ w[k]) ** 2)\n",
    "        grad_gamma_bk_to_theta_third_term = (1 + sum([np.linalg.norm(Z_b[k] @ w[j]) for j in range (number_of_users) if j != k])**2) ** 2\n",
    "        grad_gamma_bk_to_theta = (grad_gamma_bk_to_theta_first_term - grad_gamma_bk_to_theta_second_term) / grad_gamma_bk_to_theta_third_term\n",
    "\n",
    "        grad_C_bk_to_theta = 1 / ((1 + gamma_b[k]) * np.log(2)) * grad_gamma_bk_to_theta\n",
    "\n",
    "        grad_Z_emax_wk_to_theta = (1/sigma) * np.diag(hie[index_e_max_list[k]].flatten()) @ Hai @ w[k]\n",
    "\n",
    "        grad_gamma_emax_to_theta_first_term = (2 * (Z_e_max[k] @ w[k]) * grad_Z_emax_wk_to_theta) * (1 + sum([np.linalg.norm(Z_e_max[k] @ w[j])**2 for j in range (number_of_users) if j != k]))\n",
    "        grad_gamma_emax_to_theta_second_term = sum([2 * (Z_e_max[k] @ w[j]) * grad_Z_emax_wk_to_theta for j in range(number_of_users) if j != k]) * (np.linalg.norm(Z_e_max[k] @ w[k]) ** 2)\n",
    "        grad_gamma_emax_to_theta_third_term = (1 + sum([np.linalg.norm(Z_e_max[k] @ w[j]) for j in range (number_of_users) if j != k])**2) ** 2\n",
    "        grad_gamma_emax_to_theta = (grad_gamma_emax_to_theta_first_term - grad_gamma_emax_to_theta_second_term) / grad_gamma_emax_to_theta_third_term\n",
    "\n",
    "        grad_C_emax_to_theta = 1 / ((1 + gamma_e_max[k]) * np.log(2)) * grad_gamma_emax_to_theta\n",
    "\n",
    "        grad_theta -= (grad_C_bk_to_theta - grad_C_emax_to_theta)\n",
    "    \n",
    "    return np.array(grad_theta).reshape((1, Nris))\n",
    "    \n",
    "\n",
    "\n",
    "def gradient_descent_update(w, theta, learning_rate, original_secrecy_rate=None):\n",
    "    grad_w = compute_gradient_w(theta, w)\n",
    "    grad_theta = compute_gradient_theta(theta, w)\n",
    "    w_new = [w[i] - learning_rate * grad_w[i] for i in range (number_of_users)]\n",
    "    w_new = normalise_beamforming_vectors(w_new)\n",
    "        \n",
    "    theta_new = theta - learning_rate * grad_theta\n",
    "    theta_new = np.exp(1j * np.angle(theta_new))\n",
    "\n",
    "    return w_new, theta_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Secrecy Rate GD: 8.69968139551899\n",
      "Iteration 0\n",
      "Secrecy Rate: 8.69968139551899\n",
      "Iteration 1\n",
      "Secrecy Rate: 8.901927576581638\n",
      "Iteration 2\n",
      "Secrecy Rate: 9.080896832818695\n",
      "Iteration 3\n",
      "Secrecy Rate: 9.244444622040335\n",
      "Iteration 4\n",
      "Secrecy Rate: 9.40418182148963\n",
      "Iteration 5\n",
      "Secrecy Rate: 9.558978996319764\n",
      "Iteration 6\n",
      "Secrecy Rate: 9.708608369689669\n",
      "Iteration 7\n",
      "Secrecy Rate: 9.853069469279648\n",
      "Iteration 8\n",
      "Secrecy Rate: 9.992404573354378\n",
      "Iteration 9\n",
      "Secrecy Rate: 10.126692563097183\n",
      "Iteration 10\n",
      "Secrecy Rate: 10.256042162281867\n",
      "Iteration 11\n",
      "Secrecy Rate: 10.380444687253883\n",
      "Iteration 12\n",
      "Secrecy Rate: 10.49977192520473\n",
      "Iteration 13\n",
      "Secrecy Rate: 10.614019325408291\n",
      "Iteration 14\n",
      "Secrecy Rate: 10.72300381557473\n",
      "Iteration 15\n",
      "Secrecy Rate: 10.824711845591864\n",
      "Iteration 16\n",
      "Secrecy Rate: 10.92591109676218\n",
      "Iteration 17\n",
      "Secrecy Rate: 11.023135975565388\n",
      "Iteration 18\n",
      "Secrecy Rate: 11.116269529925306\n",
      "Iteration 19\n",
      "Secrecy Rate: 11.205923007806986\n",
      "Iteration 20\n",
      "Secrecy Rate: 11.292325227857422\n",
      "Iteration 21\n",
      "Secrecy Rate: 11.375006588950948\n",
      "Iteration 22\n",
      "Secrecy Rate: 11.446997027124478\n",
      "Iteration 23\n",
      "Secrecy Rate: 11.527696262718516\n",
      "Iteration 24\n",
      "Secrecy Rate: 11.596609864355042\n",
      "Iteration 25\n",
      "Secrecy Rate: 11.670654694718287\n",
      "Iteration 26\n",
      "Secrecy Rate: 11.733571130578609\n",
      "Iteration 27\n",
      "Secrecy Rate: 11.796950402247553\n",
      "Iteration 28\n",
      "Secrecy Rate: 11.865867599421504\n",
      "Iteration 29\n",
      "Secrecy Rate: 11.919653098606124\n",
      "Iteration 30\n",
      "Secrecy Rate: 11.977312614471208\n",
      "Iteration 31\n",
      "Secrecy Rate: 12.032821004798011\n",
      "Iteration 32\n",
      "Secrecy Rate: 12.086318813493394\n",
      "Iteration 33\n",
      "Secrecy Rate: 12.137852559363221\n",
      "Iteration 34\n",
      "Secrecy Rate: 12.187505416237318\n",
      "Iteration 35\n",
      "Secrecy Rate: 12.235361301813144\n",
      "Iteration 36\n",
      "Secrecy Rate: 12.281499723026585\n",
      "Iteration 37\n",
      "Secrecy Rate: 12.325996145302774\n",
      "Iteration 38\n",
      "Secrecy Rate: 12.368922205919796\n",
      "Iteration 39\n",
      "Secrecy Rate: 12.410345884578145\n",
      "Iteration 40\n",
      "Secrecy Rate: 12.450331636821236\n",
      "Iteration 41\n",
      "Secrecy Rate: 12.488940501929216\n",
      "Iteration 42\n",
      "Secrecy Rate: 12.526230194612927\n",
      "Iteration 43\n",
      "Secrecy Rate: 12.562255192239952\n",
      "Iteration 44\n",
      "Secrecy Rate: 12.597066833592745\n",
      "Iteration 45\n",
      "Secrecy Rate: 12.630713447670342\n",
      "Iteration 46\n",
      "Secrecy Rate: 12.663240527755645\n",
      "Iteration 47\n",
      "Secrecy Rate: 12.69469095328624\n",
      "Iteration 48\n",
      "Secrecy Rate: 12.725105243223204\n",
      "Iteration 49\n",
      "Secrecy Rate: 12.754521811453792\n",
      "Iteration 50\n",
      "Secrecy Rate: 12.782977197334866\n",
      "Iteration 51\n",
      "Secrecy Rate: 12.81050625907916\n",
      "Iteration 52\n",
      "Secrecy Rate: 12.837142331447515\n",
      "Iteration 53\n",
      "Secrecy Rate: 12.862917354383084\n",
      "Iteration 54\n",
      "Secrecy Rate: 12.887861977562494\n",
      "Iteration 55\n",
      "Secrecy Rate: 12.912005642585612\n",
      "Iteration 56\n",
      "Secrecy Rate: 12.935376643004556\n",
      "Iteration 57\n",
      "Secrecy Rate: 12.958002163181249\n",
      "Iteration 58\n",
      "Secrecy Rate: 12.979908299173673\n",
      "Iteration 59\n",
      "Secrecy Rate: 13.001120067285811\n",
      "Iteration 60\n",
      "Secrecy Rate: 13.021661407613301\n",
      "Iteration 61\n",
      "Secrecy Rate: 13.041555190326076\n",
      "Iteration 62\n",
      "Secrecy Rate: 13.06082323141859\n",
      "Iteration 63\n",
      "Secrecy Rate: 13.079486322462872\n",
      "Iteration 64\n",
      "Secrecy Rate: 13.09756427601806\n",
      "Iteration 65\n",
      "Secrecy Rate: 13.115075985408694\n",
      "Iteration 66\n",
      "Secrecy Rate: 13.132039495178391\n",
      "Iteration 67\n",
      "Secrecy Rate: 13.148472077078114\n",
      "Iteration 68\n",
      "Secrecy Rate: 13.16439030611684\n",
      "Iteration 69\n",
      "Secrecy Rate: 13.179810131866818\n",
      "Iteration 70\n",
      "Secrecy Rate: 13.194746941547553\n",
      "Iteration 71\n",
      "Secrecy Rate: 13.209215613001003\n",
      "Iteration 72\n",
      "Secrecy Rate: 13.22323055714853\n",
      "Iteration 73\n",
      "Secrecy Rate: 13.23680575065141\n",
      "Iteration 74\n",
      "Secrecy Rate: 13.2499547601949\n",
      "Iteration 75\n",
      "Secrecy Rate: 13.262690760114292\n",
      "Iteration 76\n",
      "Secrecy Rate: 13.275026545078811\n",
      "Iteration 77\n",
      "Secrecy Rate: 13.286974539360402\n",
      "Iteration 78\n",
      "Secrecy Rate: 13.298546803938294\n",
      "Iteration 79\n",
      "Secrecy Rate: 13.309755042397244\n",
      "Iteration 80\n",
      "Secrecy Rate: 13.320610606308945\n",
      "Iteration 81\n",
      "Secrecy Rate: 13.33112450056175\n",
      "Iteration 82\n",
      "Secrecy Rate: 13.341307388928499\n",
      "Iteration 83\n",
      "Secrecy Rate: 13.351169600031948\n",
      "Iteration 84\n",
      "Secrecy Rate: 13.360721133775309\n",
      "Iteration 85\n",
      "Secrecy Rate: 13.36997166824342\n",
      "Iteration 86\n",
      "Secrecy Rate: 13.378930567040715\n",
      "Iteration 87\n",
      "Secrecy Rate: 13.387606887009206\n",
      "Iteration 88\n",
      "Secrecy Rate: 13.396009386257944\n",
      "Iteration 89\n",
      "Secrecy Rate: 13.404146532431557\n",
      "Iteration 90\n",
      "Secrecy Rate: 13.412026511146216\n",
      "Iteration 91\n",
      "Secrecy Rate: 13.419657234525413\n",
      "Iteration 92\n",
      "Secrecy Rate: 13.427046349773391\n",
      "Iteration 93\n",
      "Secrecy Rate: 13.434201247730684\n",
      "Iteration 94\n",
      "Secrecy Rate: 13.441129071362585\n",
      "Iteration 95\n",
      "Secrecy Rate: 13.447836724138272\n",
      "Iteration 96\n",
      "Secrecy Rate: 13.454330878264418\n",
      "Iteration 97\n",
      "Secrecy Rate: 13.460617982743159\n",
      "Iteration 98\n",
      "Secrecy Rate: 13.466704271229652\n",
      "Iteration 99\n",
      "Secrecy Rate: 13.472595769669638\n",
      "Iteration 100\n",
      "Secrecy Rate: 13.478298303701887\n",
      "Iteration 101\n",
      "Secrecy Rate: 13.483817505814525\n",
      "Iteration 102\n",
      "Secrecy Rate: 13.489158822248031\n",
      "Iteration 103\n",
      "Secrecy Rate: 13.494327519640848\n",
      "Iteration 104\n",
      "Secrecy Rate: 13.499328691416553\n",
      "Iteration 105\n",
      "Secrecy Rate: 13.504167263913926\n",
      "Iteration 106\n",
      "Secrecy Rate: 13.508848002263562\n",
      "Iteration 107\n",
      "Secrecy Rate: 13.513375516016328\n",
      "Iteration 108\n",
      "Secrecy Rate: 13.517754264530595\n",
      "Iteration 109\n",
      "Secrecy Rate: 13.52198856212642\n",
      "Iteration 110\n",
      "Secrecy Rate: 13.526082583015747\n",
      "Iteration 111\n",
      "Secrecy Rate: 13.530040366018541\n",
      "Iteration 112\n",
      "Secrecy Rate: 13.533865819075313\n",
      "Iteration 113\n",
      "Secrecy Rate: 13.537562723566836\n",
      "Iteration 114\n",
      "Secrecy Rate: 13.541134738452264\n",
      "Iteration 115\n",
      "Secrecy Rate: 13.544585404236807\n",
      "Iteration 116\n",
      "Secrecy Rate: 13.547362202843326\n",
      "Iteration 117\n",
      "Secrecy Rate: 13.568404153389448\n",
      "Iteration 118\n",
      "Secrecy Rate: 13.57572340829762\n",
      "Iteration 119\n",
      "Secrecy Rate: 13.5779196911799\n",
      "Iteration 120\n",
      "Secrecy Rate: 13.580243175702204\n",
      "Iteration 121\n",
      "Secrecy Rate: 13.590034776853287\n",
      "Iteration 122\n",
      "Secrecy Rate: 13.599805141425765\n",
      "Iteration 123\n",
      "Secrecy Rate: 13.609503064313564\n",
      "Iteration 124\n",
      "Secrecy Rate: 13.619117000012821\n",
      "Iteration 125\n",
      "Secrecy Rate: 13.628647192863829\n",
      "Iteration 126\n",
      "Secrecy Rate: 13.638094702821874\n",
      "Iteration 127\n",
      "Secrecy Rate: 13.647460432675427\n",
      "Iteration 128\n",
      "Secrecy Rate: 13.656745304804048\n",
      "Iteration 129\n",
      "Secrecy Rate: 13.665950229964903\n",
      "Iteration 130\n",
      "Secrecy Rate: 13.675076108883486\n",
      "Iteration 131\n",
      "Secrecy Rate: 13.68412383240721\n",
      "Iteration 132\n",
      "Secrecy Rate: 13.693094281589733\n",
      "Iteration 133\n",
      "Secrecy Rate: 13.701988327799334\n",
      "Iteration 134\n",
      "Secrecy Rate: 13.710806832812047\n",
      "Iteration 135\n",
      "Secrecy Rate: 13.719550648895805\n",
      "Iteration 136\n",
      "Secrecy Rate: 13.728220618886485\n",
      "Iteration 137\n",
      "Secrecy Rate: 13.736817576256982\n",
      "Iteration 138\n",
      "Secrecy Rate: 13.745342345180386\n",
      "Iteration 139\n",
      "Secrecy Rate: 13.753795740588327\n",
      "Iteration 140\n",
      "Secrecy Rate: 13.7621785682254\n",
      "Iteration 141\n",
      "Secrecy Rate: 13.770491624700472\n",
      "Iteration 142\n",
      "Secrecy Rate: 13.778735697535694\n",
      "Iteration 143\n",
      "Secrecy Rate: 13.786911565213837\n",
      "Iteration 144\n",
      "Secrecy Rate: 13.795019997224646\n",
      "Iteration 145\n",
      "Secrecy Rate: 13.803061754110663\n",
      "Iteration 146\n",
      "Secrecy Rate: 13.81103758751302\n",
      "Iteration 147\n",
      "Secrecy Rate: 13.818948240217656\n",
      "Iteration 148\n",
      "Secrecy Rate: 13.826794446202193\n",
      "Iteration 149\n",
      "Secrecy Rate: 13.834576930683866\n",
      "Iteration 150\n",
      "Secrecy Rate: 13.842296410168704\n",
      "Iteration 151\n",
      "Secrecy Rate: 13.849953592502132\n",
      "Iteration 152\n",
      "Secrecy Rate: 13.857549176921184\n",
      "Iteration 153\n",
      "Secrecy Rate: 13.865083854108384\n",
      "Iteration 154\n",
      "Secrecy Rate: 13.872558306247473\n",
      "Iteration 155\n",
      "Secrecy Rate: 13.8799732070809\n",
      "Iteration 156\n",
      "Secrecy Rate: 13.8873292219692\n",
      "Iteration 157\n",
      "Secrecy Rate: 13.894627007952192\n",
      "Iteration 158\n",
      "Secrecy Rate: 13.901867213812025\n",
      "Iteration 159\n",
      "Secrecy Rate: 13.909050480137982\n",
      "Iteration 160\n",
      "Secrecy Rate: 13.91617743939302\n",
      "Iteration 161\n",
      "Secrecy Rate: 13.923248715981957\n",
      "Iteration 162\n",
      "Secrecy Rate: 13.93026492632124\n",
      "Iteration 163\n",
      "Secrecy Rate: 13.937226678910207\n",
      "Iteration 164\n",
      "Secrecy Rate: 13.944134574403733\n",
      "Iteration 165\n",
      "Secrecy Rate: 13.950989205686161\n",
      "Iteration 166\n",
      "Secrecy Rate: 13.957791157946474\n",
      "Iteration 167\n",
      "Secrecy Rate: 13.964541008754487\n",
      "Iteration 168\n",
      "Secrecy Rate: 13.97123932813806\n",
      "Iteration 169\n",
      "Secrecy Rate: 13.977886678661203\n",
      "Iteration 170\n",
      "Secrecy Rate: 13.984483615502901\n",
      "Iteration 171\n",
      "Secrecy Rate: 13.99103068653665\n",
      "Iteration 172\n",
      "Secrecy Rate: 13.997528432410542\n",
      "Iteration 173\n",
      "Secrecy Rate: 14.003977386627803\n",
      "Iteration 174\n",
      "Secrecy Rate: 14.010378075627735\n",
      "Iteration 175\n",
      "Secrecy Rate: 14.016731018866874\n",
      "Iteration 176\n",
      "Secrecy Rate: 14.023036728900427\n",
      "Iteration 177\n",
      "Secrecy Rate: 14.029295711463718\n",
      "Iteration 178\n",
      "Secrecy Rate: 14.035508465553718\n",
      "Iteration 179\n",
      "Secrecy Rate: 14.041675483510492\n",
      "Iteration 180\n",
      "Secrecy Rate: 14.047797251098542\n",
      "Iteration 181\n",
      "Secrecy Rate: 14.053874247587945\n",
      "Iteration 182\n",
      "Secrecy Rate: 14.059906945835221\n",
      "Iteration 183\n",
      "Secrecy Rate: 14.065895812363916\n",
      "Iteration 184\n",
      "Secrecy Rate: 14.07184130744479\n",
      "Iteration 185\n",
      "Secrecy Rate: 14.077743885175579\n",
      "Iteration 186\n",
      "Secrecy Rate: 14.083603993560347\n",
      "Iteration 187\n",
      "Secrecy Rate: 14.08942207458824\n",
      "Iteration 188\n",
      "Secrecy Rate: 14.095198564311776\n",
      "Iteration 189\n",
      "Secrecy Rate: 14.100845436250147\n",
      "Iteration 190\n",
      "Secrecy Rate: 14.109506661190116\n",
      "Iteration 191\n",
      "Secrecy Rate: 14.113170789389464\n",
      "Iteration 192\n",
      "Secrecy Rate: 14.11851162401047\n",
      "Iteration 193\n",
      "Secrecy Rate: 14.123960581572515\n",
      "Iteration 194\n",
      "Secrecy Rate: 14.129392706277407\n",
      "Iteration 195\n",
      "Secrecy Rate: 14.13478921197851\n",
      "Iteration 196\n",
      "Secrecy Rate: 14.140147549209019\n",
      "Iteration 197\n",
      "Secrecy Rate: 14.145467833859453\n",
      "Iteration 198\n",
      "Secrecy Rate: 14.150750406681732\n",
      "Iteration 199\n",
      "Secrecy Rate: 14.155995617538375\n",
      "Iteration 200\n",
      "Secrecy Rate: 14.161203812341757\n",
      "Iteration 201\n",
      "Secrecy Rate: 14.166375332604986\n",
      "Iteration 202\n",
      "Secrecy Rate: 14.171510515487785\n",
      "Iteration 203\n",
      "Secrecy Rate: 14.176609693868452\n",
      "Iteration 204\n",
      "Secrecy Rate: 14.181673196413776\n",
      "Iteration 205\n",
      "Secrecy Rate: 14.18670134764812\n",
      "Iteration 206\n",
      "Secrecy Rate: 14.191694468021929\n",
      "Iteration 207\n",
      "Secrecy Rate: 14.196652873979815\n",
      "Iteration 208\n",
      "Secrecy Rate: 14.20157687802829\n",
      "Iteration 209\n",
      "Secrecy Rate: 14.206466788803068\n",
      "Iteration 210\n",
      "Secrecy Rate: 14.211322911136081\n",
      "Iteration 211\n",
      "Secrecy Rate: 14.21614554612217\n",
      "Iteration 212\n",
      "Secrecy Rate: 14.22093499118547\n",
      "Iteration 213\n",
      "Secrecy Rate: 14.225691540145547\n",
      "Iteration 214\n",
      "Secrecy Rate: 14.230415483283283\n",
      "Iteration 215\n",
      "Secrecy Rate: 14.235107107406556\n",
      "Iteration 216\n",
      "Secrecy Rate: 14.239766695915705\n",
      "Iteration 217\n",
      "Secrecy Rate: 14.244394528868792\n",
      "Iteration 218\n",
      "Secrecy Rate: 14.248990883046716\n",
      "Iteration 219\n",
      "Secrecy Rate: 14.25355603201817\n",
      "Iteration 220\n",
      "Secrecy Rate: 14.258090246204413\n",
      "Iteration 221\n",
      "Secrecy Rate: 14.262593792943917\n",
      "Iteration 222\n",
      "Secrecy Rate: 14.267066936556885\n",
      "Iteration 223\n",
      "Secrecy Rate: 14.271509938409567\n",
      "Iteration 224\n",
      "Secrecy Rate: 14.275923056978488\n",
      "Iteration 225\n",
      "Secrecy Rate: 14.280306547914474\n",
      "Iteration 226\n",
      "Secrecy Rate: 14.284660664106514\n",
      "Iteration 227\n",
      "Secrecy Rate: 14.288985655745412\n",
      "Iteration 228\n",
      "Secrecy Rate: 14.293281770387246\n",
      "Iteration 229\n",
      "Secrecy Rate: 14.297549253016566\n",
      "Iteration 230\n",
      "Secrecy Rate: 14.301788346109264\n",
      "Iteration 231\n",
      "Secrecy Rate: 14.305999289695194\n",
      "Iteration 232\n",
      "Secrecy Rate: 14.31018232142035\n",
      "Iteration 233\n",
      "Secrecy Rate: 14.314337676608641\n",
      "Iteration 234\n",
      "Secrecy Rate: 14.318465588323173\n",
      "Iteration 235\n",
      "Secrecy Rate: 14.322566287426966\n",
      "Iteration 236\n",
      "Secrecy Rate: 14.326640002643027\n",
      "Iteration 237\n",
      "Secrecy Rate: 14.330686960613736\n",
      "Iteration 238\n",
      "Secrecy Rate: 14.334707385959389\n",
      "Iteration 239\n",
      "Secrecy Rate: 14.338701501335866\n",
      "Iteration 240\n",
      "Secrecy Rate: 14.342669527491289\n",
      "Iteration 241\n",
      "Secrecy Rate: 14.346611683321552\n",
      "Iteration 242\n",
      "Secrecy Rate: 14.350528185924652\n",
      "Iteration 243\n",
      "Secrecy Rate: 14.354419250653667\n",
      "Iteration 244\n",
      "Secrecy Rate: 14.358285091168234\n",
      "Iteration 245\n",
      "Secrecy Rate: 14.362125919484468\n",
      "Iteration 246\n",
      "Secrecy Rate: 14.36594194602313\n",
      "Iteration 247\n",
      "Secrecy Rate: 14.369733379655914\n",
      "Iteration 248\n",
      "Secrecy Rate: 14.373500427749757\n",
      "Iteration 249\n",
      "Secrecy Rate: 14.37724329620898\n",
      "Iteration 250\n",
      "Secrecy Rate: 14.380962189515182\n",
      "Iteration 251\n",
      "Secrecy Rate: 14.384657310764684\n",
      "Iteration 252\n",
      "Secrecy Rate: 14.388328861703487\n",
      "Iteration 253\n",
      "Secrecy Rate: 14.39197704275949\n",
      "Iteration 254\n",
      "Secrecy Rate: 14.395602053072015\n",
      "Iteration 255\n",
      "Secrecy Rate: 14.399204090518369\n",
      "Iteration 256\n",
      "Secrecy Rate: 14.402783351737442\n",
      "Iteration 257\n",
      "Secrecy Rate: 14.40634003215025\n",
      "Iteration 258\n",
      "Secrecy Rate: 14.409874325977327\n",
      "Iteration 259\n",
      "Secrecy Rate: 14.413386426252888\n",
      "Iteration 260\n",
      "Secrecy Rate: 14.416876524835796\n",
      "Iteration 261\n",
      "Secrecy Rate: 14.420344812417287\n",
      "Iteration 262\n",
      "Secrecy Rate: 14.423791478525402\n",
      "Iteration 263\n",
      "Secrecy Rate: 14.42721671152624\n",
      "Iteration 264\n",
      "Secrecy Rate: 14.430620698622047\n",
      "Iteration 265\n",
      "Secrecy Rate: 14.433974581719658\n",
      "Iteration 266\n",
      "Secrecy Rate: 14.436876289079756\n",
      "Iteration 267\n",
      "Secrecy Rate: 14.442033470437526\n",
      "Iteration 268\n",
      "Secrecy Rate: 14.444052081352211\n",
      "Iteration 269\n",
      "Secrecy Rate: 14.447170874375376\n",
      "Iteration 270\n",
      "Secrecy Rate: 14.451965298757674\n",
      "Iteration 271\n",
      "Secrecy Rate: 14.453813064944235\n",
      "Iteration 272\n",
      "Secrecy Rate: 14.457297092289718\n",
      "Iteration 273\n",
      "Secrecy Rate: 14.461715037058473\n",
      "Iteration 274\n",
      "Secrecy Rate: 14.46339619833602\n",
      "Iteration 275\n",
      "Secrecy Rate: 14.467254173004296\n",
      "Iteration 276\n",
      "Secrecy Rate: 14.471289069864575\n",
      "Iteration 277\n",
      "Secrecy Rate: 14.472806454660153\n",
      "Iteration 278\n",
      "Secrecy Rate: 14.477044565182394\n",
      "Iteration 279\n",
      "Secrecy Rate: 14.480691981580096\n",
      "Iteration 280\n",
      "Secrecy Rate: 14.482048849017193\n",
      "Iteration 281\n",
      "Secrecy Rate: 14.486670930014434\n",
      "Iteration 282\n",
      "Secrecy Rate: 14.48992826186451\n",
      "Iteration 283\n",
      "Secrecy Rate: 14.491128268653071\n",
      "Iteration 284\n",
      "Secrecy Rate: 14.496136095721315\n",
      "Iteration 285\n",
      "Secrecy Rate: 14.49900228920205\n",
      "Iteration 286\n",
      "Secrecy Rate: 14.50004945294761\n",
      "Iteration 287\n",
      "Secrecy Rate: 14.505443004581625\n",
      "Iteration 288\n",
      "Secrecy Rate: 14.507918314840621\n",
      "Iteration 289\n",
      "Secrecy Rate: 14.508816975678963\n",
      "Iteration 290\n",
      "Secrecy Rate: 14.514594668342331\n",
      "Iteration 291\n",
      "Secrecy Rate: 14.516680445790376\n",
      "Iteration 292\n",
      "Secrecy Rate: 14.517435230468987\n",
      "Iteration 293\n",
      "Secrecy Rate: 14.523594132270004\n",
      "Iteration 294\n",
      "Secrecy Rate: 14.525292628346477\n",
      "Iteration 295\n",
      "Secrecy Rate: 14.525908420643045\n",
      "Iteration 296\n",
      "Secrecy Rate: 14.532444447057177\n",
      "Iteration 297\n",
      "Secrecy Rate: 14.53375863338316\n",
      "Iteration 298\n",
      "Secrecy Rate: 14.534240554442068\n",
      "Iteration 299\n",
      "Secrecy Rate: 14.541148647394005\n",
      "Iteration 300\n",
      "Secrecy Rate: 14.542082044377532\n",
      "Iteration 301\n",
      "Secrecy Rate: 14.542435446155412\n",
      "Iteration 302\n",
      "Secrecy Rate: 14.549709735964063\n",
      "Iteration 303\n",
      "Secrecy Rate: 14.55026624879146\n",
      "Iteration 304\n",
      "Secrecy Rate: 14.550496723349452\n",
      "Iteration 305\n",
      "Secrecy Rate: 14.55813067174007\n",
      "Iteration 306\n",
      "Secrecy Rate: 14.558314433108626\n",
      "Iteration 307\n",
      "Secrecy Rate: 14.558427839998771\n",
      "Iteration 308\n",
      "Secrecy Rate: 14.566414361633216\n",
      "Converged\n",
      "Final Secrecy Rate GD: 12.490742841533333\n",
      "0.9027923993726633 1.619386263395618 1.1975127554667215 1.75620424208584 1.0036529650419568 1.0372294748555377 1.0005810327234175 1.0468140079951067 1.758416985126171 2.782262660266156 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11\\AppData\\Local\\Temp\\ipykernel_4732\\3202772336.py:54: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(float(C_bk), end = \" \")\n"
     ]
    }
   ],
   "source": [
    "# Reseed first\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Gradient Descent Algorithm\n",
    "num_cycles = 500\n",
    "learning_rate = 0.01\n",
    "theta_GD = generate_random_theta()\n",
    "w_GD = generate_random_beamforming_vectors()\n",
    "theta_GD, w_GD = repair(theta_GD, w_GD)\n",
    "print(\"Initial Secrecy Rate GD:\", secrecy_rate_objective_function(theta_GD, w_GD))\n",
    "current_secrecy_rate = secrecy_rate_objective_function(theta_GD, w_GD)\n",
    "\n",
    "GD_results = []\n",
    "GD_results.append(current_secrecy_rate)\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    print(\"Iteration\", i)\n",
    "    print(\"Secrecy Rate:\", current_secrecy_rate)\n",
    "    w_new, theta_new = gradient_descent_update(w_GD, theta_GD, learning_rate, original_secrecy_rate=current_secrecy_rate)\n",
    "    #if check_validity(theta_new, w_new) == False:\n",
    "    #    print(\"Stop by invalidity\")\n",
    "    #    break\n",
    "    new_secrecy_rate = secrecy_rate_objective_function(theta_new, w_new)\n",
    "    if (new_secrecy_rate - current_secrecy_rate) < 1e-9:\n",
    "        print(\"Converged\")\n",
    "        break\n",
    "    w_GD = w_new\n",
    "    theta_GD = theta_new\n",
    "    GD_results.append(new_secrecy_rate)\n",
    "    current_secrecy_rate = new_secrecy_rate\n",
    "\n",
    "theta_GD, w_GD = repair(theta_GD, w_GD)\n",
    "#print(GD_results)\n",
    "print(\"Final Secrecy Rate GD:\", secrecy_rate_objective_function(theta_GD, w_GD))\n",
    "print_users_Cbk(theta_GD, w_GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Swarm Optimization (PSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSOParticle:\n",
    "  def __init__(self) -> None:\n",
    "    self.theta = generate_random_theta_angles(Nris)\n",
    "    self.w = generate_random_beamforming_vectors()\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "    self.best_theta = deepcopy(self.theta)\n",
    "    self.best_w = deepcopy(self.w)\n",
    "    self.best_secrecy_rate = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.best_theta), self.best_w)\n",
    "    self.current_secrecy_rate = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.theta), self.w)\n",
    "    self.velocity_theta = np.zeros((1, Nris))\n",
    "    self.velocity_w = [np.zeros((N, 1)) for i in range(number_of_users)]\n",
    "\n",
    "  \n",
    "  def update_velocity(self, inertia, c1, c2, global_best_theta, global_best_w):\n",
    "    r1 = np.random.rand()\n",
    "    r2 = np.random.rand()\n",
    "    self.velocity_theta = inertia * self.velocity_theta + c1 * r1 * (self.best_theta - self.theta) + c2 * r2 * (global_best_theta - self.theta)\n",
    "    self.velocity_w = [inertia * self.velocity_w[i] + c1 * r1 * (self.best_w[i] - self.w[i]) + c2 * r2 * (global_best_w[i] - self.w[i]) for i in range(number_of_users)]\n",
    "\n",
    "  def update_position(self):\n",
    "    self.theta = self.theta + self.velocity_theta\n",
    "    self.w = [self.w[i] + self.velocity_w[i] for i in range(number_of_users)]\n",
    "    self.w = normalise_beamforming_vectors(self.w)\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "\n",
    "  def update_velocity_theta(self, inertia, c1, c2, global_best_theta): #Used for PSO_GD\n",
    "    self.velocity_theta = inertia * self.velocity_theta + c1 * np.random.rand() * (self.best_theta - self.theta) + c2 * np.random.rand() * (global_best_theta - self.theta)\n",
    "  \n",
    "  def update_position_theta(self): #Used for PSO_GD\n",
    "    self.theta = self.theta + self.velocity_theta\n",
    "\n",
    "  def update_best(self):\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "    self.current_secrecy_rate = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.theta), self.w)\n",
    "    if self.current_secrecy_rate > self.best_secrecy_rate:\n",
    "      self.best_secrecy_rate = self.current_secrecy_rate\n",
    "      self.best_theta = deepcopy(self.theta)\n",
    "      self.best_w = deepcopy(self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_inertia(i: int, max_iter: int, inertia_max: float, inertia_min: float) -> float:\n",
    "  E_t = float((max_iter - i - 1)/max_iter)\n",
    "  inertia = inertia_min + (inertia_max - inertia_min) * (2 /(1 + (np.e ** (-5 * E_t))) - 1)\n",
    "  return inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_optimize_w_theta(max_iter: int, num_particles: int, w_min: float, w_max: float, c1: float, c2: float):\n",
    "  particles = [PSOParticle() for _ in range(num_particles)]\n",
    "  global_best_secrecy_rate = -np.inf\n",
    "  global_best_theta = np.zeros((1, Nris))\n",
    "  global_best_w = [np.zeros((N, 1)) for i in range(number_of_users)]\n",
    "\n",
    "  results_secrecy_rate = []\n",
    "\n",
    "  for particle in particles:\n",
    "    if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "      global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "      global_best_theta = deepcopy(particle.best_theta)\n",
    "      global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "  results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "\n",
    "  for iteration in range(max_iter):\n",
    "    print(\"iteration =\", iteration, global_best_secrecy_rate)\n",
    "    inertia = dynamic_inertia(iteration, max_iter, w_max, w_min)\n",
    "\n",
    "    for particle in particles:\n",
    "      particle.update_velocity(inertia, c1, c2, global_best_theta, global_best_w)\n",
    "      particle.update_position()\n",
    "      particle.update_best()\n",
    "\n",
    "      if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "        global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "        global_best_theta = deepcopy(particle.best_theta)\n",
    "        global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "    results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "   \n",
    "\n",
    "  return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0 8.698405811598715\n",
      "iteration = 1 11.244665756531374\n",
      "iteration = 2 11.35425809694848\n",
      "iteration = 3 11.35425809694848\n",
      "iteration = 4 11.35425809694848\n",
      "iteration = 5 11.35425809694848\n",
      "iteration = 6 11.35425809694848\n",
      "iteration = 7 11.37187371791279\n",
      "iteration = 8 11.623853963255415\n",
      "iteration = 9 11.867802435078854\n",
      "iteration = 10 11.867802435078854\n",
      "iteration = 11 12.082047471243873\n",
      "iteration = 12 12.082047471243873\n",
      "iteration = 13 12.082047471243873\n",
      "iteration = 14 12.082047471243873\n",
      "iteration = 15 12.082047471243873\n",
      "iteration = 16 12.082047471243873\n",
      "iteration = 17 12.444534175163657\n",
      "iteration = 18 12.444534175163657\n",
      "iteration = 19 12.444534175163657\n",
      "iteration = 20 12.444534175163657\n",
      "iteration = 21 12.444534175163657\n",
      "iteration = 22 12.444534175163657\n",
      "iteration = 23 12.444534175163657\n",
      "iteration = 24 12.444534175163657\n",
      "iteration = 25 12.444534175163657\n",
      "iteration = 26 12.444534175163657\n",
      "iteration = 27 12.444534175163657\n",
      "iteration = 28 12.444534175163657\n",
      "iteration = 29 12.444534175163657\n",
      "iteration = 30 12.444534175163657\n",
      "iteration = 31 12.444534175163657\n",
      "iteration = 32 12.444534175163657\n",
      "iteration = 33 12.444534175163657\n",
      "iteration = 34 12.444534175163657\n",
      "iteration = 35 12.444534175163657\n",
      "iteration = 36 12.444534175163657\n",
      "iteration = 37 12.444534175163657\n",
      "iteration = 38 12.444534175163657\n",
      "iteration = 39 12.444534175163657\n",
      "iteration = 40 12.444534175163657\n",
      "iteration = 41 12.444534175163657\n",
      "iteration = 42 12.506196241676268\n",
      "iteration = 43 12.506196241676268\n",
      "iteration = 44 12.506196241676268\n",
      "iteration = 45 12.506196241676268\n",
      "iteration = 46 12.506196241676268\n",
      "iteration = 47 12.506196241676268\n",
      "iteration = 48 12.506196241676268\n",
      "iteration = 49 12.506196241676268\n",
      "iteration = 50 12.506196241676268\n",
      "iteration = 51 12.600834964088794\n",
      "iteration = 52 12.600834964088794\n",
      "iteration = 53 12.600834964088794\n",
      "iteration = 54 12.600834964088794\n",
      "iteration = 55 12.600834964088794\n",
      "iteration = 56 12.600834964088794\n",
      "iteration = 57 12.600834964088794\n",
      "iteration = 58 12.600834964088794\n",
      "iteration = 59 12.600834964088794\n",
      "iteration = 60 12.600834964088794\n",
      "iteration = 61 12.600834964088794\n",
      "iteration = 62 12.600834964088794\n",
      "iteration = 63 12.602742300303452\n",
      "iteration = 64 12.602742300303452\n",
      "iteration = 65 12.602742300303452\n",
      "iteration = 66 12.659039023685718\n",
      "iteration = 67 12.659039023685718\n",
      "iteration = 68 12.659039023685718\n",
      "iteration = 69 12.659589308323415\n",
      "iteration = 70 12.659589308323415\n",
      "iteration = 71 12.659589308323415\n",
      "iteration = 72 12.659589308323415\n",
      "iteration = 73 12.659589308323415\n",
      "iteration = 74 12.659589308323415\n",
      "iteration = 75 12.659589308323415\n",
      "iteration = 76 12.720124097353345\n",
      "iteration = 77 12.720124097353345\n",
      "iteration = 78 12.794120401449433\n",
      "iteration = 79 12.794120401449433\n",
      "iteration = 80 12.794120401449433\n",
      "iteration = 81 12.794120401449433\n",
      "iteration = 82 12.794120401449433\n",
      "iteration = 83 12.794120401449433\n",
      "iteration = 84 12.794120401449433\n",
      "iteration = 85 13.014059993158025\n",
      "iteration = 86 13.014059993158025\n",
      "iteration = 87 13.014059993158025\n",
      "iteration = 88 13.014059993158025\n",
      "iteration = 89 13.014059993158025\n",
      "iteration = 90 13.014059993158025\n",
      "iteration = 91 13.014059993158025\n",
      "iteration = 92 13.014059993158025\n",
      "iteration = 93 13.014059993158025\n",
      "iteration = 94 13.014059993158025\n",
      "iteration = 95 13.014059993158025\n",
      "iteration = 96 13.014059993158025\n",
      "iteration = 97 13.014059993158025\n",
      "iteration = 98 13.014059993158025\n",
      "iteration = 99 13.014059993158025\n",
      "iteration = 100 13.014059993158025\n",
      "iteration = 101 13.027846996104438\n",
      "iteration = 102 13.027846996104438\n",
      "iteration = 103 13.027846996104438\n",
      "iteration = 104 13.027846996104438\n",
      "iteration = 105 13.027846996104438\n",
      "iteration = 106 13.027846996104438\n",
      "iteration = 107 13.027846996104438\n",
      "iteration = 108 13.027846996104438\n",
      "iteration = 109 13.027846996104438\n",
      "iteration = 110 13.027846996104438\n",
      "iteration = 111 13.027846996104438\n",
      "iteration = 112 13.027846996104438\n",
      "iteration = 113 13.027846996104438\n",
      "iteration = 114 13.053799887173707\n",
      "iteration = 115 13.053799887173707\n",
      "iteration = 116 13.053799887173707\n",
      "iteration = 117 13.053799887173707\n",
      "iteration = 118 13.053799887173707\n",
      "iteration = 119 13.053799887173707\n",
      "iteration = 120 13.053799887173707\n",
      "iteration = 121 13.053799887173707\n",
      "iteration = 122 13.053799887173707\n",
      "iteration = 123 13.141038661006696\n",
      "iteration = 124 13.157077794157905\n",
      "iteration = 125 13.157077794157905\n",
      "iteration = 126 13.157833998829139\n",
      "iteration = 127 13.157833998829139\n",
      "iteration = 128 13.161782778081601\n",
      "iteration = 129 13.161782778081601\n",
      "iteration = 130 13.256468387450234\n",
      "iteration = 131 13.256468387450234\n",
      "iteration = 132 13.256468387450234\n",
      "iteration = 133 13.256468387450234\n",
      "iteration = 134 13.256468387450234\n",
      "iteration = 135 13.256468387450234\n",
      "iteration = 136 13.256468387450234\n",
      "iteration = 137 13.256468387450234\n",
      "iteration = 138 13.256468387450234\n",
      "iteration = 139 13.256468387450234\n",
      "iteration = 140 13.256468387450234\n",
      "iteration = 141 13.256468387450234\n",
      "iteration = 142 13.267802384808428\n",
      "iteration = 143 13.267802384808428\n",
      "iteration = 144 13.269078545755933\n",
      "iteration = 145 13.27605566874891\n",
      "iteration = 146 13.27605566874891\n",
      "iteration = 147 13.27605566874891\n",
      "iteration = 148 13.27605566874891\n",
      "iteration = 149 13.27605566874891\n",
      "iteration = 150 13.27605566874891\n",
      "iteration = 151 13.314821308317665\n",
      "iteration = 152 13.314821308317665\n",
      "iteration = 153 13.314821308317665\n",
      "iteration = 154 13.314821308317665\n",
      "iteration = 155 13.314821308317665\n",
      "iteration = 156 13.351276132516995\n",
      "iteration = 157 13.351276132516995\n",
      "iteration = 158 13.35145614674974\n",
      "iteration = 159 13.35145614674974\n",
      "iteration = 160 13.35145614674974\n",
      "iteration = 161 13.35145614674974\n",
      "iteration = 162 13.35145614674974\n",
      "iteration = 163 13.35145614674974\n",
      "iteration = 164 13.35145614674974\n",
      "iteration = 165 13.35145614674974\n",
      "iteration = 166 13.35145614674974\n",
      "iteration = 167 13.35145614674974\n",
      "iteration = 168 13.376867221106032\n",
      "iteration = 169 13.376867221106032\n",
      "iteration = 170 13.376867221106032\n",
      "iteration = 171 13.377649327145264\n",
      "iteration = 172 13.377649327145264\n",
      "iteration = 173 13.377649327145264\n",
      "iteration = 174 13.377649327145264\n",
      "iteration = 175 13.377649327145264\n",
      "iteration = 176 13.377649327145264\n",
      "iteration = 177 13.399469275438161\n",
      "iteration = 178 13.399469275438161\n",
      "iteration = 179 13.399469275438161\n",
      "iteration = 180 13.399469275438161\n",
      "iteration = 181 13.399469275438161\n",
      "iteration = 182 13.399469275438161\n",
      "iteration = 183 13.399469275438161\n",
      "iteration = 184 13.403104893526177\n",
      "iteration = 185 13.403104893526177\n",
      "iteration = 186 13.439106008344048\n",
      "iteration = 187 13.439106008344048\n",
      "iteration = 188 13.439106008344048\n",
      "iteration = 189 13.439106008344048\n",
      "iteration = 190 13.439106008344048\n",
      "iteration = 191 13.439106008344048\n",
      "iteration = 192 13.439106008344048\n",
      "iteration = 193 13.442322688931457\n",
      "iteration = 194 13.442322688931457\n",
      "iteration = 195 13.442322688931457\n",
      "iteration = 196 13.442322688931457\n",
      "iteration = 197 13.442322688931457\n",
      "iteration = 198 13.442322688931457\n",
      "iteration = 199 13.442322688931457\n",
      "Initial Secrecy Rate PSO: 8.698405811598715\n",
      "[np.float64(8.698405811598715), np.float64(11.244665756531374), np.float64(11.35425809694848), np.float64(11.35425809694848), np.float64(11.35425809694848), np.float64(11.35425809694848), np.float64(11.35425809694848), np.float64(11.37187371791279), np.float64(11.623853963255415), np.float64(11.867802435078854), np.float64(11.867802435078854), np.float64(12.082047471243873), np.float64(12.082047471243873), np.float64(12.082047471243873), np.float64(12.082047471243873), np.float64(12.082047471243873), np.float64(12.082047471243873), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.444534175163657), np.float64(12.506196241676268), np.float64(12.506196241676268), np.float64(12.506196241676268), np.float64(12.506196241676268), np.float64(12.506196241676268), np.float64(12.506196241676268), np.float64(12.506196241676268), np.float64(12.506196241676268), np.float64(12.506196241676268), np.float64(12.600834964088794), np.float64(12.600834964088794), np.float64(12.600834964088794), np.float64(12.600834964088794), np.float64(12.600834964088794), np.float64(12.600834964088794), np.float64(12.600834964088794), np.float64(12.600834964088794), np.float64(12.600834964088794), np.float64(12.600834964088794), np.float64(12.600834964088794), np.float64(12.600834964088794), np.float64(12.602742300303452), np.float64(12.602742300303452), np.float64(12.602742300303452), np.float64(12.659039023685718), np.float64(12.659039023685718), np.float64(12.659039023685718), np.float64(12.659589308323415), np.float64(12.659589308323415), np.float64(12.659589308323415), np.float64(12.659589308323415), np.float64(12.659589308323415), np.float64(12.659589308323415), np.float64(12.659589308323415), np.float64(12.720124097353345), np.float64(12.720124097353345), np.float64(12.794120401449433), np.float64(12.794120401449433), np.float64(12.794120401449433), np.float64(12.794120401449433), np.float64(12.794120401449433), np.float64(12.794120401449433), np.float64(12.794120401449433), np.float64(13.014059993158025), np.float64(13.014059993158025), np.float64(13.014059993158025), np.float64(13.014059993158025), np.float64(13.014059993158025), np.float64(13.014059993158025), np.float64(13.014059993158025), np.float64(13.014059993158025), np.float64(13.014059993158025), np.float64(13.014059993158025), np.float64(13.014059993158025), np.float64(13.014059993158025), np.float64(13.014059993158025), np.float64(13.014059993158025), np.float64(13.014059993158025), np.float64(13.014059993158025), np.float64(13.027846996104438), np.float64(13.027846996104438), np.float64(13.027846996104438), np.float64(13.027846996104438), np.float64(13.027846996104438), np.float64(13.027846996104438), np.float64(13.027846996104438), np.float64(13.027846996104438), np.float64(13.027846996104438), np.float64(13.027846996104438), np.float64(13.027846996104438), np.float64(13.027846996104438), np.float64(13.027846996104438), np.float64(13.053799887173707), np.float64(13.053799887173707), np.float64(13.053799887173707), np.float64(13.053799887173707), np.float64(13.053799887173707), np.float64(13.053799887173707), np.float64(13.053799887173707), np.float64(13.053799887173707), np.float64(13.053799887173707), np.float64(13.141038661006696), np.float64(13.157077794157905), np.float64(13.157077794157905), np.float64(13.157833998829139), np.float64(13.157833998829139), np.float64(13.161782778081601), np.float64(13.161782778081601), np.float64(13.256468387450234), np.float64(13.256468387450234), np.float64(13.256468387450234), np.float64(13.256468387450234), np.float64(13.256468387450234), np.float64(13.256468387450234), np.float64(13.256468387450234), np.float64(13.256468387450234), np.float64(13.256468387450234), np.float64(13.256468387450234), np.float64(13.256468387450234), np.float64(13.256468387450234), np.float64(13.267802384808428), np.float64(13.267802384808428), np.float64(13.269078545755933), np.float64(13.27605566874891), np.float64(13.27605566874891), np.float64(13.27605566874891), np.float64(13.27605566874891), np.float64(13.27605566874891), np.float64(13.27605566874891), np.float64(13.314821308317665), np.float64(13.314821308317665), np.float64(13.314821308317665), np.float64(13.314821308317665), np.float64(13.314821308317665), np.float64(13.351276132516995), np.float64(13.351276132516995), np.float64(13.35145614674974), np.float64(13.35145614674974), np.float64(13.35145614674974), np.float64(13.35145614674974), np.float64(13.35145614674974), np.float64(13.35145614674974), np.float64(13.35145614674974), np.float64(13.35145614674974), np.float64(13.35145614674974), np.float64(13.35145614674974), np.float64(13.376867221106032), np.float64(13.376867221106032), np.float64(13.376867221106032), np.float64(13.377649327145264), np.float64(13.377649327145264), np.float64(13.377649327145264), np.float64(13.377649327145264), np.float64(13.377649327145264), np.float64(13.377649327145264), np.float64(13.399469275438161), np.float64(13.399469275438161), np.float64(13.399469275438161), np.float64(13.399469275438161), np.float64(13.399469275438161), np.float64(13.399469275438161), np.float64(13.399469275438161), np.float64(13.403104893526177), np.float64(13.403104893526177), np.float64(13.439106008344048), np.float64(13.439106008344048), np.float64(13.439106008344048), np.float64(13.439106008344048), np.float64(13.439106008344048), np.float64(13.439106008344048), np.float64(13.439106008344048), np.float64(13.442322688931457), np.float64(13.442322688931457), np.float64(13.442322688931457), np.float64(13.442322688931457), np.float64(13.442322688931457), np.float64(13.442322688931457), np.float64(13.442322688931457), np.float64(13.442322688931457)]\n",
      "Final Secrecy Rate PSO: 13.442322688931457\n"
     ]
    }
   ],
   "source": [
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# PSO Algorithm\n",
    "max_iter = 200\n",
    "num_particles = 100\n",
    "w_min = 0.5\n",
    "w_max = 0.9\n",
    "c1 = 1.5\n",
    "c2 = 1.5\n",
    "\n",
    "PSO_results = PSO_optimize_w_theta(max_iter, num_particles, w_min, w_max, c1, c2)\n",
    "print(\"Initial Secrecy Rate PSO:\", PSO_results[0])\n",
    "print(PSO_results)\n",
    "print(\"Final Secrecy Rate PSO:\", PSO_results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm (GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAIndividual:\n",
    "  def __init__(self, theta: np.ndarray[np.float64] = None, w: np.ndarray[np.complex128] = None) -> None:\n",
    "    if theta is None or w is None:\n",
    "      self.theta = generate_random_theta_angles(Nris)\n",
    "      self.w = generate_random_beamforming_vectors()\n",
    "    else:\n",
    "      self.theta = theta\n",
    "      self.w = w\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "    self.update_fitness()\n",
    "  \n",
    "  def update_fitness(self):\n",
    "    self.fitness = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.theta), self.w)\n",
    "\n",
    "\n",
    "class GAPopulation:\n",
    "  def __init__(self, population_size: int, crossover_rate: float = 0.85, mutation_rate: float = 0.3) -> None:\n",
    "    self.population_size = population_size\n",
    "    self.individuals = [GAIndividual() for _ in range(population_size)]\n",
    "    self.crossover_rate = crossover_rate\n",
    "    self.mutation_rate = mutation_rate\n",
    "\n",
    "  def sort_population(self):\n",
    "    self.individuals.sort(key=lambda x: x.fitness, reverse=True)\n",
    "\n",
    "  def filter_population(self):\n",
    "    self.sort_population()\n",
    "    self.individuals = self.individuals[:self.population_size]\n",
    "\n",
    "  def add_individual(self, individual: GAIndividual):\n",
    "    self.individuals.append(individual)\n",
    "\n",
    "  def select_parents(self) -> tuple[GAIndividual, GAIndividual]:\n",
    "    parents = np.random.choice(self.individuals, 2, replace=False)\n",
    "    return parents[0], parents[1]\n",
    "  \n",
    "  def crossover(self, parent1: GAIndividual, parent2: GAIndividual) -> GAIndividual:\n",
    "    theta1, w1 = parent1.theta, parent1.w\n",
    "    theta2, w2 = parent2.theta, parent2.w\n",
    "    theta_child = (theta1 + theta2) / 2\n",
    "    w_child = [(w1[i] + w2[i]) / 2 for i in range(number_of_users)]\n",
    "    w_child = normalise_beamforming_vectors(w_child)\n",
    "    theta_child, w_child = repair(theta_child, w_child)\n",
    "    return GAIndividual(theta_child, w_child)\n",
    "  \n",
    "  def mutate(self, individual: GAIndividual) -> GAIndividual:\n",
    "    if np.random.rand() < self.mutation_rate:\n",
    "      mutation_index = np.random.randint(0, Nris)\n",
    "      individual.theta[0, mutation_index] = np.random.uniform(-np.pi, np.pi)\n",
    "      mutation_index = np.random.randint(len(individual.w))\n",
    "      individual.w[mutation_index] = generate_random_beamforming_vector()\n",
    "      individual.w = normalise_beamforming_vectors(individual.w)\n",
    "      individual.theta, individual.w = repair(individual.theta, individual.w)\n",
    "      individual.update_fitness()\n",
    "\n",
    "    return individual\n",
    "  \n",
    "def GA_optimize_w_theta(population_size: int, max_iter: int, crossover_rate: float = 0.85, mutation_rate: float = 0.85):\n",
    "  population = GAPopulation(population_size, crossover_rate, mutation_rate)\n",
    "  population.sort_population()\n",
    "  results_secrecy_rate = []\n",
    "  results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "\n",
    "  for iteration in range(max_iter):\n",
    "    print(\"iteration =\", iteration, population.individuals[0].fitness)\n",
    "    # Crossover and mutate\n",
    "    for _ in range(population_size):\n",
    "      if np.random.rand() < population.crossover_rate:\n",
    "        parent1, parent2 = population.select_parents()\n",
    "        child = population.crossover(parent1, parent2)\n",
    "        population.mutate(child)\n",
    "        population.add_individual(child)\n",
    "    # Filter\n",
    "    population.filter_population()\n",
    "    \n",
    "    results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "    print_users_Cbk(theta_angles_to_theta_vector(population.individuals[0].theta), population.individuals[0].w)\n",
    "  return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0 8.698405811598715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11\\AppData\\Local\\Temp\\ipykernel_4732\\3202772336.py:54: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(float(C_bk), end = \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9338980339018441 1.4633767390281989 1.0036758866659763 0.9701665486246485 0.8961831765723896 1.4545531845644926 0.974079826201935 0.9681595288111621 1.0184423477866411 0.931805872003145 \n",
      "iteration = 1 10.24197660886312\n",
      "1.0809044559333985 1.2485259033943152 1.2478618802489605 1.0169781987700415 0.8984373189114748 0.8337183374095257 0.9394381876355297 0.8992393132840953 1.7886753201490455 0.9301835971446353 \n",
      "iteration = 2 10.584381652068682\n",
      "0.8145675158184 0.9304970603571369 1.6256713684490538 0.9109260776376235 1.0071366583640022 1.8908965139604619 0.9512907158464283 1.002739687533142 0.8336645326268922 1.0787991063957205 \n",
      "iteration = 3 10.816506909188886\n",
      "0.8339551517361538 0.8488457372233871 1.1221381960877184 1.0178241877956418 1.3622534598015108 1.5668894713356774 0.8867747954502078 1.5653484379144016 1.01456725858288 1.142958041994238 \n",
      "iteration = 4 11.138319480378708\n",
      "0.8205290653062874 0.9178902864566942 1.682910145585661 0.8650352027477166 1.0236605059347932 1.9158079132404613 1.0392727553626093 1.256165208608351 0.9871642420608661 0.9653175395907178 \n",
      "iteration = 5 11.338505444329593\n",
      "0.8747616203159629 1.0190017239944038 1.0300683785250915 1.021072312518229 1.549591450017597 2.141431453232493 0.9335725941594266 1.2357023527209474 0.9230471133812511 0.9719450582575739 \n",
      "iteration = 6 11.539022547932268\n",
      "0.8747616203159629 1.0190017239944038 1.0300683785250915 1.021072312518229 1.549591450017597 2.141431453232493 0.9335725941594266 1.2357023527209474 0.9230471133812511 0.9719450582575739 \n",
      "iteration = 7 11.539022547932268\n",
      "0.8747616203159629 1.0190017239944038 1.0300683785250915 1.021072312518229 1.549591450017597 2.141431453232493 0.9335725941594266 1.2357023527209474 0.9230471133812511 0.9719450582575739 \n",
      "iteration = 8 11.539022547932268\n",
      "0.8747616203159629 1.0190017239944038 1.0300683785250915 1.021072312518229 1.549591450017597 2.141431453232493 0.9335725941594266 1.2357023527209474 0.9230471133812511 0.9719450582575739 \n",
      "iteration = 9 11.539022547932268\n",
      "0.9486323626593197 1.3239479493207715 1.200772496261811 0.821322555965281 1.0881523397881454 2.06532683305027 1.1142893606128579 0.9126764352744469 1.1298147428939942 1.13167013848596 \n",
      "iteration = 10 11.633094919177639\n",
      "0.9486323626593197 1.3239479493207715 1.200772496261811 0.821322555965281 1.0881523397881454 2.06532683305027 1.1142893606128579 0.9126764352744469 1.1298147428939942 1.13167013848596 \n",
      "iteration = 11 11.633094919177639\n",
      "0.8284410726677073 1.0144861014048188 1.6386818741167177 0.926665532586951 1.2027411476644976 2.1073925003400324 0.9306449999305861 1.1489699105909772 1.0286684526008836 1.06061794189698 \n",
      "iteration = 12 11.774052815468856\n",
      "0.8284410726677073 1.0144861014048188 1.6386818741167177 0.926665532586951 1.2027411476644976 2.1073925003400324 0.9306449999305861 1.1489699105909772 1.0286684526008836 1.06061794189698 \n",
      "iteration = 13 11.774052815468856\n",
      "0.8284410726677073 1.0144861014048188 1.6386818741167177 0.926665532586951 1.2027411476644976 2.1073925003400324 0.9306449999305861 1.1489699105909772 1.0286684526008836 1.06061794189698 \n",
      "iteration = 14 11.774052815468856\n",
      "0.8284410726677073 1.0144861014048188 1.6386818741167177 0.926665532586951 1.2027411476644976 2.1073925003400324 0.9306449999305861 1.1489699105909772 1.0286684526008836 1.06061794189698 \n",
      "iteration = 15 11.774052815468856\n",
      "0.8284410726677073 1.0144861014048188 1.6386818741167177 0.926665532586951 1.2027411476644976 2.1073925003400324 0.9306449999305861 1.1489699105909772 1.0286684526008836 1.06061794189698 \n",
      "iteration = 16 11.774052815468856\n",
      "0.870840663049605 1.1107900264646997 1.389439880421407 0.9473888706330139 1.1853997408768326 2.2356194880825497 1.0000049486601708 1.0708500192358965 1.0590569327776884 1.0928215422169356 \n",
      "iteration = 17 11.84999812773992\n",
      "1.0110381960145125 0.8089856342075898 1.5174126070544267 0.9033097440132031 1.5344021933569654 2.348747116903737 0.9012186528126851 0.9822212791602123 0.9950132444580794 1.0245816170360154 \n",
      "iteration = 18 11.894948353618815\n",
      "1.0110381960145125 0.8089856342075898 1.5174126070544267 0.9033097440132031 1.5344021933569654 2.348747116903737 0.9012186528126851 0.9822212791602123 0.9950132444580794 1.0245816170360154 \n",
      "iteration = 19 11.894948353618815\n",
      "0.9457168485184978 0.9130595419293702 1.5244917913663958 0.9311558364548861 1.386730733550944 2.373273230443898 0.9332210146527068 1.0874681743737526 0.9558356421879386 1.011873033062248 \n",
      "iteration = 20 11.94493799503813\n",
      "0.9458871768826953 0.8673275639211978 1.6516317446806847 0.8913025370031129 1.4170141755142203 2.417399800017628 0.9615485736805927 1.0416008748943852 0.8955078992663492 0.9998683811429665 \n",
      "iteration = 21 11.973390283908229\n",
      "0.9458871768826953 0.8673275639211978 1.6516317446806847 0.8913025370031129 1.4170141755142203 2.417399800017628 0.9615485736805927 1.0416008748943852 0.8955078992663492 0.9998683811429665 \n",
      "iteration = 22 11.973390283908229\n",
      "0.9436477343976507 0.9205293523921495 1.5086077038156873 0.893704632309361 1.3697764928029055 2.4684566543102133 0.9982580028514568 1.0808976499157295 0.9178157914816408 0.9986579226181006 \n",
      "iteration = 23 11.989029811870099\n",
      "0.9436477343976507 0.9205293523921495 1.5086077038156873 0.893704632309361 1.3697764928029055 2.4684566543102133 0.9982580028514568 1.0808976499157295 0.9178157914816408 0.9986579226181006 \n",
      "iteration = 24 11.989029811870099\n",
      "0.9436477343976507 0.9205293523921495 1.5086077038156873 0.893704632309361 1.3697764928029055 2.4684566543102133 0.9982580028514568 1.0808976499157295 0.9178157914816408 0.9986579226181006 \n",
      "iteration = 25 11.989029811870099\n",
      "0.9436477343976507 0.9205293523921495 1.5086077038156873 0.893704632309361 1.3697764928029055 2.4684566543102133 0.9982580028514568 1.0808976499157295 0.9178157914816408 0.9986579226181006 \n",
      "iteration = 26 11.989029811870099\n",
      "0.9236814560242776 0.907168168016388 1.4303935439299882 0.9989325623845833 1.3957667724645295 2.753758160414704 0.9003189164056206 1.0405744262144268 1.000635410717501 1.0488325459914785 \n",
      "iteration = 27 12.285444459112849\n",
      "0.9236814560242776 0.907168168016388 1.4303935439299882 0.9989325623845833 1.3957667724645295 2.753758160414704 0.9003189164056206 1.0405744262144268 1.000635410717501 1.0488325459914785 \n",
      "iteration = 28 12.285444459112849\n",
      "1.0280062664105118 0.9589645901653133 1.6023929836954487 0.8438631690292597 1.492909860084303 2.40993679376115 1.095563440221327 1.0201798297301883 0.8230657807563501 1.1389970504781355 \n",
      "iteration = 29 12.295943051594369\n",
      "1.0280062664105118 0.9589645901653133 1.6023929836954487 0.8438631690292597 1.492909860084303 2.40993679376115 1.095563440221327 1.0201798297301883 0.8230657807563501 1.1389970504781355 \n",
      "iteration = 30 12.295943051594369\n",
      "1.0280062664105118 0.9589645901653133 1.6023929836954487 0.8438631690292597 1.492909860084303 2.40993679376115 1.095563440221327 1.0201798297301883 0.8230657807563501 1.1389970504781355 \n",
      "iteration = 31 12.295943051594369\n",
      "0.9441006210078803 0.961807300356016 1.4202653917882007 1.039231636434554 1.3608585827346062 2.7723519869366435 1.0272432333858974 1.0268156349165227 0.9335121576214391 0.9826713594291048 \n",
      "iteration = 32 12.336897060264654\n",
      "0.9410634622177039 0.9528144974165796 1.4976257719013741 0.9181737063517343 1.3840426184628232 2.8247199287315095 0.9747402174208732 1.040065675869858 0.9726571139292357 1.0487438421943909 \n",
      "iteration = 33 12.438875333776165\n",
      "0.9410634622177039 0.9528144974165796 1.4976257719013741 0.9181737063517343 1.3840426184628232 2.8247199287315095 0.9747402174208732 1.040065675869858 0.9726571139292357 1.0487438421943909 \n",
      "iteration = 34 12.438875333776165\n",
      "0.9410634622177039 0.9528144974165796 1.4976257719013741 0.9181737063517343 1.3840426184628232 2.8247199287315095 0.9747402174208732 1.040065675869858 0.9726571139292357 1.0487438421943909 \n",
      "iteration = 35 12.438875333776165\n",
      "0.9410634622177039 0.9528144974165796 1.4976257719013741 0.9181737063517343 1.3840426184628232 2.8247199287315095 0.9747402174208732 1.040065675869858 0.9726571139292357 1.0487438421943909 \n",
      "iteration = 36 12.438875333776165\n",
      "0.9410634622177039 0.9528144974165796 1.4976257719013741 0.9181737063517343 1.3840426184628232 2.8247199287315095 0.9747402174208732 1.040065675869858 0.9726571139292357 1.0487438421943909 \n",
      "iteration = 37 12.438875333776165\n",
      "0.9410634622177039 0.9528144974165796 1.4976257719013741 0.9181737063517343 1.3840426184628232 2.8247199287315095 0.9747402174208732 1.040065675869858 0.9726571139292357 1.0487438421943909 \n",
      "iteration = 38 12.438875333776165\n",
      "0.9410634622177039 0.9528144974165796 1.4976257719013741 0.9181737063517343 1.3840426184628232 2.8247199287315095 0.9747402174208732 1.040065675869858 0.9726571139292357 1.0487438421943909 \n",
      "iteration = 39 12.438875333776165\n",
      "0.9410634622177039 0.9528144974165796 1.4976257719013741 0.9181737063517343 1.3840426184628232 2.8247199287315095 0.9747402174208732 1.040065675869858 0.9726571139292357 1.0487438421943909 \n",
      "iteration = 40 12.438875333776165\n",
      "0.9410634622177039 0.9528144974165796 1.4976257719013741 0.9181737063517343 1.3840426184628232 2.8247199287315095 0.9747402174208732 1.040065675869858 0.9726571139292357 1.0487438421943909 \n",
      "iteration = 41 12.438875333776165\n",
      "0.9410634622177039 0.9528144974165796 1.4976257719013741 0.9181737063517343 1.3840426184628232 2.8247199287315095 0.9747402174208732 1.040065675869858 0.9726571139292357 1.0487438421943909 \n",
      "iteration = 42 12.438875333776165\n",
      "0.9410634622177039 0.9528144974165796 1.4976257719013741 0.9181737063517343 1.3840426184628232 2.8247199287315095 0.9747402174208732 1.040065675869858 0.9726571139292357 1.0487438421943909 \n",
      "iteration = 43 12.438875333776165\n",
      "0.9410634622177039 0.9528144974165796 1.4976257719013741 0.9181737063517343 1.3840426184628232 2.8247199287315095 0.9747402174208732 1.040065675869858 0.9726571139292357 1.0487438421943909 \n",
      "iteration = 44 12.438875333776165\n",
      "0.8561562463877403 1.0410752940051196 1.5946640137425587 0.8963659433672864 1.3327154805515364 2.697090610489101 0.9824789356568814 1.156691080889585 0.9952204704727348 1.0361362891008394 \n",
      "iteration = 45 12.475169888768749\n",
      "0.8417608389396003 1.0142891010276895 1.6736321823403906 0.9511040123923439 1.3856362345508615 2.632365377943591 1.006755009295008 1.190830766289776 0.9248951321498077 1.043026119003939 \n",
      "iteration = 46 12.54597834723097\n",
      "0.8417608389396003 1.0142891010276895 1.6736321823403906 0.9511040123923439 1.3856362345508615 2.632365377943591 1.006755009295008 1.190830766289776 0.9248951321498077 1.043026119003939 \n",
      "iteration = 47 12.54597834723097\n",
      "0.8417608389396003 1.0142891010276895 1.6736321823403906 0.9511040123923439 1.3856362345508615 2.632365377943591 1.006755009295008 1.190830766289776 0.9248951321498077 1.043026119003939 \n",
      "iteration = 48 12.54597834723097\n",
      "0.8417608389396003 1.0142891010276895 1.6736321823403906 0.9511040123923439 1.3856362345508615 2.632365377943591 1.006755009295008 1.190830766289776 0.9248951321498077 1.043026119003939 \n",
      "iteration = 49 12.54597834723097\n",
      "0.8417608389396003 1.0142891010276895 1.6736321823403906 0.9511040123923439 1.3856362345508615 2.632365377943591 1.006755009295008 1.190830766289776 0.9248951321498077 1.043026119003939 \n",
      "iteration = 50 12.54597834723097\n",
      "0.8417608389396003 1.0142891010276895 1.6736321823403906 0.9511040123923439 1.3856362345508615 2.632365377943591 1.006755009295008 1.190830766289776 0.9248951321498077 1.043026119003939 \n",
      "iteration = 51 12.54597834723097\n",
      "0.8723953762170277 1.017592339186906 1.621819681659228 0.9520570095648309 1.3688474398719268 2.7128633892318743 0.9500395788922595 1.1986957800413187 0.9332375889488854 1.0589240687610528 \n",
      "iteration = 52 12.571274591059735\n",
      "0.8723953762170277 1.017592339186906 1.621819681659228 0.9520570095648309 1.3688474398719268 2.7128633892318743 0.9500395788922595 1.1986957800413187 0.9332375889488854 1.0589240687610528 \n",
      "iteration = 53 12.571274591059735\n",
      "0.8723953762170277 1.017592339186906 1.621819681659228 0.9520570095648309 1.3688474398719268 2.7128633892318743 0.9500395788922595 1.1986957800413187 0.9332375889488854 1.0589240687610528 \n",
      "iteration = 54 12.571274591059735\n",
      "0.8723953762170277 1.017592339186906 1.621819681659228 0.9520570095648309 1.3688474398719268 2.7128633892318743 0.9500395788922595 1.1986957800413187 0.9332375889488854 1.0589240687610528 \n",
      "iteration = 55 12.571274591059735\n",
      "0.8808095540996377 1.0151537870825231 1.6096334413283782 0.9583567198537805 1.3654437826073371 2.740721098124303 0.9315048766170623 1.2071578356658463 0.9178105378441515 1.0627178167965965 \n",
      "iteration = 56 12.574790485505003\n",
      "0.8653802064271313 1.0314082322564684 1.633088770787278 0.9709041729907038 1.3579147045019988 2.704161818442485 0.9403884069311073 1.205608621247225 0.9399842909521117 1.0585617506299243 \n",
      "iteration = 57 12.591918284221762\n",
      "0.8653802064271313 1.0314082322564684 1.633088770787278 0.9709041729907038 1.3579147045019988 2.704161818442485 0.9403884069311073 1.205608621247225 0.9399842909521117 1.0585617506299243 \n",
      "iteration = 58 12.591918284221762\n",
      "0.8653802064271313 1.0314082322564684 1.633088770787278 0.9709041729907038 1.3579147045019988 2.704161818442485 0.9403884069311073 1.205608621247225 0.9399842909521117 1.0585617506299243 \n",
      "iteration = 59 12.591918284221762\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 60 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 61 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 62 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 63 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 64 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 65 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 66 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 67 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 68 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 69 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 70 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 71 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 72 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 73 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 74 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 75 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 76 12.779854430963534\n",
      "0.9108636099553473 0.9884975986227637 1.6355340619505665 1.1272708209477815 1.425857384626081 2.671594286119003 0.8120436075362013 1.183231405365683 1.1292146901659517 1.0139948130151302 \n",
      "iteration = 77 12.779854430963534\n",
      "0.9062955977966478 0.9951142512453592 1.6318634634082434 1.1050304890954057 1.4189537886087342 2.708440111037637 0.811484344337833 1.2014283749149655 1.094508929583419 1.0256817533142466 \n",
      "iteration = 78 12.781862151096863\n",
      "0.9062955977966478 0.9951142512453592 1.6318634634082434 1.1050304890954057 1.4189537886087342 2.708440111037637 0.811484344337833 1.2014283749149655 1.094508929583419 1.0256817533142466 \n",
      "iteration = 79 12.781862151096863\n",
      "0.9112980506518547 1.0129416803465636 1.6386363863930882 1.1281579797293542 1.426169541417753 2.671791074317415 0.8213192440951546 1.212464122097933 1.0481249535524222 1.0380896881775399 \n",
      "iteration = 80 12.790557049519721\n",
      "0.9112980506518547 1.0129416803465636 1.6386363863930882 1.1281579797293542 1.426169541417753 2.671791074317415 0.8213192440951546 1.212464122097933 1.0481249535524222 1.0380896881775399 \n",
      "iteration = 81 12.790557049519721\n",
      "0.9112980506518547 1.0129416803465636 1.6386363863930882 1.1281579797293542 1.426169541417753 2.671791074317415 0.8213192440951546 1.212464122097933 1.0481249535524222 1.0380896881775399 \n",
      "iteration = 82 12.790557049519721\n",
      "0.9112980506518547 1.0129416803465636 1.6386363863930882 1.1281579797293542 1.426169541417753 2.671791074317415 0.8213192440951546 1.212464122097933 1.0481249535524222 1.0380896881775399 \n",
      "iteration = 83 12.790557049519721\n",
      "0.9114481385641201 1.0083878802686121 1.6377402282247862 1.1262160367895442 1.4261341009014994 2.679852831688662 0.8135078599346911 1.2073337475766772 1.0692565448388267 1.0335576574945329 \n",
      "iteration = 84 12.795668662958931\n",
      "0.9114481385641201 1.0083878802686121 1.6377402282247862 1.1262160367895442 1.4261341009014994 2.679852831688662 0.8135078599346911 1.2073337475766772 1.0692565448388267 1.0335576574945329 \n",
      "iteration = 85 12.795668662958931\n",
      "0.9114481385641201 1.0083878802686121 1.6377402282247862 1.1262160367895442 1.4261341009014994 2.679852831688662 0.8135078599346911 1.2073337475766772 1.0692565448388267 1.0335576574945329 \n",
      "iteration = 86 12.795668662958931\n",
      "0.9114481385641201 1.0083878802686121 1.6377402282247862 1.1262160367895442 1.4261341009014994 2.679852831688662 0.8135078599346911 1.2073337475766772 1.0692565448388267 1.0335576574945329 \n",
      "iteration = 87 12.795668662958931\n",
      "0.9114481385641201 1.0083878802686121 1.6377402282247862 1.1262160367895442 1.4261341009014994 2.679852831688662 0.8135078599346911 1.2073337475766772 1.0692565448388267 1.0335576574945329 \n",
      "iteration = 88 12.795668662958931\n",
      "0.9114481385641201 1.0083878802686121 1.6377402282247862 1.1262160367895442 1.4261341009014994 2.679852831688662 0.8135078599346911 1.2073337475766772 1.0692565448388267 1.0335576574945329 \n",
      "iteration = 89 12.795668662958931\n",
      "0.8380218520904567 1.1626021889739484 1.630553053491141 1.110490072543419 1.4477041584810222 2.6709738727108205 0.848363227472489 1.2863979445969584 1.052845219739919 0.9808603779027623 \n",
      "iteration = 90 12.909171122572065\n",
      "0.8380218520904567 1.1626021889739484 1.630553053491141 1.110490072543419 1.4477041584810222 2.6709738727108205 0.848363227472489 1.2863979445969584 1.052845219739919 0.9808603779027623 \n",
      "iteration = 91 12.909171122572065\n",
      "0.8380218520904567 1.1626021889739484 1.630553053491141 1.110490072543419 1.4477041584810222 2.6709738727108205 0.848363227472489 1.2863979445969584 1.052845219739919 0.9808603779027623 \n",
      "iteration = 92 12.909171122572065\n",
      "0.8380218520904567 1.1626021889739484 1.630553053491141 1.110490072543419 1.4477041584810222 2.6709738727108205 0.848363227472489 1.2863979445969584 1.052845219739919 0.9808603779027623 \n",
      "iteration = 93 12.909171122572065\n",
      "0.8380218520904567 1.1626021889739484 1.630553053491141 1.110490072543419 1.4477041584810222 2.6709738727108205 0.848363227472489 1.2863979445969584 1.052845219739919 0.9808603779027623 \n",
      "iteration = 94 12.909171122572065\n",
      "0.8380218520904567 1.1626021889739484 1.630553053491141 1.110490072543419 1.4477041584810222 2.6709738727108205 0.848363227472489 1.2863979445969584 1.052845219739919 0.9808603779027623 \n",
      "iteration = 95 12.909171122572065\n",
      "0.8323835299532087 1.1258071565279197 1.6594268954697082 1.1154765065599033 1.4470473793764727 2.679868484601949 0.8412388000841718 1.266073374520301 1.0601823945297963 1.0073625091911522 \n",
      "iteration = 96 12.917092921520183\n",
      "0.8323835299532087 1.1258071565279197 1.6594268954697082 1.1154765065599033 1.4470473793764727 2.679868484601949 0.8412388000841718 1.266073374520301 1.0601823945297963 1.0073625091911522 \n",
      "iteration = 97 12.917092921520183\n",
      "0.8823220064230627 0.9928287634036531 1.5041539935189 1.2239881226394698 1.4299726287949446 2.990938497630597 0.8973093505096005 1.14640221799513 1.055962258762363 0.9791306185405672 \n",
      "iteration = 98 12.982100084827461\n",
      "0.8709493795686849 1.0363175424743696 1.59774502684135 1.1741614344498237 1.4667468096712422 3.0157021985571815 0.8671385428048425 1.2221339406754446 1.062535794617973 1.0068004145525484 \n",
      "iteration = 99 13.202055787418152\n",
      "0.8709493795686849 1.0363175424743696 1.59774502684135 1.1741614344498237 1.4667468096712422 3.0157021985571815 0.8671385428048425 1.2221339406754446 1.062535794617973 1.0068004145525484 \n",
      "iteration = 100 13.202055787418152\n",
      "0.8709493795686849 1.0363175424743696 1.59774502684135 1.1741614344498237 1.4667468096712422 3.0157021985571815 0.8671385428048425 1.2221339406754446 1.062535794617973 1.0068004145525484 \n",
      "iteration = 101 13.202055787418152\n",
      "0.8727800758999893 1.030957350966184 1.5877720168208387 1.1845008661448344 1.4665815049349709 3.032751801735586 0.8698065475655564 1.215121954887746 1.0630431788002515 1.0037236825197444 \n",
      "iteration = 102 13.208599417006486\n",
      "0.8623865699297918 1.0480624955741678 1.6006494990088962 1.1770632206362575 1.4702177464759316 3.0130815828625432 0.8684792104446333 1.227612366933319 1.0633413447654976 1.0042108309139142 \n",
      "iteration = 103 13.216852912214206\n",
      "0.8623865699297918 1.0480624955741678 1.6006494990088962 1.1770632206362575 1.4702177464759316 3.0130815828625432 0.8684792104446333 1.227612366933319 1.0633413447654976 1.0042108309139142 \n",
      "iteration = 104 13.216852912214206\n",
      "0.8615691917762464 1.0417868117757265 1.6108848710276096 1.291651147201908 1.4616781490429225 3.0739795224715385 0.8653208249973882 1.189657730860658 0.9745093979027156 1.017132657276297 \n",
      "iteration = 105 13.274297507857794\n",
      "0.8615691917762464 1.0417868117757265 1.6108848710276096 1.291651147201908 1.4616781490429225 3.0739795224715385 0.8653208249973882 1.189657730860658 0.9745093979027156 1.017132657276297 \n",
      "iteration = 106 13.274297507857794\n",
      "0.8615691917762464 1.0417868117757265 1.6108848710276096 1.291651147201908 1.4616781490429225 3.0739795224715385 0.8653208249973882 1.189657730860658 0.9745093979027156 1.017132657276297 \n",
      "iteration = 107 13.274297507857794\n",
      "0.8615691917762464 1.0417868117757265 1.6108848710276096 1.291651147201908 1.4616781490429225 3.0739795224715385 0.8653208249973882 1.189657730860658 0.9745093979027156 1.017132657276297 \n",
      "iteration = 108 13.274297507857794\n",
      "0.8615691917762464 1.0417868117757265 1.6108848710276096 1.291651147201908 1.4616781490429225 3.0739795224715385 0.8653208249973882 1.189657730860658 0.9745093979027156 1.017132657276297 \n",
      "iteration = 109 13.274297507857794\n",
      "0.8615691917762464 1.0417868117757265 1.6108848710276096 1.291651147201908 1.4616781490429225 3.0739795224715385 0.8653208249973882 1.189657730860658 0.9745093979027156 1.017132657276297 \n",
      "iteration = 110 13.274297507857794\n",
      "0.8593888727701681 1.0554331853003296 1.6237510365811727 1.2677386488826594 1.466094062047574 3.060189415969518 0.8585867440951283 1.2152301561776808 0.9823389847496539 1.0182760188879398 \n",
      "iteration = 111 13.293149668978344\n",
      "0.8593888727701681 1.0554331853003296 1.6237510365811727 1.2677386488826594 1.466094062047574 3.060189415969518 0.8585867440951283 1.2152301561776808 0.9823389847496539 1.0182760188879398 \n",
      "iteration = 112 13.293149668978344\n",
      "0.8593888727701681 1.0554331853003296 1.6237510365811727 1.2677386488826594 1.466094062047574 3.060189415969518 0.8585867440951283 1.2152301561776808 0.9823389847496539 1.0182760188879398 \n",
      "iteration = 113 13.293149668978344\n",
      "0.8762737684095946 1.0371660229191053 1.6075382184655356 1.1816425088589073 1.4652413981308718 3.1346550581524593 0.848897613366479 1.3057445698566224 1.0101827468416056 1.031269638411455 \n",
      "iteration = 114 13.382346627640883\n",
      "0.878214820896526 0.9626234309839002 1.6174065139956735 1.1973398713134256 1.5069154631086163 3.1300304812726805 0.8546949251070849 1.306750227106772 1.0180245647914146 1.0273632884950852 \n",
      "iteration = 115 13.38453089007139\n",
      "0.878214820896526 0.9626234309839002 1.6174065139956735 1.1973398713134256 1.5069154631086163 3.1300304812726805 0.8546949251070849 1.306750227106772 1.0180245647914146 1.0273632884950852 \n",
      "iteration = 116 13.38453089007139\n",
      "0.878214820896526 0.9626234309839002 1.6174065139956735 1.1973398713134256 1.5069154631086163 3.1300304812726805 0.8546949251070849 1.306750227106772 1.0180245647914146 1.0273632884950852 \n",
      "iteration = 117 13.38453089007139\n",
      "0.878214820896526 0.9626234309839002 1.6174065139956735 1.1973398713134256 1.5069154631086163 3.1300304812726805 0.8546949251070849 1.306750227106772 1.0180245647914146 1.0273632884950852 \n",
      "iteration = 118 13.38453089007139\n",
      "0.8793718842738149 0.9603871334644905 1.61690307188644 1.2117332893242052 1.5062166715938103 3.147824264714755 0.8547134545152995 1.301617384504613 1.0068534274757828 1.0287095811662708 \n",
      "iteration = 119 13.400040941609365\n",
      "0.8793369441947205 0.9585135269770478 1.613598551305803 1.2213405936115103 1.5063917818840618 3.168157949159678 0.8568665270628265 1.2953794129115819 1.001894495745835 1.02822377126321 \n",
      "iteration = 120 13.41561916462322\n",
      "0.8793369441947205 0.9585135269770478 1.613598551305803 1.2213405936115103 1.5063917818840618 3.168157949159678 0.8568665270628265 1.2953794129115819 1.001894495745835 1.02822377126321 \n",
      "iteration = 121 13.41561916462322\n",
      "0.8804765985791443 0.964684831849679 1.6140888293414035 1.2059724969549928 1.5028243144353781 3.161647695228744 0.8536834489797365 1.3100101157445325 1.0064601656795826 1.0302892138243043 \n",
      "iteration = 122 13.415645207183239\n",
      "0.8788003714588228 0.9575812159977054 1.611109925088572 1.1966505849479023 1.5090419897892453 3.1903734219491384 0.8712403395653184 1.2978425571074246 1.0105183851710504 1.027529491368289 \n",
      "iteration = 123 13.436899705129976\n",
      "0.8788003714588228 0.9575812159977054 1.611109925088572 1.1966505849479023 1.5090419897892453 3.1903734219491384 0.8712403395653184 1.2978425571074246 1.0105183851710504 1.027529491368289 \n",
      "iteration = 124 13.436899705129976\n",
      "0.8788003714588228 0.9575812159977054 1.611109925088572 1.1966505849479023 1.5090419897892453 3.1903734219491384 0.8712403395653184 1.2978425571074246 1.0105183851710504 1.027529491368289 \n",
      "iteration = 125 13.436899705129976\n",
      "0.8788003714588228 0.9575812159977054 1.611109925088572 1.1966505849479023 1.5090419897892453 3.1903734219491384 0.8712403395653184 1.2978425571074246 1.0105183851710504 1.027529491368289 \n",
      "iteration = 126 13.436899705129976\n",
      "1.0688700604873436 0.978075972972555 1.2860198903173004 1.2117835135619786 1.5312790796907596 3.2396270007326033 0.9118277466152351 1.2869940585555708 0.983349690525875 1.1503650317850822 \n",
      "iteration = 127 13.534485633697148\n",
      "1.0688700604873436 0.978075972972555 1.2860198903173004 1.2117835135619786 1.5312790796907596 3.2396270007326033 0.9118277466152351 1.2869940585555708 0.983349690525875 1.1503650317850822 \n",
      "iteration = 128 13.534485633697148\n",
      "1.0688700604873436 0.978075972972555 1.2860198903173004 1.2117835135619786 1.5312790796907596 3.2396270007326033 0.9118277466152351 1.2869940585555708 0.983349690525875 1.1503650317850822 \n",
      "iteration = 129 13.534485633697148\n",
      "1.0688700604873436 0.978075972972555 1.2860198903173004 1.2117835135619786 1.5312790796907596 3.2396270007326033 0.9118277466152351 1.2869940585555708 0.983349690525875 1.1503650317850822 \n",
      "iteration = 130 13.534485633697148\n",
      "1.0688700604873436 0.978075972972555 1.2860198903173004 1.2117835135619786 1.5312790796907596 3.2396270007326033 0.9118277466152351 1.2869940585555708 0.983349690525875 1.1503650317850822 \n",
      "iteration = 131 13.534485633697148\n",
      "1.0688700604873436 0.978075972972555 1.2860198903173004 1.2117835135619786 1.5312790796907596 3.2396270007326033 0.9118277466152351 1.2869940585555708 0.983349690525875 1.1503650317850822 \n",
      "iteration = 132 13.534485633697148\n",
      "1.0688700604873436 0.978075972972555 1.2860198903173004 1.2117835135619786 1.5312790796907596 3.2396270007326033 0.9118277466152351 1.2869940585555708 0.983349690525875 1.1503650317850822 \n",
      "iteration = 133 13.534485633697148\n",
      "1.0688700604873436 0.978075972972555 1.2860198903173004 1.2117835135619786 1.5312790796907596 3.2396270007326033 0.9118277466152351 1.2869940585555708 0.983349690525875 1.1503650317850822 \n",
      "iteration = 134 13.534485633697148\n",
      "1.004089318425983 0.9756056265627002 1.403259038184303 1.2179946138723492 1.5306028275341381 3.2193973101966167 0.8984105570957432 1.2883774329963147 0.9935040008398347 1.117152605347342 \n",
      "iteration = 135 13.534659738489438\n",
      "1.0112467017150994 0.9755195066993012 1.3913026487175153 1.2180834698009129 1.531264472431306 3.2228703665037837 0.8995499140837578 1.2891505137305987 0.9922447305897529 1.1213846348600878 \n",
      "iteration = 136 13.538891876939353\n",
      "1.0112467017150994 0.9755195066993012 1.3913026487175153 1.2180834698009129 1.531264472431306 3.2228703665037837 0.8995499140837578 1.2891505137305987 0.9922447305897529 1.1213846348600878 \n",
      "iteration = 137 13.538891876939353\n",
      "1.0112467017150994 0.9755195066993012 1.3913026487175153 1.2180834698009129 1.531264472431306 3.2228703665037837 0.8995499140837578 1.2891505137305987 0.9922447305897529 1.1213846348600878 \n",
      "iteration = 138 13.538891876939353\n",
      "1.0112467017150994 0.9755195066993012 1.3913026487175153 1.2180834698009129 1.531264472431306 3.2228703665037837 0.8995499140837578 1.2891505137305987 0.9922447305897529 1.1213846348600878 \n",
      "iteration = 139 13.538891876939353\n",
      "1.0112467017150994 0.9755195066993012 1.3913026487175153 1.2180834698009129 1.531264472431306 3.2228703665037837 0.8995499140837578 1.2891505137305987 0.9922447305897529 1.1213846348600878 \n",
      "iteration = 140 13.538891876939353\n",
      "1.0292342514553119 0.976424481235043 1.3597368185570264 1.2168489061554655 1.5322525098261561 3.2298835481818835 0.9038139830395793 1.2886944052896339 0.9896952844771144 1.1313351853361875 \n",
      "iteration = 141 13.544218126617356\n",
      "1.0371941462606433 0.9786744833447394 1.2350875595209507 1.2169293604316833 1.5429870836685284 3.399110635525973 0.9057027316619182 1.3025828746336456 0.9766566048695228 1.1277442982291794 \n",
      "iteration = 142 13.607536420114632\n",
      "1.0184825890362104 0.9789879681986051 1.3288959245147074 1.2264188763399644 1.5372406286500813 3.3632424045597094 0.9023168178899897 1.2969032425117997 0.9871384741641116 1.1185198938906697 \n",
      "iteration = 143 13.64371098422471\n",
      "1.0221829628777221 0.9791982389242044 1.3086536107494735 1.2261571286623583 1.538832859919865 3.3845571551894764 0.9029385265143817 1.29868626440985 0.9848060587018265 1.119548192259372 \n",
      "iteration = 144 13.650948996097625\n",
      "1.0221829628777221 0.9791982389242044 1.3086536107494735 1.2261571286623583 1.538832859919865 3.3845571551894764 0.9029385265143817 1.29868626440985 0.9848060587018265 1.119548192259372 \n",
      "iteration = 145 13.650948996097625\n",
      "1.0221829628777221 0.9791982389242044 1.3086536107494735 1.2261571286623583 1.538832859919865 3.3845571551894764 0.9029385265143817 1.29868626440985 0.9848060587018265 1.119548192259372 \n",
      "iteration = 146 13.650948996097625\n",
      "1.0221829628777221 0.9791982389242044 1.3086536107494735 1.2261571286623583 1.538832859919865 3.3845571551894764 0.9029385265143817 1.29868626440985 0.9848060587018265 1.119548192259372 \n",
      "iteration = 147 13.650948996097625\n",
      "1.0221829628777221 0.9791982389242044 1.3086536107494735 1.2261571286623583 1.538832859919865 3.3845571551894764 0.9029385265143817 1.29868626440985 0.9848060587018265 1.119548192259372 \n",
      "iteration = 148 13.650948996097625\n",
      "1.0315702276175611 0.9766227042021639 1.3531447743302245 1.219043830103708 1.4724169374196288 3.452552095043435 0.9305622974129794 1.2973044113298904 0.9917002520851474 1.046013893392784 \n",
      "iteration = 149 13.657202866527635\n",
      "1.0315702276175611 0.9766227042021639 1.3531447743302245 1.219043830103708 1.4724169374196288 3.452552095043435 0.9305622974129794 1.2973044113298904 0.9917002520851474 1.046013893392784 \n",
      "iteration = 150 13.657202866527635\n",
      "1.0372665034268647 0.9770396346894321 1.3334222636557527 1.2198015524404182 1.473879179040936 3.4829585028688697 0.9318939500703424 1.2993069751775226 0.9899739999890635 1.0479302854361792 \n",
      "iteration = 151 13.679607151053585\n",
      "1.034839690714039 0.9783482973150246 1.308662713287024 1.2235437891385992 1.5080012008341201 3.4580003484147763 0.9188685492040363 1.3002797505852015 0.9866061720310282 1.0841821241496084 \n",
      "iteration = 152 13.687484188579967\n",
      "1.0424470059423427 0.9775028914612667 1.3150367372943508 1.2200675724406 1.4750517053836112 3.505368100532421 0.9331041716415858 1.300596521955901 0.9882309672329872 1.0498988407709646 \n",
      "iteration = 153 13.693318096524141\n",
      "1.0424470059423427 0.9775028914612667 1.3150367372943508 1.2200675724406 1.4750517053836112 3.505368100532421 0.9331041716415858 1.300596521955901 0.9882309672329872 1.0498988407709646 \n",
      "iteration = 154 13.693318096524141\n",
      "1.0424470059423427 0.9775028914612667 1.3150367372943508 1.2200675724406 1.4750517053836112 3.505368100532421 0.9331041716415858 1.300596521955901 0.9882309672329872 1.0498988407709646 \n",
      "iteration = 155 13.693318096524141\n",
      "1.0424470059423427 0.9775028914612667 1.3150367372943508 1.2200675724406 1.4750517053836112 3.505368100532421 0.9331041716415858 1.300596521955901 0.9882309672329872 1.0498988407709646 \n",
      "iteration = 156 13.693318096524141\n",
      "1.0424470059423427 0.9775028914612667 1.3150367372943508 1.2200675724406 1.4750517053836112 3.505368100532421 0.9331041716415858 1.300596521955901 0.9882309672329872 1.0498988407709646 \n",
      "iteration = 157 13.693318096524141\n",
      "0.9887719957745424 1.0704452389127956 1.3341497475780686 1.1263361721340925 1.3630227746046173 3.708476408117926 0.9222244419662263 1.3266401374823433 0.9115906839899505 1.0693455201604032 \n",
      "iteration = 158 13.703230270162514\n",
      "1.0112614178640829 1.0434030282038569 1.3349703230420598 1.1731374486876394 1.451432277618742 3.5992741215282744 0.9234029862440117 1.3380326290050801 0.9557982212402554 1.070358881212703 \n",
      "iteration = 159 13.785373300329312\n",
      "1.0121786963335884 1.043808922270127 1.3229522233722013 1.1737694875256441 1.4582125747413033 3.6006894856365124 0.9210063610284086 1.3387969586560688 0.9545189389105433 1.0785801227601552 \n",
      "iteration = 160 13.788763997235087\n",
      "1.0551876772797921 0.9939666566608949 1.3350740664264962 1.183145030771511 1.4880846677969837 3.604920090065699 0.932553567690662 1.3623221317418486 1.0666350410891874 0.9454705719138765 \n",
      "iteration = 161 13.850162388250025\n",
      "1.0406879503399322 1.0071875422776504 1.3363746741183515 1.1929126768634295 1.4915415096611655 3.5978576695690303 0.927930248371209 1.3538632604521443 1.0238986418304954 0.9964102922952677 \n",
      "iteration = 162 13.85279468532209\n",
      "1.0414473491392227 1.031410561906688 1.3430623422755144 1.1618178762661016 1.4812172537611508 3.6939114208680994 0.9266604188396911 1.3903710773912406 1.0496072533605352 0.9496548258375244 \n",
      "iteration = 163 13.951111144286003\n",
      "1.0414473491392227 1.031410561906688 1.3430623422755144 1.1618178762661016 1.4812172537611508 3.6939114208680994 0.9266604188396911 1.3903710773912406 1.0496072533605352 0.9496548258375244 \n",
      "iteration = 164 13.951111144286003\n",
      "1.0414473491392227 1.031410561906688 1.3430623422755144 1.1618178762661016 1.4812172537611508 3.6939114208680994 0.9266604188396911 1.3903710773912406 1.0496072533605352 0.9496548258375244 \n",
      "iteration = 165 13.951111144286003\n",
      "1.0414473491392227 1.031410561906688 1.3430623422755144 1.1618178762661016 1.4812172537611508 3.6939114208680994 0.9266604188396911 1.3903710773912406 1.0496072533605352 0.9496548258375244 \n",
      "iteration = 166 13.951111144286003\n",
      "1.0414473491392227 1.031410561906688 1.3430623422755144 1.1618178762661016 1.4812172537611508 3.6939114208680994 0.9266604188396911 1.3903710773912406 1.0496072533605352 0.9496548258375244 \n",
      "iteration = 167 13.951111144286003\n",
      "1.0414473491392227 1.031410561906688 1.3430623422755144 1.1618178762661016 1.4812172537611508 3.6939114208680994 0.9266604188396911 1.3903710773912406 1.0496072533605352 0.9496548258375244 \n",
      "iteration = 168 13.951111144286003\n",
      "1.0414473491392227 1.031410561906688 1.3430623422755144 1.1618178762661016 1.4812172537611508 3.6939114208680994 0.9266604188396911 1.3903710773912406 1.0496072533605352 0.9496548258375244 \n",
      "iteration = 169 13.951111144286003\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 170 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 171 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 172 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 173 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 174 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 175 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 176 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 177 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 178 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 179 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 180 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 181 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 182 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 183 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 184 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 185 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 186 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 187 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 188 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 189 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 190 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 191 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 192 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 193 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 194 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 195 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 196 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 197 14.130886348673465\n",
      "1.022728195686779 1.0249597860881958 1.3161093856199457 1.1686517926495075 1.6804041826418452 3.9213618605878358 1.0079283115649824 1.2552516555553377 1.0485682557472897 0.8033450993666114 \n",
      "iteration = 198 14.130886348673465\n",
      "0.9377765301912999 1.0421090510325701 1.7622028939468004 1.189057829075519 1.674800608873632 3.739024058437252 0.9347493326002535 1.2303776889028466 0.9568212701564914 0.8343088341258986 \n",
      "iteration = 199 14.180152926427601\n",
      "0.9903719764688701 1.040880418894932 1.5936257221670345 1.1902163466921902 1.6494282126190394 3.796660448298767 0.9249405029332634 1.2974348803900966 1.0193716018659524 0.8400312463642959 \n",
      "Initial Secrecy Rate GA: 8.698405811598715\n",
      "[np.float64(8.698405811598715), np.float64(10.24197660886312), np.float64(10.584381652068682), np.float64(10.816506909188886), np.float64(11.138319480378708), np.float64(11.338505444329593), np.float64(11.539022547932268), np.float64(11.539022547932268), np.float64(11.539022547932268), np.float64(11.539022547932268), np.float64(11.633094919177639), np.float64(11.633094919177639), np.float64(11.774052815468856), np.float64(11.774052815468856), np.float64(11.774052815468856), np.float64(11.774052815468856), np.float64(11.774052815468856), np.float64(11.84999812773992), np.float64(11.894948353618815), np.float64(11.894948353618815), np.float64(11.94493799503813), np.float64(11.973390283908229), np.float64(11.973390283908229), np.float64(11.989029811870099), np.float64(11.989029811870099), np.float64(11.989029811870099), np.float64(11.989029811870099), np.float64(12.285444459112849), np.float64(12.285444459112849), np.float64(12.295943051594369), np.float64(12.295943051594369), np.float64(12.295943051594369), np.float64(12.336897060264654), np.float64(12.438875333776165), np.float64(12.438875333776165), np.float64(12.438875333776165), np.float64(12.438875333776165), np.float64(12.438875333776165), np.float64(12.438875333776165), np.float64(12.438875333776165), np.float64(12.438875333776165), np.float64(12.438875333776165), np.float64(12.438875333776165), np.float64(12.438875333776165), np.float64(12.438875333776165), np.float64(12.475169888768749), np.float64(12.54597834723097), np.float64(12.54597834723097), np.float64(12.54597834723097), np.float64(12.54597834723097), np.float64(12.54597834723097), np.float64(12.54597834723097), np.float64(12.571274591059735), np.float64(12.571274591059735), np.float64(12.571274591059735), np.float64(12.571274591059735), np.float64(12.574790485505003), np.float64(12.591918284221762), np.float64(12.591918284221762), np.float64(12.591918284221762), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.779854430963534), np.float64(12.781862151096863), np.float64(12.781862151096863), np.float64(12.790557049519721), np.float64(12.790557049519721), np.float64(12.790557049519721), np.float64(12.790557049519721), np.float64(12.795668662958931), np.float64(12.795668662958931), np.float64(12.795668662958931), np.float64(12.795668662958931), np.float64(12.795668662958931), np.float64(12.795668662958931), np.float64(12.909171122572065), np.float64(12.909171122572065), np.float64(12.909171122572065), np.float64(12.909171122572065), np.float64(12.909171122572065), np.float64(12.909171122572065), np.float64(12.917092921520183), np.float64(12.917092921520183), np.float64(12.982100084827461), np.float64(13.202055787418152), np.float64(13.202055787418152), np.float64(13.202055787418152), np.float64(13.208599417006486), np.float64(13.216852912214206), np.float64(13.216852912214206), np.float64(13.274297507857794), np.float64(13.274297507857794), np.float64(13.274297507857794), np.float64(13.274297507857794), np.float64(13.274297507857794), np.float64(13.274297507857794), np.float64(13.293149668978344), np.float64(13.293149668978344), np.float64(13.293149668978344), np.float64(13.382346627640883), np.float64(13.38453089007139), np.float64(13.38453089007139), np.float64(13.38453089007139), np.float64(13.38453089007139), np.float64(13.400040941609365), np.float64(13.41561916462322), np.float64(13.41561916462322), np.float64(13.415645207183239), np.float64(13.436899705129976), np.float64(13.436899705129976), np.float64(13.436899705129976), np.float64(13.436899705129976), np.float64(13.534485633697148), np.float64(13.534485633697148), np.float64(13.534485633697148), np.float64(13.534485633697148), np.float64(13.534485633697148), np.float64(13.534485633697148), np.float64(13.534485633697148), np.float64(13.534485633697148), np.float64(13.534659738489438), np.float64(13.538891876939353), np.float64(13.538891876939353), np.float64(13.538891876939353), np.float64(13.538891876939353), np.float64(13.538891876939353), np.float64(13.544218126617356), np.float64(13.607536420114632), np.float64(13.64371098422471), np.float64(13.650948996097625), np.float64(13.650948996097625), np.float64(13.650948996097625), np.float64(13.650948996097625), np.float64(13.650948996097625), np.float64(13.657202866527635), np.float64(13.657202866527635), np.float64(13.679607151053585), np.float64(13.687484188579967), np.float64(13.693318096524141), np.float64(13.693318096524141), np.float64(13.693318096524141), np.float64(13.693318096524141), np.float64(13.693318096524141), np.float64(13.703230270162514), np.float64(13.785373300329312), np.float64(13.788763997235087), np.float64(13.850162388250025), np.float64(13.85279468532209), np.float64(13.951111144286003), np.float64(13.951111144286003), np.float64(13.951111144286003), np.float64(13.951111144286003), np.float64(13.951111144286003), np.float64(13.951111144286003), np.float64(13.951111144286003), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.130886348673465), np.float64(14.180152926427601), np.float64(14.226884446922732)]\n",
      "Final Secrecy Rate GA: 14.226884446922732\n"
     ]
    }
   ],
   "source": [
    "population_size = 100\n",
    "num_generations = 200\n",
    "crossover_rate = 0.9\n",
    "mutation_rate = 0.3\n",
    "\n",
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# GA Algorithm\n",
    "GA_results = GA_optimize_w_theta(population_size, num_generations, crossover_rate, mutation_rate)\n",
    "print(\"Initial Secrecy Rate GA:\", GA_results[0])\n",
    "print(GA_results)\n",
    "print(\"Final Secrecy Rate GA:\", GA_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_update_w_only(w, theta, learning_rate):\n",
    "    grad_w = compute_gradient_w(theta, w)\n",
    "    w_new = [w[i] - learning_rate * grad_w[i] for i in range (number_of_users)]\n",
    "    w_new = normalise_beamforming_vectors(w_new)\n",
    "    theta_new = theta\n",
    "\n",
    "    return w_new, theta_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of PSO and GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_GD(max_pso_iter, max_gd_iter, number_of_particles, learning_rate, w_max, w_min, c1, c2):\n",
    "    particles = [PSOParticle() for _ in range(number_of_particles)]\n",
    "    global_best_secrecy_rate = -np.inf\n",
    "    global_best_theta = np.zeros((1, Nris))\n",
    "    global_best_w = [np.zeros((N, 1)) for i in range(number_of_users)]\n",
    "\n",
    "    results_secrecy_rate = []\n",
    "\n",
    "    for particle in particles:\n",
    "        if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "            global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "            global_best_theta = deepcopy(particle.best_theta)\n",
    "            global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "    results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "    \n",
    "    for iteration in range(max_pso_iter):\n",
    "        print(\"iteration =\", iteration, \"Global Best Secrecy Rate:\", global_best_secrecy_rate)\n",
    "        inertia = dynamic_inertia(iteration, max_iter, w_max, w_min)\n",
    "\n",
    "        \"\"\"\n",
    "            Update particles theta by velocity\n",
    "        \"\"\"\n",
    "        for particle in particles:\n",
    "            particle.update_velocity(inertia, c1, c2, global_best_theta, global_best_w)\n",
    "            particle.update_position()\n",
    "            particle.update_best()\n",
    "            \n",
    "            if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "                global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "                global_best_theta = deepcopy(particle.best_theta)\n",
    "                global_best_w = deepcopy(particle.best_w)\n",
    "        \n",
    "        # GD\n",
    "        for particle in particles:\n",
    "            for _ in range (max_gd_iter):\n",
    "                new_w, new_theta = gradient_descent_update(particle.w, theta_angles_to_theta_vector(particle.theta), learning_rate)\n",
    "                new_secrecy_rate = secrecy_rate_objective_function(new_theta, new_w)\n",
    "                if (new_secrecy_rate - particle.current_secrecy_rate) < 1e-9:\n",
    "                    break\n",
    "                \n",
    "                particle.w = new_w\n",
    "                particle.theta = theta_vector_to_theta_angles(new_theta)\n",
    "                particle.current_secrecy_rate = new_secrecy_rate\n",
    "\n",
    "            particle.update_best()\n",
    "            \n",
    "            if particle.best_secrecy_rate > global_best_secrecy_rate: \n",
    "                # No need to check validity as we already checked it in the inner loop\n",
    "                global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "                global_best_theta = deepcopy(particle.best_theta)\n",
    "                global_best_w = deepcopy(particle.best_w)\n",
    "       \n",
    "        results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "    return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0 Global Best Secrecy Rate: 8.698405811598715\n",
      "iteration = 1 Global Best Secrecy Rate: 12.067198824966306\n",
      "iteration = 2 Global Best Secrecy Rate: 12.190076725703847\n",
      "iteration = 3 Global Best Secrecy Rate: 12.497654529290655\n",
      "iteration = 4 Global Best Secrecy Rate: 12.627340993186555\n",
      "iteration = 5 Global Best Secrecy Rate: 12.627340993186555\n",
      "iteration = 6 Global Best Secrecy Rate: 12.627340993186555\n",
      "iteration = 7 Global Best Secrecy Rate: 12.627340993186555\n",
      "iteration = 8 Global Best Secrecy Rate: 12.725231632204219\n",
      "iteration = 9 Global Best Secrecy Rate: 12.784422023846762\n",
      "iteration = 10 Global Best Secrecy Rate: 13.241490627175454\n",
      "iteration = 11 Global Best Secrecy Rate: 13.241490627175454\n",
      "iteration = 12 Global Best Secrecy Rate: 13.241490627175454\n",
      "iteration = 13 Global Best Secrecy Rate: 13.371067175479777\n",
      "iteration = 14 Global Best Secrecy Rate: 13.700895041285476\n",
      "iteration = 15 Global Best Secrecy Rate: 13.956900854872416\n",
      "iteration = 16 Global Best Secrecy Rate: 14.006841256755926\n",
      "iteration = 17 Global Best Secrecy Rate: 14.439172717820476\n",
      "iteration = 18 Global Best Secrecy Rate: 14.439172717820476\n",
      "iteration = 19 Global Best Secrecy Rate: 14.439172717820476\n",
      "iteration = 20 Global Best Secrecy Rate: 14.60762346586838\n",
      "iteration = 21 Global Best Secrecy Rate: 14.60762346586838\n",
      "iteration = 22 Global Best Secrecy Rate: 14.60762346586838\n",
      "iteration = 23 Global Best Secrecy Rate: 14.77335776444244\n",
      "iteration = 24 Global Best Secrecy Rate: 14.77335776444244\n",
      "iteration = 25 Global Best Secrecy Rate: 15.03049203040906\n",
      "iteration = 26 Global Best Secrecy Rate: 15.03049203040906\n",
      "iteration = 27 Global Best Secrecy Rate: 15.03049203040906\n",
      "iteration = 28 Global Best Secrecy Rate: 15.04922666116166\n",
      "iteration = 29 Global Best Secrecy Rate: 15.04922666116166\n",
      "iteration = 30 Global Best Secrecy Rate: 15.22060944071514\n",
      "iteration = 31 Global Best Secrecy Rate: 15.22060944071514\n",
      "iteration = 32 Global Best Secrecy Rate: 15.22060944071514\n",
      "iteration = 33 Global Best Secrecy Rate: 15.22060944071514\n",
      "iteration = 34 Global Best Secrecy Rate: 15.22060944071514\n",
      "iteration = 35 Global Best Secrecy Rate: 15.228477792197882\n",
      "iteration = 36 Global Best Secrecy Rate: 15.228477792197882\n",
      "iteration = 37 Global Best Secrecy Rate: 15.228477792197882\n",
      "iteration = 38 Global Best Secrecy Rate: 15.228477792197882\n",
      "iteration = 39 Global Best Secrecy Rate: 15.228477792197882\n",
      "iteration = 40 Global Best Secrecy Rate: 15.228477792197882\n",
      "iteration = 41 Global Best Secrecy Rate: 15.228477792197882\n",
      "iteration = 42 Global Best Secrecy Rate: 15.228477792197882\n",
      "iteration = 43 Global Best Secrecy Rate: 15.228477792197882\n",
      "iteration = 44 Global Best Secrecy Rate: 15.228477792197882\n",
      "iteration = 45 Global Best Secrecy Rate: 15.426254363375323\n",
      "iteration = 46 Global Best Secrecy Rate: 15.426254363375323\n",
      "iteration = 47 Global Best Secrecy Rate: 15.426254363375323\n",
      "iteration = 48 Global Best Secrecy Rate: 15.426254363375323\n",
      "iteration = 49 Global Best Secrecy Rate: 15.444008955066591\n",
      "iteration = 50 Global Best Secrecy Rate: 15.502932476571772\n",
      "iteration = 51 Global Best Secrecy Rate: 15.502932476571772\n",
      "iteration = 52 Global Best Secrecy Rate: 15.502932476571772\n",
      "iteration = 53 Global Best Secrecy Rate: 15.502932476571772\n",
      "iteration = 54 Global Best Secrecy Rate: 15.502932476571772\n",
      "iteration = 55 Global Best Secrecy Rate: 15.549576051930481\n",
      "iteration = 56 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 57 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 58 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 59 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 60 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 61 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 62 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 63 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 64 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 65 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 66 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 67 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 68 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 69 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 70 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 71 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 72 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 73 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 74 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 75 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 76 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 77 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 78 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 79 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 80 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 81 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 82 Global Best Secrecy Rate: 15.570841219213502\n",
      "iteration = 83 Global Best Secrecy Rate: 15.828407755376109\n",
      "iteration = 84 Global Best Secrecy Rate: 16.03482546870204\n",
      "iteration = 85 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 86 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 87 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 88 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 89 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 90 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 91 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 92 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 93 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 94 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 95 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 96 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 97 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 98 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 99 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 100 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 101 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 102 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 103 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 104 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 105 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 106 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 107 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 108 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 109 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 110 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 111 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 112 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 113 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 114 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 115 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 116 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 117 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 118 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 119 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 120 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 121 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 122 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 123 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 124 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 125 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 126 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 127 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 128 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 129 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 130 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 131 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 132 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 133 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 134 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 135 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 136 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 137 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 138 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 139 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 140 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 141 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 142 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 143 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 144 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 145 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 146 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 147 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 148 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 149 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 150 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 151 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 152 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 153 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 154 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 155 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 156 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 157 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 158 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 159 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 160 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 161 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 162 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 163 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 164 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 165 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 166 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 167 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 168 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 169 Global Best Secrecy Rate: 16.309421599623217\n",
      "iteration = 170 Global Best Secrecy Rate: 16.314518065299605\n",
      "iteration = 171 Global Best Secrecy Rate: 16.559287662267657\n",
      "iteration = 172 Global Best Secrecy Rate: 16.669993092667443\n",
      "iteration = 173 Global Best Secrecy Rate: 16.669993092667443\n",
      "iteration = 174 Global Best Secrecy Rate: 16.669993092667443\n",
      "iteration = 175 Global Best Secrecy Rate: 16.669993092667443\n",
      "iteration = 176 Global Best Secrecy Rate: 16.669993092667443\n",
      "iteration = 177 Global Best Secrecy Rate: 16.669993092667443\n",
      "iteration = 178 Global Best Secrecy Rate: 16.669993092667443\n",
      "iteration = 179 Global Best Secrecy Rate: 16.67129989352994\n",
      "iteration = 180 Global Best Secrecy Rate: 16.77688079151813\n",
      "iteration = 181 Global Best Secrecy Rate: 16.77688079151813\n",
      "iteration = 182 Global Best Secrecy Rate: 16.77688079151813\n",
      "iteration = 183 Global Best Secrecy Rate: 16.77688079151813\n",
      "iteration = 184 Global Best Secrecy Rate: 16.77688079151813\n",
      "iteration = 185 Global Best Secrecy Rate: 16.826129244028955\n",
      "iteration = 186 Global Best Secrecy Rate: 16.826129244028955\n",
      "iteration = 187 Global Best Secrecy Rate: 16.92133089840153\n",
      "iteration = 188 Global Best Secrecy Rate: 16.92133089840153\n",
      "iteration = 189 Global Best Secrecy Rate: 16.92133089840153\n",
      "iteration = 190 Global Best Secrecy Rate: 16.92133089840153\n",
      "iteration = 191 Global Best Secrecy Rate: 17.138320997133363\n",
      "iteration = 192 Global Best Secrecy Rate: 17.171344520413246\n",
      "iteration = 193 Global Best Secrecy Rate: 17.171344520413246\n",
      "iteration = 194 Global Best Secrecy Rate: 17.171344520413246\n",
      "iteration = 195 Global Best Secrecy Rate: 17.171344520413246\n",
      "iteration = 196 Global Best Secrecy Rate: 17.171344520413246\n",
      "iteration = 197 Global Best Secrecy Rate: 17.171344520413246\n",
      "iteration = 198 Global Best Secrecy Rate: 17.171344520413246\n",
      "iteration = 199 Global Best Secrecy Rate: 17.171344520413246\n",
      "Initial Secrecy Rate PSO-GD: 8.698405811598715\n",
      "Final Secrecy Rate PSO-GD: 17.171344520413246\n"
     ]
    }
   ],
   "source": [
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "max_pso_iter = 200\n",
    "max_gd_iter = 50\n",
    "number_of_particles = 50\n",
    "w_max = 0.9\n",
    "w_min = 0.5\n",
    "c1 = 1.5\n",
    "c2 = 1.5\n",
    "\n",
    "PSO_GD_results = PSO_GD(max_pso_iter, max_gd_iter, number_of_particles, learning_rate, w_max, w_min, c1, c2)\n",
    "print(\"Initial Secrecy Rate PSO-GD:\", PSO_GD_results[0])\n",
    "print(\"Final Secrecy Rate PSO-GD:\", PSO_GD_results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of GA and GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_GD_optimize_w_theta(population_size: int, max_iter: int, max_iter_gd: int, crossover_rate: float = 0.85, mutation_rate: float = 0.85):\n",
    "  population = GAPopulation(population_size, crossover_rate, mutation_rate)\n",
    "  population.sort_population()\n",
    "  results_secrecy_rate = []\n",
    "  results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "\n",
    "  for iteration in range(max_iter):\n",
    "    print(\"iteration =\", iteration)\n",
    "    print(\"Best secrecy rate:\", population.individuals[0].fitness)\n",
    "    # Crossover\n",
    "    for _ in range(population_size):\n",
    "      if np.random.rand() < population.crossover_rate:\n",
    "        parent1, parent2 = population.select_parents()\n",
    "        child = population.crossover(parent1, parent2)\n",
    "    #Mutate \n",
    "        population.mutate(child)\n",
    "        population.add_individual(child)\n",
    "\n",
    "\n",
    "    # GD\n",
    "    for individual in population.individuals:\n",
    "      for _ in range(max_iter_gd):\n",
    "        new_w, new_theta = gradient_descent_update(individual.w, theta_angles_to_theta_vector(individual.theta), learning_rate)\n",
    "        new_secrecy_rate = secrecy_rate_objective_function(new_theta, new_w)\n",
    "        if (new_secrecy_rate - individual.fitness) < 1e-9:\n",
    "          break\n",
    "        \n",
    "        individual.w = new_w\n",
    "        individual.theta = theta_vector_to_theta_angles(new_theta)\n",
    "        individual.update_fitness()\n",
    "\n",
    "      individual.theta, individual.w = repair(theta_angles_to_theta_vector(individual.theta), individual.w)\n",
    "      individual.theta = theta_vector_to_theta_angles(individual.theta)\n",
    "      individual.update_fitness()\n",
    "\n",
    "    # Filter\n",
    "    population.filter_population() \n",
    "\n",
    "    # Sort\n",
    "    population.sort_population()\n",
    "    \n",
    "    #print(f\"[Generation {iteration + 1}] Population before GD: {list(map(lambda x: x.fitness, population.individuals))}\")\n",
    "\n",
    "    print(\"Best secrecy rate:\", population.individuals[0].fitness)\n",
    "    results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "\n",
    "  return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0\n",
      "Best secrecy rate: 8.698405811598715\n",
      "Best secrecy rate: 12.435476130817866\n",
      "iteration = 1\n",
      "Best secrecy rate: 12.435476130817866\n",
      "Best secrecy rate: 12.734209106923807\n",
      "iteration = 2\n",
      "Best secrecy rate: 12.734209106923807\n",
      "Best secrecy rate: 13.259967933795785\n",
      "iteration = 3\n",
      "Best secrecy rate: 13.259967933795785\n",
      "Best secrecy rate: 13.34700973803588\n",
      "iteration = 4\n",
      "Best secrecy rate: 13.34700973803588\n",
      "Best secrecy rate: 13.259967933795785\n",
      "iteration = 5\n",
      "Best secrecy rate: 13.259967933795785\n",
      "Best secrecy rate: 13.652221000254421\n",
      "iteration = 6\n",
      "Best secrecy rate: 13.652221000254421\n",
      "Best secrecy rate: 13.863243917803906\n",
      "iteration = 7\n",
      "Best secrecy rate: 13.863243917803906\n",
      "Best secrecy rate: 13.863243917803906\n",
      "iteration = 8\n",
      "Best secrecy rate: 13.863243917803906\n",
      "Best secrecy rate: 13.863243917803906\n",
      "iteration = 9\n",
      "Best secrecy rate: 13.863243917803906\n",
      "Best secrecy rate: 14.093976153575142\n",
      "iteration = 10\n",
      "Best secrecy rate: 14.093976153575142\n",
      "Best secrecy rate: 14.261193941824422\n",
      "iteration = 11\n",
      "Best secrecy rate: 14.261193941824422\n",
      "Best secrecy rate: 14.263407725194138\n",
      "iteration = 12\n",
      "Best secrecy rate: 14.263407725194138\n",
      "Best secrecy rate: 14.457274769992019\n",
      "iteration = 13\n",
      "Best secrecy rate: 14.457274769992019\n",
      "Best secrecy rate: 14.394708893868987\n",
      "iteration = 14\n",
      "Best secrecy rate: 14.394708893868987\n",
      "Best secrecy rate: 14.429900905169207\n",
      "iteration = 15\n",
      "Best secrecy rate: 14.429900905169207\n",
      "Best secrecy rate: 14.50822756583532\n",
      "iteration = 16\n",
      "Best secrecy rate: 14.50822756583532\n",
      "Best secrecy rate: 14.50822756583532\n",
      "iteration = 17\n",
      "Best secrecy rate: 14.50822756583532\n",
      "Best secrecy rate: 14.50822756583532\n",
      "iteration = 18\n",
      "Best secrecy rate: 14.50822756583532\n",
      "Best secrecy rate: 14.657164306388431\n",
      "iteration = 19\n",
      "Best secrecy rate: 14.657164306388431\n",
      "Best secrecy rate: 14.657164306388431\n",
      "iteration = 20\n",
      "Best secrecy rate: 14.657164306388431\n",
      "Best secrecy rate: 14.657164306388431\n",
      "iteration = 21\n",
      "Best secrecy rate: 14.657164306388431\n",
      "Best secrecy rate: 14.657164306388431\n",
      "iteration = 22\n",
      "Best secrecy rate: 14.657164306388431\n",
      "Best secrecy rate: 14.657164306388431\n",
      "iteration = 23\n",
      "Best secrecy rate: 14.657164306388431\n",
      "Best secrecy rate: 14.657164306388431\n",
      "iteration = 24\n",
      "Best secrecy rate: 14.657164306388431\n",
      "Best secrecy rate: 14.657164306388431\n",
      "iteration = 25\n",
      "Best secrecy rate: 14.657164306388431\n",
      "Best secrecy rate: 14.657164306388431\n",
      "iteration = 26\n",
      "Best secrecy rate: 14.657164306388431\n",
      "Best secrecy rate: 14.657164306388431\n",
      "iteration = 27\n",
      "Best secrecy rate: 14.657164306388431\n",
      "Best secrecy rate: 14.65794344619486\n",
      "iteration = 28\n",
      "Best secrecy rate: 14.65794344619486\n",
      "Best secrecy rate: 14.65794344619486\n",
      "iteration = 29\n",
      "Best secrecy rate: 14.65794344619486\n",
      "Best secrecy rate: 14.65794344619486\n",
      "iteration = 30\n",
      "Best secrecy rate: 14.65794344619486\n",
      "Best secrecy rate: 14.65794344619486\n",
      "iteration = 31\n",
      "Best secrecy rate: 14.65794344619486\n",
      "Best secrecy rate: 14.660875835144552\n",
      "iteration = 32\n",
      "Best secrecy rate: 14.660875835144552\n",
      "Best secrecy rate: 14.660875835144552\n",
      "iteration = 33\n",
      "Best secrecy rate: 14.660875835144552\n",
      "Best secrecy rate: 14.660875835144552\n",
      "iteration = 34\n",
      "Best secrecy rate: 14.660875835144552\n",
      "Best secrecy rate: 14.660875835144552\n",
      "iteration = 35\n",
      "Best secrecy rate: 14.660875835144552\n",
      "Best secrecy rate: 14.719171855495562\n",
      "iteration = 36\n",
      "Best secrecy rate: 14.719171855495562\n",
      "Best secrecy rate: 14.719171855495562\n",
      "iteration = 37\n",
      "Best secrecy rate: 14.719171855495562\n",
      "Best secrecy rate: 14.719171855495562\n",
      "iteration = 38\n",
      "Best secrecy rate: 14.719171855495562\n",
      "Best secrecy rate: 14.719171855495562\n",
      "iteration = 39\n",
      "Best secrecy rate: 14.719171855495562\n",
      "Best secrecy rate: 14.719171855495562\n",
      "iteration = 40\n",
      "Best secrecy rate: 14.719171855495562\n",
      "Best secrecy rate: 14.719171855495562\n",
      "iteration = 41\n",
      "Best secrecy rate: 14.719171855495562\n",
      "Best secrecy rate: 14.719171855495562\n",
      "iteration = 42\n",
      "Best secrecy rate: 14.719171855495562\n",
      "Best secrecy rate: 14.719171855495562\n",
      "iteration = 43\n",
      "Best secrecy rate: 14.719171855495562\n",
      "Best secrecy rate: 14.721539802048925\n",
      "iteration = 44\n",
      "Best secrecy rate: 14.721539802048925\n",
      "Best secrecy rate: 14.721539802048925\n",
      "iteration = 45\n",
      "Best secrecy rate: 14.721539802048925\n",
      "Best secrecy rate: 14.721539802048925\n",
      "iteration = 46\n",
      "Best secrecy rate: 14.721539802048925\n",
      "Best secrecy rate: 14.721539802048925\n",
      "iteration = 47\n",
      "Best secrecy rate: 14.721539802048925\n",
      "Best secrecy rate: 14.721539802048925\n",
      "iteration = 48\n",
      "Best secrecy rate: 14.721539802048925\n",
      "Best secrecy rate: 14.721539802048925\n",
      "iteration = 49\n",
      "Best secrecy rate: 14.721539802048925\n",
      "Best secrecy rate: 14.721539802048925\n",
      "iteration = 50\n",
      "Best secrecy rate: 14.721539802048925\n",
      "Best secrecy rate: 14.721539802048925\n",
      "iteration = 51\n",
      "Best secrecy rate: 14.721539802048925\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 52\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 53\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 54\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 55\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 56\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 57\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 58\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 59\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 60\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 61\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 62\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 63\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 64\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 65\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 66\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 67\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 68\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 69\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 70\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 71\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 72\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 73\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 74\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 75\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 76\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 77\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 78\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 79\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 80\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 81\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 82\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 83\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 84\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 85\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 86\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 87\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 88\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 89\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 90\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 91\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 92\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 93\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 94\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 95\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 96\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 97\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 98\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 99\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 100\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 101\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 102\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 103\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 104\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 105\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 106\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 107\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 108\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 109\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 110\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 111\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 112\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 113\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 114\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 115\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 116\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 117\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 118\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.721618536535889\n",
      "iteration = 119\n",
      "Best secrecy rate: 14.721618536535889\n",
      "Best secrecy rate: 14.74364707456636\n",
      "iteration = 120\n",
      "Best secrecy rate: 14.74364707456636\n",
      "Best secrecy rate: 14.750108642884019\n",
      "iteration = 121\n",
      "Best secrecy rate: 14.750108642884019\n",
      "Best secrecy rate: 14.750108642884019\n",
      "iteration = 122\n",
      "Best secrecy rate: 14.750108642884019\n",
      "Best secrecy rate: 14.750434211876868\n",
      "iteration = 123\n",
      "Best secrecy rate: 14.750434211876868\n",
      "Best secrecy rate: 14.750434211876868\n",
      "iteration = 124\n",
      "Best secrecy rate: 14.750434211876868\n",
      "Best secrecy rate: 14.750434211876868\n",
      "iteration = 125\n",
      "Best secrecy rate: 14.750434211876868\n",
      "Best secrecy rate: 14.75130413846457\n",
      "iteration = 126\n",
      "Best secrecy rate: 14.75130413846457\n",
      "Best secrecy rate: 14.751823873561989\n",
      "iteration = 127\n",
      "Best secrecy rate: 14.751823873561989\n",
      "Best secrecy rate: 14.751823873561989\n",
      "iteration = 128\n",
      "Best secrecy rate: 14.751823873561989\n",
      "Best secrecy rate: 14.751823873561989\n",
      "iteration = 129\n",
      "Best secrecy rate: 14.751823873561989\n",
      "Best secrecy rate: 14.751823873561989\n",
      "iteration = 130\n",
      "Best secrecy rate: 14.751823873561989\n",
      "Best secrecy rate: 14.751823873561989\n",
      "iteration = 131\n",
      "Best secrecy rate: 14.751823873561989\n",
      "Best secrecy rate: 14.751823873561989\n",
      "iteration = 132\n",
      "Best secrecy rate: 14.751823873561989\n",
      "Best secrecy rate: 14.751823873561989\n",
      "iteration = 133\n",
      "Best secrecy rate: 14.751823873561989\n",
      "Best secrecy rate: 14.751823873561989\n",
      "iteration = 134\n",
      "Best secrecy rate: 14.751823873561989\n",
      "Best secrecy rate: 14.751823873561989\n",
      "iteration = 135\n",
      "Best secrecy rate: 14.751823873561989\n",
      "Best secrecy rate: 14.789567441070673\n",
      "iteration = 136\n",
      "Best secrecy rate: 14.789567441070673\n",
      "Best secrecy rate: 14.789567441070673\n",
      "iteration = 137\n",
      "Best secrecy rate: 14.789567441070673\n",
      "Best secrecy rate: 14.789567441070673\n",
      "iteration = 138\n",
      "Best secrecy rate: 14.789567441070673\n",
      "Best secrecy rate: 14.789567441070673\n",
      "iteration = 139\n",
      "Best secrecy rate: 14.789567441070673\n",
      "Best secrecy rate: 14.789567441070673\n",
      "iteration = 140\n",
      "Best secrecy rate: 14.789567441070673\n",
      "Best secrecy rate: 14.789567441070673\n",
      "iteration = 141\n",
      "Best secrecy rate: 14.789567441070673\n",
      "Best secrecy rate: 14.789567441070673\n",
      "iteration = 142\n",
      "Best secrecy rate: 14.789567441070673\n",
      "Best secrecy rate: 14.789567441070673\n",
      "iteration = 143\n",
      "Best secrecy rate: 14.789567441070673\n",
      "Best secrecy rate: 14.789567441070673\n",
      "iteration = 144\n",
      "Best secrecy rate: 14.789567441070673\n",
      "Best secrecy rate: 14.789567441070673\n",
      "iteration = 145\n",
      "Best secrecy rate: 14.789567441070673\n",
      "Best secrecy rate: 14.789567441070673\n",
      "iteration = 146\n",
      "Best secrecy rate: 14.789567441070673\n",
      "Best secrecy rate: 14.789567441070673\n",
      "iteration = 147\n",
      "Best secrecy rate: 14.789567441070673\n",
      "Best secrecy rate: 14.79175411376756\n",
      "iteration = 148\n",
      "Best secrecy rate: 14.79175411376756\n",
      "Best secrecy rate: 14.79183788371928\n",
      "iteration = 149\n",
      "Best secrecy rate: 14.79183788371928\n",
      "Best secrecy rate: 14.791870018706208\n",
      "iteration = 150\n",
      "Best secrecy rate: 14.791870018706208\n",
      "Best secrecy rate: 14.791994418232616\n",
      "iteration = 151\n",
      "Best secrecy rate: 14.791994418232616\n",
      "Best secrecy rate: 14.791998455887054\n",
      "iteration = 152\n",
      "Best secrecy rate: 14.791998455887054\n",
      "Best secrecy rate: 14.792002015822618\n",
      "iteration = 153\n",
      "Best secrecy rate: 14.792002015822618\n",
      "Best secrecy rate: 14.792002015822618\n",
      "iteration = 154\n",
      "Best secrecy rate: 14.792002015822618\n",
      "Best secrecy rate: 14.792002015822618\n",
      "iteration = 155\n",
      "Best secrecy rate: 14.792002015822618\n",
      "Best secrecy rate: 14.792002015822618\n",
      "iteration = 156\n",
      "Best secrecy rate: 14.792002015822618\n",
      "Best secrecy rate: 14.792002015822618\n",
      "iteration = 157\n",
      "Best secrecy rate: 14.792002015822618\n",
      "Best secrecy rate: 14.792002015822618\n",
      "iteration = 158\n",
      "Best secrecy rate: 14.792002015822618\n",
      "Best secrecy rate: 14.792002015822618\n",
      "iteration = 159\n",
      "Best secrecy rate: 14.792002015822618\n",
      "Best secrecy rate: 14.792002015822618\n",
      "iteration = 160\n",
      "Best secrecy rate: 14.792002015822618\n",
      "Best secrecy rate: 14.792002015822618\n",
      "iteration = 161\n",
      "Best secrecy rate: 14.792002015822618\n",
      "Best secrecy rate: 14.792002015822618\n",
      "iteration = 162\n",
      "Best secrecy rate: 14.792002015822618\n",
      "Best secrecy rate: 14.792004540367325\n",
      "iteration = 163\n",
      "Best secrecy rate: 14.792004540367325\n",
      "Best secrecy rate: 14.792004671277132\n",
      "iteration = 164\n",
      "Best secrecy rate: 14.792004671277132\n",
      "Best secrecy rate: 14.792004671277132\n",
      "iteration = 165\n",
      "Best secrecy rate: 14.792004671277132\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 166\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 167\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 168\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 169\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 170\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 171\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 172\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 173\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 174\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 175\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 176\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 177\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 178\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 179\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 180\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 181\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 182\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 183\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 184\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 185\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 186\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 187\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 188\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 189\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 190\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 191\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.792005896699624\n",
      "iteration = 192\n",
      "Best secrecy rate: 14.792005896699624\n",
      "Best secrecy rate: 14.815325222609683\n",
      "iteration = 193\n",
      "Best secrecy rate: 14.815325222609683\n",
      "Best secrecy rate: 14.815325804132641\n",
      "iteration = 194\n",
      "Best secrecy rate: 14.815325804132641\n",
      "Best secrecy rate: 14.815325804132641\n",
      "iteration = 195\n",
      "Best secrecy rate: 14.815325804132641\n",
      "Best secrecy rate: 14.815326081395542\n",
      "iteration = 196\n",
      "Best secrecy rate: 14.815326081395542\n",
      "Best secrecy rate: 14.815326081395542\n",
      "iteration = 197\n",
      "Best secrecy rate: 14.815326081395542\n",
      "Best secrecy rate: 14.817617473837146\n",
      "iteration = 198\n",
      "Best secrecy rate: 14.817617473837146\n",
      "Best secrecy rate: 14.817617473837146\n",
      "iteration = 199\n",
      "Best secrecy rate: 14.817617473837146\n",
      "Best secrecy rate: 14.817617531690942\n",
      "Initial Secrecy Rate GA-GD: 8.698405811598715\n",
      "[np.float64(8.698405811598715), np.float64(12.435476130817866), np.float64(12.734209106923807), np.float64(13.259967933795785), np.float64(13.34700973803588), np.float64(13.259967933795785), np.float64(13.652221000254421), np.float64(13.863243917803906), np.float64(13.863243917803906), np.float64(13.863243917803906), np.float64(14.093976153575142), np.float64(14.261193941824422), np.float64(14.263407725194138), np.float64(14.457274769992019), np.float64(14.394708893868987), np.float64(14.429900905169207), np.float64(14.50822756583532), np.float64(14.50822756583532), np.float64(14.50822756583532), np.float64(14.657164306388431), np.float64(14.657164306388431), np.float64(14.657164306388431), np.float64(14.657164306388431), np.float64(14.657164306388431), np.float64(14.657164306388431), np.float64(14.657164306388431), np.float64(14.657164306388431), np.float64(14.657164306388431), np.float64(14.65794344619486), np.float64(14.65794344619486), np.float64(14.65794344619486), np.float64(14.65794344619486), np.float64(14.660875835144552), np.float64(14.660875835144552), np.float64(14.660875835144552), np.float64(14.660875835144552), np.float64(14.719171855495562), np.float64(14.719171855495562), np.float64(14.719171855495562), np.float64(14.719171855495562), np.float64(14.719171855495562), np.float64(14.719171855495562), np.float64(14.719171855495562), np.float64(14.719171855495562), np.float64(14.721539802048925), np.float64(14.721539802048925), np.float64(14.721539802048925), np.float64(14.721539802048925), np.float64(14.721539802048925), np.float64(14.721539802048925), np.float64(14.721539802048925), np.float64(14.721539802048925), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.721618536535889), np.float64(14.74364707456636), np.float64(14.750108642884019), np.float64(14.750108642884019), np.float64(14.750434211876868), np.float64(14.750434211876868), np.float64(14.750434211876868), np.float64(14.75130413846457), np.float64(14.751823873561989), np.float64(14.751823873561989), np.float64(14.751823873561989), np.float64(14.751823873561989), np.float64(14.751823873561989), np.float64(14.751823873561989), np.float64(14.751823873561989), np.float64(14.751823873561989), np.float64(14.751823873561989), np.float64(14.789567441070673), np.float64(14.789567441070673), np.float64(14.789567441070673), np.float64(14.789567441070673), np.float64(14.789567441070673), np.float64(14.789567441070673), np.float64(14.789567441070673), np.float64(14.789567441070673), np.float64(14.789567441070673), np.float64(14.789567441070673), np.float64(14.789567441070673), np.float64(14.789567441070673), np.float64(14.79175411376756), np.float64(14.79183788371928), np.float64(14.791870018706208), np.float64(14.791994418232616), np.float64(14.791998455887054), np.float64(14.792002015822618), np.float64(14.792002015822618), np.float64(14.792002015822618), np.float64(14.792002015822618), np.float64(14.792002015822618), np.float64(14.792002015822618), np.float64(14.792002015822618), np.float64(14.792002015822618), np.float64(14.792002015822618), np.float64(14.792002015822618), np.float64(14.792004540367325), np.float64(14.792004671277132), np.float64(14.792004671277132), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.792005896699624), np.float64(14.815325222609683), np.float64(14.815325804132641), np.float64(14.815325804132641), np.float64(14.815326081395542), np.float64(14.815326081395542), np.float64(14.817617473837146), np.float64(14.817617473837146), np.float64(14.817617531690942)]\n",
      "Final Secrecy Rate GA-GD: 14.817617531690942\n"
     ]
    }
   ],
   "source": [
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# GA-GD\n",
    "population_size = 50\n",
    "num_generations = 200\n",
    "num_iter_gd = 50\n",
    "crossover_rate = 0.9\n",
    "mutation_rate = 0.3\n",
    "learning_rate = 0.01\n",
    "\n",
    "GA_GD_results = GA_GD_optimize_w_theta(population_size, num_generations, num_iter_gd, crossover_rate, mutation_rate)\n",
    "print(\"Initial Secrecy Rate GA-GD:\", GA_GD_results[0])\n",
    "print(GA_GD_results)\n",
    "print(\"Final Secrecy Rate GA-GD:\", GA_GD_results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# iterations = range(0, num_cycles+10, 10)\n",
    "\n",
    "iterations = range(0, 200)\n",
    "# Extend the results to the same length\n",
    "GD_results_draw = GD_results[:200]\n",
    "PSO_results_draw = PSO_results[:200]\n",
    "GA_results_draw = GA_results[:200]\n",
    "PSO_GD_results_draw = PSO_GD_results[:200]\n",
    "GA_GD_results_draw = GA_GD_results[:200]\n",
    "\n",
    "\n",
    "#plt.plot(iterations, GD_results_draw, label='Gradient Descent')\n",
    "plt.plot(iterations, PSO_results_draw, label='PSO')\n",
    "plt.plot(iterations, GA_results_draw, label='Genetic Algorithm')\n",
    "plt.plot(iterations, PSO_GD_results_draw, label='PSO-GD')\n",
    "plt.plot(iterations, GA_GD_results_draw, label='GA-GD')\n",
    "\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Secrecy rate (bps/Hz)')\n",
    "plt.title('gamma =' + str(gamma))\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.sa\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Secrecy Rate GD: 14.566414361633216\n",
      "Best Secrecy Rate PSO: 13.442322688931457\n",
      "Best Secrecy Rate GA: 14.226884446922732\n",
      "Best Secrecy Rate PSO-GD: 17.171344520413246\n",
      "Best Secrecy Rate GA-GD: 14.817617531690942\n"
     ]
    }
   ],
   "source": [
    "# Best results of each methods\n",
    "print(\"Best Secrecy Rate GD:\", max(GD_results))\n",
    "print(\"Best Secrecy Rate PSO:\", max(PSO_results))\n",
    "print(\"Best Secrecy Rate GA:\", max(GA_results))\n",
    "print(\"Best Secrecy Rate PSO-GD:\", max(PSO_GD_results))\n",
    "print(\"Best Secrecy Rate GA-GD:\", max(GA_GD_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if os.path.exists('results') == False:\n",
    "    os.mkdir('results')\n",
    "os.chdir('results')\n",
    "if os.path.exists('general') == False:\n",
    "    os.mkdir('general')\n",
    "os.chdir('general')\n",
    "times = 1\n",
    "if os.path.exists(f'{times}_run') == False:\n",
    "    os.mkdir(f'{times}_run')\n",
    "    os.chdir(f'{times}_run')\n",
    "    plt.savefig('gamma_' + str(gamma) + '.png')\n",
    "    np.save('GD_results', GD_results)\n",
    "    np.save('PSO_results', PSO_results)\n",
    "    np.save('GA_results', GA_results)\n",
    "    np.save('PSO_GD_results', PSO_GD_results)\n",
    "    np.save('GA_GD_results', GA_GD_results)\n",
    "    os.chdir('../')\n",
    "os.chdir('../../')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

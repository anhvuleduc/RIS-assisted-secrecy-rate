{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy, copy\n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 18\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transfer from dBW to W (power)\n",
    "def db2pow(db: float) -> float:\n",
    "    return 10**(db/10)\n",
    "\n",
    "# Function to transfer from W to dBW (power)\n",
    "def pow2db(pow: float) -> float:\n",
    "    return 10*np.log10(pow)\n",
    "\n",
    "# Hermitian transpose of a matrix\n",
    "def HermTranspose(x: np.ndarray) -> np.ndarray:\n",
    "    return x.conj().T\n",
    "\n",
    "def chanGen(zeta: float, d: float, dim1: int, dim2: int) -> np.ndarray:\n",
    "    \"\"\"Function to generate Rayleigh fading channel coefficients\n",
    "\n",
    "    Args:\n",
    "        zeta: Î¾ is the path loss exponent\n",
    "        d: the distance between the transmitter and the receiver\n",
    "        dim1: the number of rows in the channel matrix\n",
    "        dim2: the number of columns in the channel matrix\n",
    "    \"\"\"\n",
    "    pl_ref: float = -30                                    # pathloss (dBW) at reference distance\n",
    "    pl: float = db2pow(pl_ref - 10*zeta*np.log10(d))       # pathloss model at distance d\n",
    "    y: np.ndarray = np.sqrt(0.5*pl)*(np.random.randn(dim1,dim2)\\\n",
    "        + 1j*np.random.randn(dim1,dim2))            # Rayleigh distribution\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = db2pow(-75)                                                                 # noise power\n",
    "N = 10                                                                              # number of transmit antennas\n",
    "Nris = 100                                                                          # number of RIS elements\n",
    "number_of_users = 10                                                                 # number of users\n",
    "number_of_eavesdroppers = 3                                                         # number of eavesdroppers\n",
    "zetaAI = 2.2                                                                        # Path loss exponent of the channel between the Alice and the RIS\n",
    "zetaIB = 2.5                                                                        # Path loss exponent of the channel between the legitimate receivers and the RIS\n",
    "zetaIE = 2.5                                                                        # Path loss exponent of the channel between the eavesdroppers and the RIS\n",
    "zetaAB = 3.5                                                                        # Path loss exponent of the channel between the Alice and the legitimate receivers\n",
    "zetaAE = 3.5                                                                        # Path loss exponent of the channel between the Alice and the eavesdroppers\n",
    "\n",
    "dAI = 50                                                                            # distance between Alice and the RIS\n",
    "dv = 2                                                                              # Vertical distance between the Alice and the Eve and Bob\n",
    "dABh = np.random.uniform(5, 10, size=number_of_users)                               # Horizontal distance between Alice and the legitimate receivers\n",
    "dAEh = np.random.uniform(50, 150, size=number_of_eavesdroppers)                     # Horizontal distance between Alice and the eavesdroppers\n",
    "dAB = [np.sqrt(dABh[i]**2 + dv**2) for i in range(number_of_users)]                 # Distance between Alice and the legitimate receivers\n",
    "dAE = [np.sqrt(dAEh[i]**2 + dv**2) for i in range(number_of_eavesdroppers)]         # Distance between Alice and the eavesdroppers\n",
    "dIB = [np.sqrt((dABh[i]-dAI)**2 + dv**2) for i in range(number_of_users)]           # Distance between the legitimate receivers and the RIS\n",
    "dIE = [np.sqrt((dAEh[i]-dAI)**2 + dv**2) for i in range(number_of_eavesdroppers)]   # Distance between the eavesdroppers and the RIS\n",
    "\n",
    "gamma = 0.8 # Lower bound for user's link quality\n",
    "pmax = 1000  # Maximum transmit power of Alice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_beamforming_vectors(w: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Function to normalise the beamforming vectors\n",
    "\n",
    "    Args:\n",
    "        w: the beamforming vectors\n",
    "    \"\"\"\n",
    "    total_norm_squared = 0\n",
    "    for i in range(number_of_users):\n",
    "        total_norm_squared += (np.linalg.norm(w[i]) ** 2)\n",
    "    if total_norm_squared <= pmax:\n",
    "        return w\n",
    "    for i in range(number_of_users):\n",
    "        w[i] = w[i] / (total_norm_squared ** 0.5) * np.sqrt(pmax)\n",
    "    return w\n",
    "\n",
    "def generate_random_beamforming_vector():\n",
    "  '''\n",
    "  Generate one random beamforming vector\n",
    "  '''\n",
    "  return np.random.uniform(-1, 1, (N, 1)) + 1j * np.random.uniform(-1, 1, (N, 1))\n",
    "\n",
    "def generate_random_beamforming_vectors():\n",
    "    # Generate random complex numbers for each element of the beamforming vector\n",
    "    beamforming_vectors = [generate_random_beamforming_vector() for _ in range (number_of_users)]\n",
    "    \n",
    "    # Normalize the vectors\n",
    "    beamforming_vectors = normalise_beamforming_vectors(beamforming_vectors)\n",
    "    return beamforming_vectors\n",
    "    #w: list of beamforming vectors, length = number of users, elements are N x 1\n",
    "\n",
    "def generate_random_theta():\n",
    "    theta = np.random.uniform(-np.pi, np.pi, (1, Nris))\n",
    "    theta = np.exp(1j * theta)\n",
    "    return theta\n",
    "    #theta: phase shift of RIS, size 1 x Nris\n",
    "\n",
    "def generate_random_theta_angles(size: int):\n",
    "  \"\"\"\n",
    "    Generate a random vector of angles from -pi to pi\n",
    "  \"\"\"\n",
    "  return np.random.uniform(-np.pi, np.pi, size=(1, size))\n",
    "\n",
    "def theta_angles_to_theta_vector(angles: np.ndarray[np.float64]) -> np.ndarray[np.complex128]:\n",
    "  \"\"\"\n",
    "    Convert a vector of angles to a vector of complex numbers on the unit circle\n",
    "  \"\"\"\n",
    "  return np.exp(1j * angles)\n",
    "\n",
    "def theta_vector_to_theta_angles(theta: np.ndarray[np.complex128]) -> np.ndarray[np.float64]:\n",
    "  \"\"\"\n",
    "    Convert a vector of complex numbers on the unit circle to a vector of angles\n",
    "  \"\"\"\n",
    "  return np.angle(theta)\n",
    "\n",
    "def generateChannel():\n",
    "    normFact: float = 1/np.sqrt(sigma)\n",
    "    Hai = chanGen(zetaAI, dAI, Nris, N)                                                         # Alice to RIS channel\n",
    "    hib = [normFact*chanGen(zetaIB, dIB[i], 1, Nris) for i in range(number_of_users)]           # Channel between the RIS and the legitimate receivers\n",
    "    hie = [normFact*chanGen(zetaIE, dIE[i], 1, Nris) for i in range(number_of_eavesdroppers)]   # Channel between the RIS and the eavesdroppers\n",
    "    hab = [normFact*chanGen(zetaAB, dAB[i], 1, N) for i in range(number_of_users)]              # Channel between Alice and the legitimate receivers\n",
    "    hae = [normFact*chanGen(zetaAE, dAE[i], 1, N) for i in range(number_of_eavesdroppers)]      # Channel between Alice and the eavesdroppers\n",
    "    return Hai, hib, hie, hab, hae\n",
    "\n",
    "    #Hai: Channel between Alice and RIS: Nris x N  \n",
    "    #hib: Channel between RIS and users: List of length number_of_users, elements are 1 x Nris\n",
    "    #hab: Channel between Alice and users: List of length number_of_users, elements are 1 x N\n",
    "    #hie: Channel between RIS and eavesdroppers: List of length number_of_eavesdroppers, elements are 1 x Nris\n",
    "    #hae: Channel between Alice and eavesdroppers: List of length number_of_eavesdroppers, elements are 1 x N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseed\n",
    "# np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Channel generation\n",
    "Hai, hib, hie, hab, hae = generateChannel()\n",
    "\n",
    "# Generate random theta and w\n",
    "theta_init = generate_random_theta()\n",
    "w_init = generate_random_beamforming_vectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secrecy_rate_objective_function(theta, w) -> float:\n",
    "    secrecy_rate: float = 0\n",
    "    for k in range(number_of_users):\n",
    "        R_bk = []\n",
    "        # Legitimate user k\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        C_bk = np.log2(1 + gamma_bk)\n",
    "        \n",
    "        for m in range(number_of_eavesdroppers):\n",
    "            # Eavesdropper i\n",
    "            Z_em = hie[m] @ np.diag(theta.flatten()) @ Hai + hae[m]\n",
    "            numGamma_em = np.abs(Z_em @ w[k])**2\n",
    "            denGamma_em = 1 + np.sum([np.abs(Z_em @ w[j])**2 for j in range(number_of_users) if j != k])\n",
    "            gamma_em = numGamma_em/denGamma_em\n",
    "            C_em = np.log2(1 + gamma_em)\n",
    "            R_bk.append(C_bk - C_em)\n",
    "        \n",
    "        secrecy_rate += max(min(R_bk),0)\n",
    "\n",
    "    # Return the only element in the matrix as it is currently a 1x1 np array\n",
    "    return secrecy_rate[0, 0]\n",
    "\n",
    "# Check if the current set up is valid (every users' C_bk >= gamma)\n",
    "# Returns the index of the first invalid user, -1 if all users are valid\n",
    "def check_validity(theta, w) -> int:\n",
    "    for k in range(number_of_users):\n",
    "        # Legitimate user k\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        C_bk = np.log2(1 + gamma_bk)\n",
    "        \n",
    "        if (C_bk < gamma):\n",
    "            return k\n",
    "    return -1 # All users have C_bk >= gamma\n",
    "\n",
    "# Print the C_bk of each user\n",
    "def print_users_Cbk(theta, w) -> None:\n",
    "    for k in range(number_of_users):\n",
    "        # Legitimate user k\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        C_bk = np.log2(1 + gamma_bk)\n",
    "        print(float(C_bk), end = \" \")\n",
    "    print()\n",
    "\n",
    "# Calculate the C_bk of a user\n",
    "def calculate_user_Cbk(theta, w, user) -> float:\n",
    "    Z_bk = hib[user] @ np.diag(theta.flatten()) @ Hai + hab[user]\n",
    "    numGamma_bk = np.abs(Z_bk @ w[user])**2\n",
    "    denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != user])\n",
    "    gamma_bk = numGamma_bk/denGamma_bk\n",
    "    C_bk = np.log2(1 + gamma_bk)\n",
    "    return C_bk\n",
    "\n",
    "# Using gradient descent to repair the beamforming vector of a user\n",
    "# Try to make that user's C_bk >= gamma\n",
    "def repair_beamforming_vectors(theta, w, user, learning_rate = 0.01, max_iter = 500):\n",
    "    #print(\"Initial norm of user beamforming vector: \", np.linalg.norm(w[user]))\n",
    "    #print(\"Before update beamforming of user \", user, \": \")\n",
    "    #print_users_Cbk(theta, w)\n",
    "    while (calculate_user_Cbk(theta, w, user) < gamma + 0.2 and max_iter > 0):\n",
    "        Z_bk = hib[user] @ np.diag(theta.flatten()) @ Hai + hab[user]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[user])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != user])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        \n",
    "        num_grad_C_bk_to_w_k = 2 * (HermTranspose(Z_bk) @ Z_bk @ w[user])\n",
    "        den_grad_C_bk_to_w_k = (1 + gamma_bk) * np.log(2) * (1 + sum([abs(Z_bk @ w[j]) for j in range (number_of_users) if j != user]))\n",
    "        grad_C_bk_to_w_k = num_grad_C_bk_to_w_k / den_grad_C_bk_to_w_k\n",
    "        w[user] = w[user] + learning_rate * grad_C_bk_to_w_k\n",
    "        #w[user] *= 2\n",
    "        max_iter -= 1\n",
    "\n",
    "        w = normalise_beamforming_vectors(w)\n",
    "    #print(\"New norm of user beamforming vector: \", np.linalg.norm(w[user]))\n",
    "    #print(\"After update beamforming of user \", user, \": \")\n",
    "    #print_users_Cbk(theta, w)\n",
    "    return w\n",
    "\n",
    "# Using gradient descent to repair the whole (theta, w) set up\n",
    "def repair(theta, w, iter = 100):\n",
    "    invalid_user = check_validity(theta, w)\n",
    "    while (invalid_user != -1 and iter > 0):\n",
    "        w = repair_beamforming_vectors(theta, w, invalid_user)\n",
    "        invalid_user = check_validity(theta, w)\n",
    "        iter -= 1\n",
    "    if (invalid_user != -1):\n",
    "        theta, w = generate_random_theta(), generate_random_beamforming_vectors()\n",
    "        return repair(theta, w)\n",
    "    return theta, w\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between Alice and the receivers:  [np.float64(8.490781968990742), np.float64(7.788436718125179), np.float64(9.603571583724229), np.float64(6.238482023509884), np.float64(9.474660073970615), np.float64(8.976325835141209), np.float64(8.567226456673964), np.float64(10.13869852751857), np.float64(6.595395392664417), np.float64(5.516822173929771)]\n",
      "distance between Alice and the eavesdroppers:  [np.float64(113.58952016905081), np.float64(134.74608229833302), np.float64(123.63364039696921)]\n",
      "Secrecy Rate: 2.405041669607318\n"
     ]
    }
   ],
   "source": [
    "# print(theta_init)\n",
    "print(\"distance between Alice and the receivers: \", dAB)\n",
    "print(\"distance between Alice and the eavesdroppers: \", dAE)\n",
    "print(\"Secrecy Rate:\", secrecy_rate_objective_function(theta_init, w_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent for Maximization (GD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_w(theta, w):\n",
    "    grad_w = []\n",
    "    Z_e_max = [] #Z_e_max[k] = Z_e_max for user k\n",
    "    gamma_e_max = [] #gamma_e_max[k] = gamma_e_max for user k\n",
    "    Z_b = [] #Z_b[k] = Z_bk\n",
    "    gamma_b = [] #gamma_b[k] = gamma_bk\n",
    "    counted = [] #counted[k] = true if gamma_k > gamma_e_max[k]\n",
    "    \n",
    "    #Precalculation \n",
    "    for k in range(number_of_users):\n",
    "        gamma_e = []\n",
    "        for m in range (number_of_eavesdroppers):\n",
    "            Z_em = hie[m] @ np.diag(theta.flatten()) @ Hai + hae[m]\n",
    "            numGamma_em = np.abs(Z_em @ w[k])**2\n",
    "            denGamma_em = 1 + np.sum([np.abs(Z_em @ w[j])**2 for j in range(number_of_users) if j != k])\n",
    "            gamma_em = numGamma_em/denGamma_em\n",
    "            gamma_e.append(gamma_em)\n",
    "        \n",
    "        gamma_e_max.append(max(gamma_e))\n",
    "        index_e_max = gamma_e.index(max(gamma_e))\n",
    "        Z_e = hie[index_e_max] @ np.diag(theta.flatten()) @ Hai + hae[index_e_max]\n",
    "        Z_e_max.append(Z_e)\n",
    "\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "\n",
    "        Z_b.append(Z_bk)\n",
    "        gamma_b.append(gamma_bk)\n",
    "\n",
    "        counted.append(gamma_bk > gamma_e[index_e_max])\n",
    "\n",
    "\n",
    "    #Calculating grad for i-th beamforming vector\n",
    "    for i in range(number_of_users):\n",
    "        grad = np.zeros((N, 1))\n",
    "        for k in range (number_of_users):\n",
    "            if (counted[k] == False):\n",
    "                continue\n",
    "            if (k == i):\n",
    "                num_grad_C_bk_to_w_k = 2 * (HermTranspose(Z_b[k]) @ Z_b[k] @ w[k])\n",
    "                den_grad_C_bk_to_w_k = (1 + gamma_b[k]) * np.log(2) * (1 + sum([abs(Z_b[k] @ w[j]) for j in range (number_of_users) if j != k]))\n",
    "                grad_C_bk_to_w_k = num_grad_C_bk_to_w_k / den_grad_C_bk_to_w_k\n",
    "\n",
    "                num_grad_C_e_max_to_w_k = 2 * (HermTranspose(Z_e_max[k]) @ Z_e_max[k] @ w[k])\n",
    "                den_grad_C_e_max_to_w_k = (1 + gamma_e_max[k]) * np.log(2) * (1 + sum([abs(Z_e_max[k] @ w[j]) for j in range (number_of_users) if j != k]))\n",
    "                grad_C_e_max_to_w_k = num_grad_C_e_max_to_w_k / den_grad_C_e_max_to_w_k\n",
    "                \n",
    "                grad = grad - (grad_C_bk_to_w_k - grad_C_e_max_to_w_k)\n",
    "            else:\n",
    "                num_grad_C_bk_to_w_i = -2 * abs(Z_b[k] @ w[k]) * (HermTranspose(Z_b[k]) @ Z_b[k] @ w[i])\n",
    "                den_grad_C_bk_to_w_i = (1 + gamma_b[k]) * np.log(2) * (1 + sum([abs(Z_b[k] @ w[j]) for j in range (number_of_users) if j != k])) ** 2\n",
    "                grad_C_bk_to_w_i = num_grad_C_bk_to_w_i / den_grad_C_bk_to_w_i\n",
    "\n",
    "                num_grad_C_e_max_to_w_i = -2 * abs(Z_e_max[k] @ w[k]) * (HermTranspose(Z_e_max[k]) @ Z_e_max[k] @ w[i])\n",
    "                den_grad_C_e_max_to_w_i = (1 + gamma_e_max[k]) * np.log(2) * (1 + sum([abs(Z_e_max[k] @ w[j]) for j in range (number_of_users) if j != k])) ** 2\n",
    "                grad_C_e_max_to_w_i = num_grad_C_e_max_to_w_i / den_grad_C_e_max_to_w_i\n",
    "\n",
    "                grad = grad - (grad_C_bk_to_w_i - grad_C_e_max_to_w_i)\n",
    "            \n",
    "        grad_w.append(grad)\n",
    "    return grad_w\n",
    "\n",
    "def compute_gradient_theta_central(theta, w, epsilon=1e-3):\n",
    "    perturbation = epsilon #+ epsilon * 1j\n",
    "    grad_theta = []\n",
    "    for i in range(Nris):\n",
    "        theta_plus = copy(theta)\n",
    "        theta_plus[0, i] += perturbation\n",
    "        theta_minus = copy(theta)\n",
    "        theta_minus[0, i] -= perturbation\n",
    "        grad_theta_i = (secrecy_rate_objective_function(theta_plus, w) - secrecy_rate_objective_function(theta_minus, w)) / (2*epsilon)\n",
    "        grad_theta.append(grad_theta_i)\n",
    "            \n",
    "    return np.array(grad_theta)\n",
    "\n",
    "def compute_gradient_theta_forward(theta, w, original_secrecy_rate=None, epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Faster implementation of the gradient calculation\n",
    "\n",
    "    Improvements:\n",
    "    - Use forward difference instead of central difference\n",
    "    \"\"\"\n",
    "    perturbation = epsilon + epsilon * 1j\n",
    "    grad_theta = []\n",
    "    for i in range(Nris):\n",
    "        theta_plus = copy(theta)\n",
    "        theta_plus[0, i] += perturbation\n",
    "        grad_theta_i = (secrecy_rate_objective_function(theta_plus, w) - original_secrecy_rate) / epsilon\n",
    "        grad_theta.append(grad_theta_i)\n",
    "\n",
    "    return np.array(grad_theta)\n",
    "\n",
    "def compute_gradient_theta(theta, w):\n",
    "    Z_e_max = [] #Z_e_max[k] = Z_e_max for user k\n",
    "    gamma_e_max = [] #gamma_e_max[k] = gamma_e_max for user k\n",
    "    Z_b = [] #Z_b[k] = Z_bk\n",
    "    gamma_b = [] #gamma_b[k] = gamma_bk\n",
    "    counted = [] #counted[k] = true if gamma_k > gamma_e_max[k]\n",
    "    index_e_max_list = []\n",
    "    #Precalculation\n",
    "    for k in range(number_of_users):\n",
    "        gamma_e = []\n",
    "        for m in range (number_of_eavesdroppers):\n",
    "            Z_em = hie[m] @ np.diag(theta.flatten()) @ Hai + hae[m]\n",
    "            numGamma_em = np.abs(Z_em @ w[k])**2\n",
    "            denGamma_em = 1 + np.sum([np.abs(Z_em @ w[j])**2 for j in range(number_of_users) if j != k])\n",
    "            gamma_em = numGamma_em/denGamma_em\n",
    "            gamma_e.append(gamma_em)\n",
    "        \n",
    "        gamma_e_max.append(max(gamma_e))\n",
    "        index_e_max = gamma_e.index(max(gamma_e))\n",
    "        index_e_max_list.append(index_e_max)\n",
    "        Z_e = hie[index_e_max] @ np.diag(theta.flatten()) @ Hai + hae[index_e_max]\n",
    "        Z_e_max.append(Z_e)\n",
    "\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "\n",
    "        Z_b.append(Z_bk)\n",
    "        gamma_b.append(gamma_bk)\n",
    "\n",
    "        counted.append(gamma_bk > gamma_e[index_e_max])\n",
    "\n",
    "\n",
    "    grad_theta = 0\n",
    "\n",
    "\n",
    "    for k in range(number_of_users):\n",
    "        if (counted[k] == False):\n",
    "            continue\n",
    "\n",
    "        grad_Z_bk_wk_to_theta = (1/sigma) * np.diag(hib[k].flatten()) @ Hai @ w[k]\n",
    "        grad_gamma_bk_to_theta_first_term = (2 * (Z_b[k] @ w[k]) * grad_Z_bk_wk_to_theta) * (1 + sum([np.linalg.norm(Z_b[k] @ w[j])**2 for j in range (number_of_users) if j != k]))\n",
    "        grad_gamma_bk_to_theta_second_term = sum([2 * (Z_b[k] @ w[j]) * grad_Z_bk_wk_to_theta for j in range(number_of_users) if j != k]) * (np.linalg.norm(Z_b[k] @ w[k]) ** 2)\n",
    "        grad_gamma_bk_to_theta_third_term = (1 + sum([np.linalg.norm(Z_b[k] @ w[j]) for j in range (number_of_users) if j != k])**2) ** 2\n",
    "        grad_gamma_bk_to_theta = (grad_gamma_bk_to_theta_first_term - grad_gamma_bk_to_theta_second_term) / grad_gamma_bk_to_theta_third_term\n",
    "\n",
    "        grad_C_bk_to_theta = 1 / ((1 + gamma_b[k]) * np.log(2)) * grad_gamma_bk_to_theta\n",
    "\n",
    "        grad_Z_emax_wk_to_theta = (1/sigma) * np.diag(hie[index_e_max_list[k]].flatten()) @ Hai @ w[k]\n",
    "\n",
    "        grad_gamma_emax_to_theta_first_term = (2 * (Z_e_max[k] @ w[k]) * grad_Z_emax_wk_to_theta) * (1 + sum([np.linalg.norm(Z_e_max[k] @ w[j])**2 for j in range (number_of_users) if j != k]))\n",
    "        grad_gamma_emax_to_theta_second_term = sum([2 * (Z_e_max[k] @ w[j]) * grad_Z_emax_wk_to_theta for j in range(number_of_users) if j != k]) * (np.linalg.norm(Z_e_max[k] @ w[k]) ** 2)\n",
    "        grad_gamma_emax_to_theta_third_term = (1 + sum([np.linalg.norm(Z_e_max[k] @ w[j]) for j in range (number_of_users) if j != k])**2) ** 2\n",
    "        grad_gamma_emax_to_theta = (grad_gamma_emax_to_theta_first_term - grad_gamma_emax_to_theta_second_term) / grad_gamma_emax_to_theta_third_term\n",
    "\n",
    "        grad_C_emax_to_theta = 1 / ((1 + gamma_e_max[k]) * np.log(2)) * grad_gamma_emax_to_theta\n",
    "\n",
    "        grad_theta -= (grad_C_bk_to_theta - grad_C_emax_to_theta)\n",
    "    \n",
    "    return np.array(grad_theta).reshape((1, Nris))\n",
    "    \n",
    "\n",
    "\n",
    "def gradient_descent_update(w, theta, learning_rate, original_secrecy_rate=None):\n",
    "    grad_w = compute_gradient_w(theta, w)\n",
    "    grad_theta = compute_gradient_theta(theta, w)\n",
    "    w_new = [w[i] - learning_rate * grad_w[i] for i in range (number_of_users)]\n",
    "    w_new = normalise_beamforming_vectors(w_new)\n",
    "        \n",
    "    theta_new = theta - learning_rate * grad_theta\n",
    "    theta_new = np.exp(1j * np.angle(theta_new))\n",
    "\n",
    "    return w_new, theta_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Secrecy Rate GD: 8.755948751846821\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 70\n",
      "Iteration 71\n",
      "Iteration 72\n",
      "Iteration 73\n",
      "Iteration 74\n",
      "Iteration 75\n",
      "Iteration 76\n",
      "Iteration 77\n",
      "Iteration 78\n",
      "Iteration 79\n",
      "Iteration 80\n",
      "Iteration 81\n",
      "Iteration 82\n",
      "Iteration 83\n",
      "Iteration 84\n",
      "Iteration 85\n",
      "Iteration 86\n",
      "Iteration 87\n",
      "Iteration 88\n",
      "Iteration 89\n",
      "Iteration 90\n",
      "Iteration 91\n",
      "Iteration 92\n",
      "Iteration 93\n",
      "Iteration 94\n",
      "Iteration 95\n",
      "Iteration 96\n",
      "Iteration 97\n",
      "Iteration 98\n",
      "Iteration 99\n",
      "Iteration 100\n",
      "Iteration 101\n",
      "Iteration 102\n",
      "Iteration 103\n",
      "Iteration 104\n",
      "Iteration 105\n",
      "Iteration 106\n",
      "Iteration 107\n",
      "Iteration 108\n",
      "Iteration 109\n",
      "Iteration 110\n",
      "Iteration 111\n",
      "Iteration 112\n",
      "Iteration 113\n",
      "Iteration 114\n",
      "Iteration 115\n",
      "Iteration 116\n",
      "Iteration 117\n",
      "Iteration 118\n",
      "Iteration 119\n",
      "Iteration 120\n",
      "Iteration 121\n",
      "Iteration 122\n",
      "Iteration 123\n",
      "Iteration 124\n",
      "Iteration 125\n",
      "Iteration 126\n",
      "Iteration 127\n",
      "Iteration 128\n",
      "Iteration 129\n",
      "Iteration 130\n",
      "Iteration 131\n",
      "Iteration 132\n",
      "Iteration 133\n",
      "Iteration 134\n",
      "Iteration 135\n",
      "Iteration 136\n",
      "Iteration 137\n",
      "Iteration 138\n",
      "Iteration 139\n",
      "Iteration 140\n",
      "Iteration 141\n",
      "Iteration 142\n",
      "Iteration 143\n",
      "Iteration 144\n",
      "Iteration 145\n",
      "Iteration 146\n",
      "Iteration 147\n",
      "Iteration 148\n",
      "Iteration 149\n",
      "Iteration 150\n",
      "Iteration 151\n",
      "Iteration 152\n",
      "Iteration 153\n",
      "Iteration 154\n",
      "Iteration 155\n",
      "Iteration 156\n",
      "Iteration 157\n",
      "Iteration 158\n",
      "Iteration 159\n",
      "Iteration 160\n",
      "Iteration 161\n",
      "Iteration 162\n",
      "Iteration 163\n",
      "Iteration 164\n",
      "Iteration 165\n",
      "Iteration 166\n",
      "Iteration 167\n",
      "Iteration 168\n",
      "Iteration 169\n",
      "Iteration 170\n",
      "Iteration 171\n",
      "Iteration 172\n",
      "Iteration 173\n",
      "Iteration 174\n",
      "Iteration 175\n",
      "Iteration 176\n",
      "Iteration 177\n",
      "Iteration 178\n",
      "Iteration 179\n",
      "Iteration 180\n",
      "Iteration 181\n",
      "Iteration 182\n",
      "Iteration 183\n",
      "Iteration 184\n",
      "Iteration 185\n",
      "Iteration 186\n",
      "Iteration 187\n",
      "Iteration 188\n",
      "Iteration 189\n",
      "Iteration 190\n",
      "Iteration 191\n",
      "Iteration 192\n",
      "Iteration 193\n",
      "Iteration 194\n",
      "Iteration 195\n",
      "Iteration 196\n",
      "Iteration 197\n",
      "Iteration 198\n",
      "Iteration 199\n",
      "Iteration 200\n",
      "Iteration 201\n",
      "Iteration 202\n",
      "Iteration 203\n",
      "Iteration 204\n",
      "Iteration 205\n",
      "Iteration 206\n",
      "Iteration 207\n",
      "Iteration 208\n",
      "Iteration 209\n",
      "Iteration 210\n",
      "Iteration 211\n",
      "Iteration 212\n",
      "Iteration 213\n",
      "Iteration 214\n",
      "Iteration 215\n",
      "Iteration 216\n",
      "Iteration 217\n",
      "Iteration 218\n",
      "Iteration 219\n",
      "Iteration 220\n",
      "Iteration 221\n",
      "Iteration 222\n",
      "Iteration 223\n",
      "Iteration 224\n",
      "Iteration 225\n",
      "Iteration 226\n",
      "Iteration 227\n",
      "Iteration 228\n",
      "Iteration 229\n",
      "Iteration 230\n",
      "Iteration 231\n",
      "Iteration 232\n",
      "Iteration 233\n",
      "Iteration 234\n",
      "Iteration 235\n",
      "Iteration 236\n",
      "Iteration 237\n",
      "Iteration 238\n",
      "Iteration 239\n",
      "Iteration 240\n",
      "Iteration 241\n",
      "Iteration 242\n",
      "Iteration 243\n",
      "Iteration 244\n",
      "Iteration 245\n",
      "Iteration 246\n",
      "Iteration 247\n",
      "Iteration 248\n",
      "Iteration 249\n",
      "Iteration 250\n",
      "Iteration 251\n",
      "Iteration 252\n",
      "Iteration 253\n",
      "Iteration 254\n",
      "Iteration 255\n",
      "Iteration 256\n",
      "Iteration 257\n",
      "Iteration 258\n",
      "Iteration 259\n",
      "Iteration 260\n",
      "Iteration 261\n",
      "Iteration 262\n",
      "Iteration 263\n",
      "Iteration 264\n",
      "Iteration 265\n",
      "Iteration 266\n",
      "Iteration 267\n",
      "Iteration 268\n",
      "Iteration 269\n",
      "Iteration 270\n",
      "Iteration 271\n",
      "Iteration 272\n",
      "Iteration 273\n",
      "Iteration 274\n",
      "Iteration 275\n",
      "Iteration 276\n",
      "Iteration 277\n",
      "Iteration 278\n",
      "Iteration 279\n",
      "Iteration 280\n",
      "Iteration 281\n",
      "Iteration 282\n",
      "Iteration 283\n",
      "Iteration 284\n",
      "Iteration 285\n",
      "Iteration 286\n",
      "Iteration 287\n",
      "Iteration 288\n",
      "Iteration 289\n",
      "Iteration 290\n",
      "Iteration 291\n",
      "Iteration 292\n",
      "Iteration 293\n",
      "Iteration 294\n",
      "Iteration 295\n",
      "Iteration 296\n",
      "Iteration 297\n",
      "Iteration 298\n",
      "Iteration 299\n",
      "Iteration 300\n",
      "Iteration 301\n",
      "Iteration 302\n",
      "Iteration 303\n",
      "Iteration 304\n",
      "Iteration 305\n",
      "Iteration 306\n",
      "Converged\n",
      "[np.float64(8.755948751846821), np.float64(8.955763417925015), np.float64(9.12001381685457), np.float64(9.280281176109703), np.float64(9.436787860146898), np.float64(9.58910608741984), np.float64(9.735696987361102), np.float64(9.876656304890526), np.float64(10.012649246885049), np.float64(10.143452487219808), np.float64(10.26872407201717), np.float64(10.386324031672935), np.float64(10.504792318180279), np.float64(10.615627773657824), np.float64(10.722302740816513), np.float64(10.824407481738469), np.float64(10.921925617953036), np.float64(11.01383138164133), np.float64(11.104731176611352), np.float64(11.192029345735822), np.float64(11.273804435572531), np.float64(11.335621588436428), np.float64(11.423662707903915), np.float64(11.48686944216912), np.float64(11.573624617131923), np.float64(11.629321437761266), np.float64(11.70776365716605), np.float64(11.75882688533896), np.float64(11.821130019241707), np.float64(11.879632656535076), np.float64(11.936020044596116), np.float64(11.990350298862516), np.float64(12.042703491051885), np.float64(12.093166112362713), np.float64(12.141819743115388), np.float64(12.18874201302674), np.float64(12.234006937844708), np.float64(12.27768506934487), np.float64(12.319843605035956), np.float64(12.360546477066606), np.float64(12.399854426790471), np.float64(12.437825074033956), np.float64(12.474512990686858), np.float64(12.509969789980982), np.float64(12.544244244842917), np.float64(12.577382447507745), np.float64(12.609428013623056), np.float64(12.640422317178249), np.float64(12.67040472699827), np.float64(12.699412813957107), np.float64(12.72748251223334), np.float64(12.754648236034491), np.float64(12.780942963616999), np.float64(12.80639830140073), np.float64(12.831044537213323), np.float64(12.854910687591687), np.float64(12.878024541387887), np.float64(12.900412700694963), np.float64(12.922100619797082), np.float64(12.943112642966422), np.float64(12.963472042153567), np.float64(12.983201055762759), np.float64(13.0023209296658), np.float64(13.02085196134156), np.float64(13.038813547536284), np.float64(13.056224235188111), np.float64(13.073101774671883), np.float64(13.089463173857819), np.float64(13.105324751185503), np.float64(13.12070218600546), np.float64(13.13561056480388), np.float64(13.150064422480654), np.float64(13.164077778440305), np.float64(13.17766416774594), np.float64(13.190836667905973), np.float64(13.20360792200525), np.float64(13.215990158893364), np.float64(13.227995211057925), np.float64(13.23963453068899), np.float64(13.250919204318242), np.float64(13.261859966312212), np.float64(13.27246721141945), np.float64(13.282751006516234), np.float64(13.292721101659273), np.float64(13.302386940531562), np.float64(13.311757670353677), np.float64(13.320842151323811), np.float64(13.329648965643093), np.float64(13.338186426176621), np.float64(13.346462584794548), np.float64(13.354485240431341), np.float64(13.362261946894835), np.float64(13.369800020450583), np.float64(13.377106547200906), np.float64(13.384188390272971), np.float64(13.391052196825406), np.float64(13.397704404879466), np.float64(13.40415124997756), np.float64(13.410398771670108), np.float64(13.416452819830099), np.float64(13.42231906079403), np.float64(13.428002983327696), np.float64(13.433509904415363), np.float64(13.438844974871357), np.float64(13.44401318477378), np.float64(13.449019368720826), np.float64(13.453868210910958), np.float64(13.458564250049161), np.float64(13.463111884082178), np.float64(13.46751537476646), np.float64(13.471778852073207), np.float64(13.47590631843548), np.float64(13.47990165284287), np.float64(13.483768614789652), np.float64(13.487510848082714), np.float64(13.49084305754087), np.float64(13.512180361023571), np.float64(13.519920538893837), np.float64(13.524406406848092), np.float64(13.534730176542316), np.float64(13.544913928135639), np.float64(13.555011790243766), np.float64(13.565023885907038), np.float64(13.5749497626153), np.float64(13.584790444214846), np.float64(13.594546835494102), np.float64(13.604219834648351), np.float64(13.613810328257177), np.float64(13.623319190024668), np.float64(13.632747281883333), np.float64(13.642095454712344), np.float64(13.65136454903115), np.float64(13.66055539563288), np.float64(13.669668816156793), np.float64(13.678705623601424), np.float64(13.687666622779787), np.float64(13.69655261071901), np.float64(13.70536437700698), np.float64(13.714102704088962), np.float64(13.722768367517572), np.float64(13.731362136159492), np.float64(13.739884772362597), np.float64(13.748337032087132), np.float64(13.756719665004539), np.float64(13.765033414567585), np.float64(13.773279018055261), np.float64(13.781457206595753), np.float64(13.78956870517069), np.float64(13.79761423260371), np.float64(13.805594501535994), np.float64(13.813510218391476), np.float64(13.821362083333952), np.float64(13.8291507902183), np.float64(13.836877026537662), np.float64(13.844541473368327), np.float64(13.852144805313756), np.float64(13.859687690449078), np.float64(13.867170790267176), np.float64(13.87459475962731), np.float64(13.881960246707012), np.float64(13.889267892958019), np.float64(13.896518333066622), np.float64(13.903712194918933), np.float64(13.910850099571306), np.float64(13.917932661226141), np.float64(13.92496048721318), np.float64(13.931934177976363), np.float64(13.938854327066158), np.float64(13.945721521137397), np.float64(13.95253633995246), np.float64(13.959299356389598), np.float64(13.966011136456347), np.float64(13.972672239307729), np.float64(13.979283217269018), np.float64(13.985844615862911), np.float64(13.992356973840792), np.float64(13.99882082321786), np.float64(14.00523668931187), np.float64(14.011605090785213), np.float64(14.01792653969014), np.float64(14.024201541516796), np.float64(14.0304305952439), np.float64(14.036614193391795), np.float64(14.042752822077663), np.float64(14.04884696107265), np.float64(14.05489708386075), np.float64(14.06090365769921), np.float64(14.066859486925207), np.float64(14.076099200607732), np.float64(14.079725974293533), np.float64(14.085291993472717), np.float64(14.090956372225968), np.float64(14.096603996248707), np.float64(14.102214300295525), np.float64(14.10778496688052), np.float64(14.11331612290107), np.float64(14.11880812852686), np.float64(14.124261351907776), np.float64(14.129676157269845), np.float64(14.135052904464482), np.float64(14.140391949020584), np.float64(14.145693642222568), np.float64(14.150958331187981), np.float64(14.156186358944536), np.float64(14.16137806450671), np.float64(14.16653378295195), np.float64(14.171653845496389), np.float64(14.17673857957013), np.float64(14.181788308892028), np.float64(14.186803353543912), np.float64(14.191784030044289), np.float64(14.196730651421364), np.float64(14.201643527285437), np.float64(14.206522963900563), np.float64(14.21136926425538), np.float64(14.216182728133107), np.float64(14.22096365218059), np.float64(14.225712329976282), np.float64(14.230429052097161), np.float64(14.235114106184362), np.float64(14.23976777700754), np.float64(14.244390346527798), np.float64(14.248982093959032), np.float64(14.253543295827695), np.float64(14.258074226030686), np.float64(14.262575155891435), np.float64(14.26704635421388), np.float64(14.271488087334346), np.float64(14.275900619171097), np.float64(14.2802842112715), np.float64(14.284639122856643), np.float64(14.288965610863308), np.float64(14.293263929983139), np.float64(14.297534332698955), np.float64(14.301777069318033), np.float64(14.305992388002348), np.float64(14.310180534795606), np.float64(14.314310576971344), np.float64(14.316032086917081), np.float64(14.323473299339389), np.float64(14.326608465346066), np.float64(14.328428618472621), np.float64(14.335655110479296), np.float64(14.33860351574305), np.float64(14.340610060131715), np.float64(14.347603761139275), np.float64(14.350370634387147), np.float64(14.352590578585627), np.float64(14.359327883000741), np.float64(14.361916696041135), np.float64(14.364374083817994), np.float64(14.370833766113362), np.float64(14.37324804896545), np.float64(14.375963881478771), np.float64(14.382127555550957), np.float64(14.384370903361523), np.float64(14.387362915558523), np.float64(14.393215239282394), np.float64(14.39529131366971), np.float64(14.398573937549752), np.float64(14.404102634560571), np.float64(14.40601515803327), np.float64(14.409599630939898), np.float64(14.41479537528602), np.float64(14.41654811717297), np.float64(14.420442692541156), np.float64(14.425298900513791), np.float64(14.426895654236084), np.float64(14.431105877761174), np.float64(14.435618444356013), np.float64(14.437062997074634), np.float64(14.4415920189573), np.float64(14.445759027639705), np.float64(14.447055124183544), np.float64(14.451904025666506), np.float64(14.455725451728362), np.float64(14.456876755203727), np.float64(14.462044873961826), np.float64(14.465522294872924), np.float64(14.466532346499978), np.float64(14.472017590308411), np.float64(14.475134258142111), np.float64(14.478447233017459), np.float64(14.481418863591188), np.float64(14.484933553991844), np.float64(14.48763174599124), np.float64(14.49134826616911), np.float64(14.493777370068209), np.float64(14.497692548425842), np.float64(14.499856304877754), np.float64(14.5039673217541), np.float64(14.505869632961412), np.float64(14.510173453983771), np.float64(14.511818398370421), np.float64(14.516311810956212), np.float64(14.517703597643331), np.float64(14.52238325545083), np.float64(14.523526182121088), np.float64(14.528388645639955), np.float64(14.529287060225489), np.float64(14.534328833778407), np.float64(14.534987099756117), np.float64(14.540204665099575), np.float64(14.5406271301672), np.float64(14.546016976897869), np.float64(14.546207944786252), np.float64(14.55176659777728)]\n",
      "Final Secrecy Rate GD: 12.478302842104798\n",
      "0.9032386893457283 1.6241032968143696 1.2011937791975575 1.750521980696132 1.005642502015856 1.0310120835793557 0.9995312736123375 1.0556520929204778 1.7531532713511269 2.772873963487207 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11\\AppData\\Local\\Temp\\ipykernel_6980\\3033746169.py:50: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(float(C_bk), end = \" \")\n"
     ]
    }
   ],
   "source": [
    "# Reseed first\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Gradient Descent Algorithm\n",
    "num_cycles = 500\n",
    "learning_rate = 0.01\n",
    "theta_GD = generate_random_theta()\n",
    "w_GD = generate_random_beamforming_vectors()\n",
    "theta_GD, w_GD = repair(theta_GD, w_GD)\n",
    "print(\"Initial Secrecy Rate GD:\", secrecy_rate_objective_function(theta_GD, w_GD))\n",
    "current_secrecy_rate = secrecy_rate_objective_function(theta_GD, w_GD)\n",
    "\n",
    "GD_results = []\n",
    "GD_results.append(current_secrecy_rate)\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    print(\"Iteration\", i)\n",
    "    print(\"Secrecy Rate:\", current_secrecy_rate)\n",
    "    w_new, theta_new = gradient_descent_update(w_GD, theta_GD, learning_rate, original_secrecy_rate=current_secrecy_rate)\n",
    "    #if check_validity(theta_new, w_new) == False:\n",
    "    #    print(\"Stop by invalidity\")\n",
    "    #    break\n",
    "    new_secrecy_rate = secrecy_rate_objective_function(theta_new, w_new)\n",
    "    if (new_secrecy_rate - current_secrecy_rate) < 1e-9:\n",
    "        print(\"Converged\")\n",
    "        break\n",
    "    w_GD = w_new\n",
    "    theta_GD = theta_new\n",
    "    GD_results.append(new_secrecy_rate)\n",
    "    current_secrecy_rate = new_secrecy_rate\n",
    "\n",
    "theta_GD, w_GD = repair(theta_GD, w_GD)\n",
    "#print(GD_results)\n",
    "print(\"Final Secrecy Rate GD:\", secrecy_rate_objective_function(theta_GD, w_GD))\n",
    "print_users_Cbk(theta_GD, w_GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Swarm Optimization (PSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSOParticle:\n",
    "  def __init__(self) -> None:\n",
    "    self.theta = generate_random_theta_angles(Nris)\n",
    "    self.w = generate_random_beamforming_vectors()\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "    self.best_theta = deepcopy(self.theta)\n",
    "    self.best_w = deepcopy(self.w)\n",
    "    self.best_secrecy_rate = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.best_theta), self.best_w)\n",
    "    self.current_secrecy_rate = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.theta), self.w)\n",
    "    self.velocity_theta = np.zeros((1, Nris))\n",
    "    self.velocity_w = [np.zeros((N, 1)) for i in range(number_of_users)]\n",
    "\n",
    "  \n",
    "  def update_velocity(self, inertia, c1, c2, global_best_theta, global_best_w):\n",
    "    r1 = np.random.rand()\n",
    "    r2 = np.random.rand()\n",
    "    self.velocity_theta = inertia * self.velocity_theta + c1 * r1 * (self.best_theta - self.theta) + c2 * r2 * (global_best_theta - self.theta)\n",
    "    self.velocity_w = [inertia * self.velocity_w[i] + c1 * r1 * (self.best_w[i] - self.w[i]) + c2 * r2 * (global_best_w[i] - self.w[i]) for i in range(number_of_users)]\n",
    "\n",
    "  def update_position(self):\n",
    "    self.theta = self.theta + self.velocity_theta\n",
    "    self.w = [self.w[i] + self.velocity_w[i] for i in range(number_of_users)]\n",
    "    self.w = normalise_beamforming_vectors(self.w)\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "\n",
    "  def update_velocity_theta(self, inertia, c1, c2, global_best_theta): #Used for PSO_GD\n",
    "    self.velocity_theta = inertia * self.velocity_theta + c1 * np.random.rand() * (self.best_theta - self.theta) + c2 * np.random.rand() * (global_best_theta - self.theta)\n",
    "  \n",
    "  def update_position_theta(self): #Used for PSO_GD\n",
    "    self.theta = self.theta + self.velocity_theta\n",
    "\n",
    "  def update_best(self):\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "    self.current_secrecy_rate = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.theta), self.w)\n",
    "    if self.current_secrecy_rate > self.best_secrecy_rate:\n",
    "      self.best_secrecy_rate = self.current_secrecy_rate\n",
    "      self.best_theta = deepcopy(self.theta)\n",
    "      self.best_w = deepcopy(self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_inertia(i: int, max_iter: int, inertia_max: float, inertia_min: float) -> float:\n",
    "  E_t = float((max_iter - i - 1)/max_iter)\n",
    "  inertia = inertia_min + (inertia_max - inertia_min) * (2 /(1 + (np.e ** (-5 * E_t))) - 1)\n",
    "  return inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_optimize_w_theta(max_iter: int, num_particles: int, w_min: float, w_max: float, c1: float, c2: float):\n",
    "  particles = [PSOParticle() for _ in range(num_particles)]\n",
    "  global_best_secrecy_rate = -np.inf\n",
    "  global_best_theta = np.zeros((1, Nris))\n",
    "  global_best_w = [np.zeros((N, 1)) for i in range(number_of_users)]\n",
    "\n",
    "  results_secrecy_rate = []\n",
    "\n",
    "  for particle in particles:\n",
    "    if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "      global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "      global_best_theta = deepcopy(particle.best_theta)\n",
    "      global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "  results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "\n",
    "  for iteration in range(max_iter):\n",
    "    print(\"iteration =\", iteration, global_best_secrecy_rate)\n",
    "    inertia = dynamic_inertia(iteration, max_iter, w_max, w_min)\n",
    "\n",
    "    for particle in particles:\n",
    "      particle.update_velocity(inertia, c1, c2, global_best_theta, global_best_w)\n",
    "      particle.update_position()\n",
    "      particle.update_best()\n",
    "\n",
    "      if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "        global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "        global_best_theta = deepcopy(particle.best_theta)\n",
    "        global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "    results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "   \n",
    "\n",
    "  return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0 10.473586752465723\n",
      "iteration = 1 10.639077960878227\n",
      "iteration = 2 10.929530880384124\n",
      "iteration = 3 10.929530880384124\n",
      "iteration = 4 11.040664599971054\n",
      "iteration = 5 11.040664599971054\n",
      "iteration = 6 11.040664599971054\n",
      "iteration = 7 11.06829799281468\n",
      "iteration = 8 11.06829799281468\n",
      "iteration = 9 11.141282446730674\n",
      "iteration = 10 11.141282446730674\n",
      "iteration = 11 11.141282446730674\n",
      "iteration = 12 11.141282446730674\n",
      "iteration = 13 11.141282446730674\n",
      "iteration = 14 11.141282446730674\n",
      "iteration = 15 11.141282446730674\n",
      "iteration = 16 11.141282446730674\n",
      "iteration = 17 11.141282446730674\n",
      "iteration = 18 11.141282446730674\n",
      "iteration = 19 11.141282446730674\n",
      "iteration = 20 11.141282446730674\n",
      "iteration = 21 11.141282446730674\n",
      "iteration = 22 11.17861302985265\n",
      "iteration = 23 11.17861302985265\n",
      "iteration = 24 11.341085129228958\n",
      "iteration = 25 11.341085129228958\n",
      "iteration = 26 11.341085129228958\n",
      "iteration = 27 11.341085129228958\n",
      "iteration = 28 11.341085129228958\n",
      "iteration = 29 11.341085129228958\n",
      "iteration = 30 11.341085129228958\n",
      "iteration = 31 11.426925802362595\n",
      "iteration = 32 11.426925802362595\n",
      "iteration = 33 11.426925802362595\n",
      "iteration = 34 11.426925802362595\n",
      "iteration = 35 11.426925802362595\n",
      "iteration = 36 11.426925802362595\n",
      "iteration = 37 11.426925802362595\n",
      "iteration = 38 11.426925802362595\n",
      "iteration = 39 11.74655082053031\n",
      "iteration = 40 11.74655082053031\n",
      "iteration = 41 11.74655082053031\n",
      "iteration = 42 11.74655082053031\n",
      "iteration = 43 11.74655082053031\n",
      "iteration = 44 11.74655082053031\n",
      "iteration = 45 11.74655082053031\n",
      "iteration = 46 11.74655082053031\n",
      "iteration = 47 11.74655082053031\n",
      "iteration = 48 11.74655082053031\n",
      "iteration = 49 11.74655082053031\n",
      "iteration = 50 11.74655082053031\n",
      "iteration = 51 11.74655082053031\n",
      "iteration = 52 11.74655082053031\n",
      "iteration = 53 11.74655082053031\n",
      "iteration = 54 11.74655082053031\n",
      "iteration = 55 11.74655082053031\n",
      "iteration = 56 11.74655082053031\n",
      "iteration = 57 11.74655082053031\n",
      "iteration = 58 11.74655082053031\n",
      "iteration = 59 11.74655082053031\n",
      "iteration = 60 11.74655082053031\n",
      "iteration = 61 11.74655082053031\n",
      "iteration = 62 11.74655082053031\n",
      "iteration = 63 11.74655082053031\n",
      "iteration = 64 11.74655082053031\n",
      "iteration = 65 11.74655082053031\n",
      "iteration = 66 11.74655082053031\n",
      "iteration = 67 11.74655082053031\n",
      "iteration = 68 11.74655082053031\n",
      "iteration = 69 11.74655082053031\n",
      "iteration = 70 11.74655082053031\n",
      "iteration = 71 11.74655082053031\n",
      "iteration = 72 11.74655082053031\n",
      "iteration = 73 11.74655082053031\n",
      "iteration = 74 11.74655082053031\n",
      "iteration = 75 11.74655082053031\n",
      "iteration = 76 11.74655082053031\n",
      "iteration = 77 11.74655082053031\n",
      "iteration = 78 11.74655082053031\n",
      "iteration = 79 11.74655082053031\n",
      "iteration = 80 11.74655082053031\n",
      "iteration = 81 11.74655082053031\n",
      "iteration = 82 11.74655082053031\n",
      "iteration = 83 11.74655082053031\n",
      "iteration = 84 11.74655082053031\n",
      "iteration = 85 11.74655082053031\n",
      "iteration = 86 11.74655082053031\n",
      "iteration = 87 11.74655082053031\n",
      "iteration = 88 11.74655082053031\n",
      "iteration = 89 11.74655082053031\n",
      "iteration = 90 11.74655082053031\n",
      "iteration = 91 11.74655082053031\n",
      "iteration = 92 11.74655082053031\n",
      "iteration = 93 11.74655082053031\n",
      "iteration = 94 11.74655082053031\n",
      "iteration = 95 11.74655082053031\n",
      "iteration = 96 11.900189384858775\n",
      "iteration = 97 11.900189384858775\n",
      "iteration = 98 11.900189384858775\n",
      "iteration = 99 11.900189384858775\n",
      "iteration = 100 11.900189384858775\n",
      "iteration = 101 11.900189384858775\n",
      "iteration = 102 11.900189384858775\n",
      "iteration = 103 11.900189384858775\n",
      "iteration = 104 11.900189384858775\n",
      "iteration = 105 11.95191549706279\n",
      "iteration = 106 11.95191549706279\n",
      "iteration = 107 11.95191549706279\n",
      "iteration = 108 11.95191549706279\n",
      "iteration = 109 12.01520104066287\n",
      "iteration = 110 12.01520104066287\n",
      "iteration = 111 12.01520104066287\n",
      "iteration = 112 12.01520104066287\n",
      "iteration = 113 12.01520104066287\n",
      "iteration = 114 12.01520104066287\n",
      "iteration = 115 12.01520104066287\n",
      "iteration = 116 12.01520104066287\n",
      "iteration = 117 12.01520104066287\n",
      "iteration = 118 12.01520104066287\n",
      "iteration = 119 12.01520104066287\n",
      "iteration = 120 12.01520104066287\n",
      "iteration = 121 12.01520104066287\n",
      "iteration = 122 12.01520104066287\n",
      "iteration = 123 12.01520104066287\n",
      "iteration = 124 12.01520104066287\n",
      "iteration = 125 12.01520104066287\n",
      "iteration = 126 12.01520104066287\n",
      "iteration = 127 12.1065378460584\n",
      "iteration = 128 12.1065378460584\n",
      "iteration = 129 12.111650231176949\n",
      "iteration = 130 12.111650231176949\n",
      "iteration = 131 12.111650231176949\n",
      "iteration = 132 12.111650231176949\n",
      "iteration = 133 12.111650231176949\n",
      "iteration = 134 12.111650231176949\n",
      "iteration = 135 12.111650231176949\n",
      "iteration = 136 12.111650231176949\n",
      "iteration = 137 12.186825215621152\n",
      "iteration = 138 12.186825215621152\n",
      "iteration = 139 12.2207788080075\n",
      "iteration = 140 12.223451810089037\n",
      "iteration = 141 12.223451810089037\n",
      "iteration = 142 12.223451810089037\n",
      "iteration = 143 12.223451810089037\n",
      "iteration = 144 12.223451810089037\n",
      "iteration = 145 12.223451810089037\n",
      "iteration = 146 12.223451810089037\n",
      "iteration = 147 12.223451810089037\n",
      "iteration = 148 12.223451810089037\n",
      "iteration = 149 12.223451810089037\n",
      "iteration = 150 12.223451810089037\n",
      "iteration = 151 12.223451810089037\n",
      "iteration = 152 12.223451810089037\n",
      "iteration = 153 12.224819497926847\n",
      "iteration = 154 12.224819497926847\n",
      "iteration = 155 12.224819497926847\n",
      "iteration = 156 12.224819497926847\n",
      "iteration = 157 12.224819497926847\n",
      "iteration = 158 12.224819497926847\n",
      "iteration = 159 12.250092563644456\n",
      "iteration = 160 12.250092563644456\n",
      "iteration = 161 12.250092563644456\n",
      "iteration = 162 12.250092563644456\n",
      "iteration = 163 12.250092563644456\n",
      "iteration = 164 12.250092563644456\n",
      "iteration = 165 12.250092563644456\n",
      "iteration = 166 12.250092563644456\n",
      "iteration = 167 12.250092563644456\n",
      "iteration = 168 12.250092563644456\n",
      "iteration = 169 12.30411971094843\n",
      "iteration = 170 12.420120721992854\n",
      "iteration = 171 12.420120721992854\n",
      "iteration = 172 12.420120721992854\n",
      "iteration = 173 12.420120721992854\n",
      "iteration = 174 12.420120721992854\n",
      "iteration = 175 12.420120721992854\n",
      "iteration = 176 12.423007756858016\n",
      "iteration = 177 12.423007756858016\n",
      "iteration = 178 12.423007756858016\n",
      "iteration = 179 12.446842790446818\n",
      "iteration = 180 12.446842790446818\n",
      "iteration = 181 12.44702250625039\n",
      "iteration = 182 12.44702250625039\n",
      "iteration = 183 12.44702250625039\n",
      "iteration = 184 12.44702250625039\n",
      "iteration = 185 12.44702250625039\n",
      "iteration = 186 12.476866173861348\n",
      "iteration = 187 12.476866173861348\n",
      "iteration = 188 12.476866173861348\n",
      "iteration = 189 12.476866173861348\n",
      "iteration = 190 12.476866173861348\n",
      "iteration = 191 12.476866173861348\n",
      "iteration = 192 12.476866173861348\n",
      "iteration = 193 12.476866173861348\n",
      "iteration = 194 12.476866173861348\n",
      "iteration = 195 12.476866173861348\n",
      "iteration = 196 12.476866173861348\n",
      "iteration = 197 12.476866173861348\n",
      "iteration = 198 12.476866173861348\n",
      "iteration = 199 12.476866173861348\n",
      "Initial Secrecy Rate PSO: 8.760058732423133\n",
      "[np.float64(8.760058732423133), np.float64(10.473586752465723), np.float64(10.639077960878227), np.float64(10.929530880384124), np.float64(10.929530880384124), np.float64(11.040664599971054), np.float64(11.040664599971054), np.float64(11.040664599971054), np.float64(11.06829799281468), np.float64(11.06829799281468), np.float64(11.141282446730674), np.float64(11.141282446730674), np.float64(11.141282446730674), np.float64(11.141282446730674), np.float64(11.141282446730674), np.float64(11.141282446730674), np.float64(11.141282446730674), np.float64(11.141282446730674), np.float64(11.141282446730674), np.float64(11.141282446730674), np.float64(11.141282446730674), np.float64(11.141282446730674), np.float64(11.141282446730674), np.float64(11.17861302985265), np.float64(11.17861302985265), np.float64(11.341085129228958), np.float64(11.341085129228958), np.float64(11.341085129228958), np.float64(11.341085129228958), np.float64(11.341085129228958), np.float64(11.341085129228958), np.float64(11.341085129228958), np.float64(11.426925802362595), np.float64(11.426925802362595), np.float64(11.426925802362595), np.float64(11.426925802362595), np.float64(11.426925802362595), np.float64(11.426925802362595), np.float64(11.426925802362595), np.float64(11.426925802362595), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.74655082053031), np.float64(11.900189384858775), np.float64(11.900189384858775), np.float64(11.900189384858775), np.float64(11.900189384858775), np.float64(11.900189384858775), np.float64(11.900189384858775), np.float64(11.900189384858775), np.float64(11.900189384858775), np.float64(11.900189384858775), np.float64(11.95191549706279), np.float64(11.95191549706279), np.float64(11.95191549706279), np.float64(11.95191549706279), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.01520104066287), np.float64(12.1065378460584), np.float64(12.1065378460584), np.float64(12.111650231176949), np.float64(12.111650231176949), np.float64(12.111650231176949), np.float64(12.111650231176949), np.float64(12.111650231176949), np.float64(12.111650231176949), np.float64(12.111650231176949), np.float64(12.111650231176949), np.float64(12.186825215621152), np.float64(12.186825215621152), np.float64(12.2207788080075), np.float64(12.223451810089037), np.float64(12.223451810089037), np.float64(12.223451810089037), np.float64(12.223451810089037), np.float64(12.223451810089037), np.float64(12.223451810089037), np.float64(12.223451810089037), np.float64(12.223451810089037), np.float64(12.223451810089037), np.float64(12.223451810089037), np.float64(12.223451810089037), np.float64(12.223451810089037), np.float64(12.223451810089037), np.float64(12.224819497926847), np.float64(12.224819497926847), np.float64(12.224819497926847), np.float64(12.224819497926847), np.float64(12.224819497926847), np.float64(12.224819497926847), np.float64(12.250092563644456), np.float64(12.250092563644456), np.float64(12.250092563644456), np.float64(12.250092563644456), np.float64(12.250092563644456), np.float64(12.250092563644456), np.float64(12.250092563644456), np.float64(12.250092563644456), np.float64(12.250092563644456), np.float64(12.250092563644456), np.float64(12.30411971094843), np.float64(12.420120721992854), np.float64(12.420120721992854), np.float64(12.420120721992854), np.float64(12.420120721992854), np.float64(12.420120721992854), np.float64(12.420120721992854), np.float64(12.423007756858016), np.float64(12.423007756858016), np.float64(12.423007756858016), np.float64(12.446842790446818), np.float64(12.446842790446818), np.float64(12.44702250625039), np.float64(12.44702250625039), np.float64(12.44702250625039), np.float64(12.44702250625039), np.float64(12.44702250625039), np.float64(12.476866173861348), np.float64(12.476866173861348), np.float64(12.476866173861348), np.float64(12.476866173861348), np.float64(12.476866173861348), np.float64(12.476866173861348), np.float64(12.476866173861348), np.float64(12.476866173861348), np.float64(12.476866173861348), np.float64(12.476866173861348), np.float64(12.476866173861348), np.float64(12.476866173861348), np.float64(12.476866173861348), np.float64(12.476866173861348)]\n",
      "Final Secrecy Rate PSO: 12.476866173861348\n"
     ]
    }
   ],
   "source": [
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# PSO Algorithm\n",
    "max_iter = 200\n",
    "num_particles = 100\n",
    "w_min = 0.5\n",
    "w_max = 0.9\n",
    "c1 = 1.5\n",
    "c2 = 1.5\n",
    "\n",
    "PSO_results = PSO_optimize_w_theta(max_iter, num_particles, w_min, w_max, c1, c2)\n",
    "print(\"Initial Secrecy Rate PSO:\", PSO_results[0])\n",
    "print(PSO_results)\n",
    "print(\"Final Secrecy Rate PSO:\", PSO_results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm (GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAIndividual:\n",
    "  def __init__(self, theta: np.ndarray[np.float64] = None, w: np.ndarray[np.complex128] = None) -> None:\n",
    "    if theta is None or w is None:\n",
    "      self.theta = generate_random_theta_angles(Nris)\n",
    "      self.w = generate_random_beamforming_vectors()\n",
    "    else:\n",
    "      self.theta = theta\n",
    "      self.w = w\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "    self.update_fitness()\n",
    "  \n",
    "  def update_fitness(self):\n",
    "    self.fitness = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.theta), self.w)\n",
    "\n",
    "\n",
    "class GAPopulation:\n",
    "  def __init__(self, population_size: int, crossover_rate: float = 0.85, mutation_rate: float = 0.3) -> None:\n",
    "    self.population_size = population_size\n",
    "    self.individuals = [GAIndividual() for _ in range(population_size)]\n",
    "    self.crossover_rate = crossover_rate\n",
    "    self.mutation_rate = mutation_rate\n",
    "\n",
    "  def sort_population(self):\n",
    "    self.individuals.sort(key=lambda x: x.fitness, reverse=True)\n",
    "\n",
    "  def filter_population(self):\n",
    "    self.sort_population()\n",
    "    self.individuals = self.individuals[:self.population_size]\n",
    "\n",
    "  def add_individual(self, individual: GAIndividual):\n",
    "    self.individuals.append(individual)\n",
    "\n",
    "  def select_parents(self) -> tuple[GAIndividual, GAIndividual]:\n",
    "    parents = np.random.choice(self.individuals, 2, replace=False)\n",
    "    return parents[0], parents[1]\n",
    "  \n",
    "  def crossover(self, parent1: GAIndividual, parent2: GAIndividual) -> GAIndividual:\n",
    "    theta1, w1 = parent1.theta, parent1.w\n",
    "    theta2, w2 = parent2.theta, parent2.w\n",
    "    theta_child = (theta1 + theta2) / 2\n",
    "    w_child = [(w1[i] + w2[i]) / 2 for i in range(number_of_users)]\n",
    "    w_child = normalise_beamforming_vectors(w_child)\n",
    "    theta_child, w_child = repair(theta_child, w_child)\n",
    "    return GAIndividual(theta_child, w_child)\n",
    "  \n",
    "  def mutate(self, individual: GAIndividual) -> GAIndividual:\n",
    "    if np.random.rand() < self.mutation_rate:\n",
    "      mutation_index = np.random.randint(0, Nris)\n",
    "      individual.theta[0, mutation_index] = np.random.uniform(-np.pi, np.pi)\n",
    "      mutation_index = np.random.randint(len(individual.w))\n",
    "      individual.w[mutation_index] = generate_random_beamforming_vector()\n",
    "      individual.w = normalise_beamforming_vectors(individual.w)\n",
    "      individual.theta, individual.w = repair(individual.theta, individual.w)\n",
    "      individual.update_fitness()\n",
    "\n",
    "    return individual\n",
    "  \n",
    "def GA_optimize_w_theta(population_size: int, max_iter: int, crossover_rate: float = 0.85, mutation_rate: float = 0.85):\n",
    "  population = GAPopulation(population_size, crossover_rate, mutation_rate)\n",
    "  population.sort_population()\n",
    "  results_secrecy_rate = []\n",
    "  results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "\n",
    "  for iteration in range(max_iter):\n",
    "    print(\"iteration =\", iteration, population.individuals[0].fitness)\n",
    "    # Crossover and mutate\n",
    "    for _ in range(population_size):\n",
    "      if np.random.rand() < population.crossover_rate:\n",
    "        parent1, parent2 = population.select_parents()\n",
    "        child = population.crossover(parent1, parent2)\n",
    "        population.mutate(child)\n",
    "        population.add_individual(child)\n",
    "    # Filter\n",
    "    population.filter_population()\n",
    "    \n",
    "    results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "    print_users_Cbk(theta_angles_to_theta_vector(population.individuals[0].theta), population.individuals[0].w)\n",
    "  return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0 8.760058732423133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11\\AppData\\Local\\Temp\\ipykernel_6980\\3033746169.py:50: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(float(C_bk), end = \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8089470026183772 0.8408753175865881 1.0038259827565315 1.0671650579992258 1.0162096330763284 1.145949646467149 1.0040934691065762 0.9742188464464296 1.405335454544685 1.50302152307082 \n",
      "iteration = 1 10.341293270811377\n",
      "0.8664184979149423 1.4555190692704254 0.8790578961695771 1.0892010351966344 0.9678759950996096 1.5488476349813232 0.9263266017198349 0.9045335947492319 1.0754710329331694 1.032875624168369 \n",
      "iteration = 2 10.365817363916834\n",
      "0.8545399574613476 0.8111624986572953 0.9434846219336533 1.102029724965609 0.9791498567935144 1.0081107910105844 1.0543820408668116 1.2636020467195876 1.5663826818565185 1.4445401989981588 \n",
      "iteration = 3 10.76576233895609\n",
      "0.8547475004181587 0.8958373854554961 1.0208178644315709 1.472067948758249 0.9966914489911842 0.8916957547710249 0.9673613661139026 1.940644351653101 1.2250364205808049 1.0209237515535707 \n",
      "iteration = 4 11.174720756218868\n",
      "0.8459302411016577 0.9661932745324312 1.6138607070324897 1.3039829279493858 0.9559378656511731 1.305195681120719 1.3216220238841963 1.3009054843054764 0.8497997206154618 1.0805759547985432 \n",
      "iteration = 5 11.359274373138064\n",
      "0.8459302411016577 0.9661932745324312 1.6138607070324897 1.3039829279493858 0.9559378656511731 1.3051956811207193 1.3216220238841963 1.3009054843054764 0.8497997206154618 1.0805759547985432 \n",
      "iteration = 6 11.359274373138064\n",
      "0.8459302411016577 0.9661932745324309 1.6138607070324897 1.3039829279493858 0.9559378656511731 1.305195681120719 1.3216220238841963 1.3009054843054764 0.8497997206154618 1.0805759547985432 \n",
      "iteration = 7 11.359274373138064\n",
      "0.8459302411016577 0.9661932745324309 1.6138607070324897 1.3039829279493858 0.9559378656511731 1.305195681120719 1.3216220238841963 1.3009054843054764 0.8497997206154618 1.0805759547985432 \n",
      "iteration = 8 11.359274373138064\n",
      "0.8459302411016577 0.9661932745324309 1.6138607070324897 1.3039829279493858 0.9559378656511732 1.305195681120719 1.3216220238841963 1.3009054843054764 0.8497997206154619 1.0805759547985432 \n",
      "iteration = 9 11.359274373138064\n",
      "0.9240995805275203 1.2408205425656782 1.3823313846392242 1.547299922382145 0.9669159250756225 1.3774056516342126 0.9804914775656857 0.9725953466997397 1.087889727618337 1.0409096995385276 \n",
      "iteration = 10 11.372136453794981\n",
      "0.9505449293728214 0.9268968910756211 1.046670455049983 1.6167230621512108 1.139157646345494 1.0408369567141167 0.8002855252767147 1.115163233228637 1.8528518348213552 1.1067600273521754 \n",
      "iteration = 11 11.455195235393969\n",
      "0.9505449293728214 0.9268968910756211 1.046670455049983 1.6167230621512108 1.139157646345494 1.0408369567141167 0.8002855252767147 1.115163233228637 1.8528518348213552 1.1067600273521752 \n",
      "iteration = 12 11.455195235393969\n",
      "0.9177113854233543 1.091168648796294 1.1965610368444664 1.3998733595600614 0.9815795811769894 1.0954332054480034 0.855573183902183 1.2214160713251008 1.8064287349469619 1.0718756686255133 \n",
      "iteration = 13 11.510085841906136\n",
      "0.9177113854233543 1.091168648796294 1.1965610368444664 1.3998733595600614 0.9815795811769894 1.0954332054480034 0.855573183902183 1.2214160713251008 1.8064287349469619 1.0718756686255133 \n",
      "iteration = 14 11.510085841906136\n",
      "0.8555004828383013 1.0925397421095226 1.5119891588777306 1.2913618664434825 1.0123719623558673 1.0560018001429652 1.0996977192473927 1.3295203498320032 1.5535749076136012 0.9077130979691469 \n",
      "iteration = 15 11.585517729283858\n",
      "0.8555004828383013 1.0925397421095226 1.5119891588777306 1.2913618664434825 1.0123719623558678 1.0560018001429652 1.0996977192473927 1.3295203498320032 1.5535749076136012 0.9077130979691469 \n",
      "iteration = 16 11.585517729283858\n",
      "0.8555004828383013 1.0925397421095226 1.5119891588777306 1.2913618664434825 1.0123719623558673 1.0560018001429652 1.0996977192473927 1.3295203498320032 1.5535749076136012 0.9077130979691469 \n",
      "iteration = 17 11.585517729283858\n",
      "0.8555004828383013 1.0925397421095226 1.5119891588777306 1.2913618664434825 1.0123719623558673 1.0560018001429652 1.0996977192473927 1.3295203498320032 1.5535749076136012 0.9077130979691469 \n",
      "iteration = 18 11.585517729283858\n",
      "0.8555004828383013 1.0925397421095226 1.5119891588777306 1.2913618664434825 1.0123719623558678 1.0560018001429652 1.0996977192473927 1.3295203498320032 1.5535749076136012 0.9077130979691469 \n",
      "iteration = 19 11.585517729283858\n",
      "0.8555004828383013 1.0925397421095226 1.5119891588777306 1.2913618664434825 1.0123719623558678 1.0560018001429652 1.0996977192473927 1.3295203498320032 1.5535749076136012 0.9077130979691469 \n",
      "iteration = 20 11.585517729283858\n",
      "0.8555004828383013 1.0925397421095226 1.5119891588777303 1.2913618664434825 1.0123719623558673 1.0560018001429652 1.0996977192473927 1.3295203498320032 1.5535749076136012 0.9077130979691469 \n",
      "iteration = 21 11.585517729283858\n",
      "0.8555004828383013 1.0925397421095226 1.5119891588777306 1.2913618664434825 1.0123719623558673 1.0560018001429652 1.0996977192473927 1.3295203498320032 1.5535749076136012 0.9077130979691469 \n",
      "iteration = 22 11.585517729283858\n",
      "0.8229791226653801 1.1148763826471995 1.5547358610146464 1.341965275826536 1.0182500351058945 1.052523052378092 1.0312742184644377 1.344484832987904 1.5657443875859824 0.901185588281019 \n",
      "iteration = 23 11.626398913996162\n",
      "0.8307254985133238 1.0880159023354852 1.5296481597753229 1.325229003567865 1.0364496908669443 1.0652020773855655 1.0056374752932737 1.3639301470939742 1.5961287561824042 0.9149221838761055 \n",
      "iteration = 24 11.634488430591418\n",
      "0.8307254985133238 1.0880159023354852 1.5296481597753229 1.325229003567865 1.0364496908669443 1.0652020773855655 1.0056374752932737 1.3639301470939742 1.5961287561824042 0.9149221838761055 \n",
      "iteration = 25 11.634488430591418\n",
      "0.830725498513324 1.0880159023354852 1.5296481597753229 1.3252290035678655 1.0364496908669443 1.0652020773855655 1.0056374752932737 1.3639301470939742 1.5961287561824042 0.9149221838761055 \n",
      "iteration = 26 11.634488430591418\n",
      "0.830725498513324 1.0880159023354852 1.5296481597753229 1.3252290035678655 1.0364496908669443 1.0652020773855655 1.0056374752932737 1.3639301470939742 1.5961287561824042 0.9149221838761055 \n",
      "iteration = 27 11.634488430591418\n",
      "0.830725498513324 1.0880159023354852 1.5296481597753229 1.3252290035678655 1.0364496908669443 1.0652020773855655 1.0056374752932737 1.3639301470939742 1.5961287561824042 0.9149221838761055 \n",
      "iteration = 28 11.634488430591418\n",
      "1.0143998356421637 1.064129959719663 1.5295590806226222 1.3459849434001572 1.0165156175904648 1.0678475958140885 0.9803785544392617 1.3636768091810176 1.4896220229390933 0.988599318154908 \n",
      "iteration = 29 11.735573893519517\n",
      "1.0143998356421637 1.064129959719663 1.5295590806226222 1.3459849434001572 1.0165156175904648 1.0678475958140885 0.9803785544392617 1.3636768091810176 1.4896220229390933 0.988599318154908 \n",
      "iteration = 30 11.735573893519517\n",
      "1.0143998356421637 1.064129959719663 1.5295590806226222 1.3459849434001572 1.0165156175904648 1.0678475958140885 0.9803785544392617 1.3636768091810176 1.4896220229390933 0.988599318154908 \n",
      "iteration = 31 11.735573893519517\n",
      "1.0143998356421637 1.064129959719663 1.5295590806226222 1.3459849434001572 1.0165156175904648 1.0678475958140885 0.9803785544392617 1.3636768091810176 1.4896220229390933 0.988599318154908 \n",
      "iteration = 32 11.735573893519517\n",
      "0.8585935970630119 1.1920603974460493 1.5204497272688067 1.3343403474567945 1.023669604863284 1.0522836890688387 0.9896060098557115 1.3758434164749282 1.5466571745170055 0.9911199251056726 \n",
      "iteration = 33 11.762111998298154\n",
      "0.8585935970630119 1.1920603974460493 1.5204497272688067 1.3343403474567945 1.023669604863284 1.0522836890688387 0.9896060098557115 1.3758434164749282 1.5466571745170055 0.9911199251056726 \n",
      "iteration = 34 11.762111998298154\n",
      "0.8585935970630119 1.1920603974460493 1.5204497272688067 1.3343403474567945 1.023669604863284 1.0522836890688387 0.9896060098557115 1.3758434164749282 1.5466571745170055 0.9911199251056726 \n",
      "iteration = 35 11.762111998298154\n",
      "0.812805903773968 1.1590804074745606 1.5661966615644811 1.3478064326898311 1.0312715234790995 1.0696716694057529 0.9782342795502214 1.3790279035624304 1.5455931520324555 1.0090049736775024 \n",
      "iteration = 36 11.778033609338209\n",
      "0.8223275030742544 1.1596095351961166 1.5695422151136857 1.3582652471347405 1.027279766488459 1.066703640681237 0.9791743018480573 1.373066990436005 1.5344640401029335 1.009014550959262 \n",
      "iteration = 37 11.77834910405411\n",
      "0.8223275030742547 1.1596095351961166 1.5695422151136857 1.3582652471347405 1.027279766488459 1.066703640681237 0.9791743018480573 1.373066990436005 1.5344640401029335 1.009014550959262 \n",
      "iteration = 38 11.77834910405411\n",
      "0.8524408168975472 1.165044508910555 1.4851570333353694 1.3858148968866653 1.104702508973064 1.0610275103281295 0.9517019416167762 1.3759333930311457 1.5780716303348026 0.9783889785049223 \n",
      "iteration = 39 11.814120931605421\n",
      "0.8524408168975472 1.165044508910555 1.4851570333353694 1.3858148968866653 1.1047025089730633 1.0610275103281295 0.9517019416167762 1.3759333930311457 1.5780716303348026 0.9783889785049223 \n",
      "iteration = 40 11.814120931605421\n",
      "0.8614900275514528 1.1215327279424545 1.5102123611340579 1.4025852091828506 1.108288592116571 1.0747294215617895 0.9392754218094537 1.3779808338941222 1.563105447131795 0.9886990340147543 \n",
      "iteration = 41 11.824994180976157\n",
      "0.8614900275514528 1.1215327279424545 1.5102123611340579 1.4025852091828506 1.108288592116571 1.0747294215617895 0.9392754218094537 1.3779808338941222 1.563105447131795 0.9886990340147543 \n",
      "iteration = 42 11.824994180976157\n",
      "0.8614900275514528 1.1215327279424545 1.5102123611340579 1.4025852091828506 1.108288592116571 1.0747294215617895 0.9392754218094537 1.3779808338941222 1.563105447131795 0.9886990340147542 \n",
      "iteration = 43 11.824994180976157\n",
      "0.8614900275514528 1.1215327279424545 1.5102123611340579 1.4025852091828506 1.108288592116571 1.0747294215617895 0.9392754218094537 1.3779808338941222 1.563105447131795 0.9886990340147543 \n",
      "iteration = 44 11.824994180976157\n",
      "0.8747398176962917 1.1682543608818072 1.5323252179046674 1.3677909892582627 1.0512127897746948 1.06661867834453 0.955773581097827 1.3846474178528465 1.5660606611504937 0.9931160019555068 \n",
      "iteration = 45 11.837936548904969\n",
      "0.8747398176962914 1.1682543608818072 1.5323252179046674 1.3677909892582627 1.0512127897746948 1.06661867834453 0.955773581097827 1.3846474178528465 1.5660606611504937 0.9931160019555068 \n",
      "iteration = 46 11.837936548904969\n",
      "0.8747398176962914 1.1682543608818072 1.5323252179046674 1.3677909892582627 1.0512127897746948 1.06661867834453 0.955773581097827 1.3846474178528465 1.5660606611504937 0.9931160019555068 \n",
      "iteration = 47 11.837936548904969\n",
      "0.879590384194988 1.146702142649118 1.534271260650243 1.3800983673496607 1.071330662432214 1.0778797400985871 0.9590366033194101 1.4001010762138206 1.5256156319302692 0.9925988023307585 \n",
      "iteration = 48 11.844357588864076\n",
      "0.879590384194988 1.146702142649118 1.534271260650243 1.3800983673496607 1.071330662432214 1.0778797400985871 0.9590366033194101 1.4001010762138206 1.5256156319302692 0.9925988023307585 \n",
      "iteration = 49 11.844357588864076\n",
      "0.879590384194988 1.146702142649118 1.534271260650243 1.3800983673496607 1.071330662432214 1.0778797400985871 0.9590366033194101 1.4001010762138206 1.5256156319302692 0.9925988023307585 \n",
      "iteration = 50 11.844357588864076\n",
      "0.883116124165773 1.1543856900349772 1.6131539830321113 1.4083658569643522 1.2100998457935113 1.0780763838871594 0.9663848454516797 1.3806710881603783 1.5022512656334799 0.8497138409324262 \n",
      "iteration = 51 11.924377975108772\n",
      "0.8699131240167542 1.1053136029435993 1.6649141489681716 1.39742134027617 1.0828152285985613 1.0397181354970038 0.9372991891099697 1.4349104683557474 1.6620614044944535 0.9438566693570595 \n",
      "iteration = 52 12.01240224754235\n",
      "0.8699131240167542 1.1053136029435993 1.6649141489681716 1.39742134027617 1.0828152285985608 1.0397181354970038 0.9372991891099697 1.4349104683557474 1.6620614044944535 0.9438566693570595 \n",
      "iteration = 53 12.01240224754235\n",
      "0.8699131240167542 1.1053136029435993 1.6649141489681716 1.39742134027617 1.0828152285985613 1.0397181354970038 0.9372991891099697 1.4349104683557474 1.6620614044944535 0.9438566693570595 \n",
      "iteration = 54 12.01240224754235\n",
      "0.869913124016754 1.1053136029435993 1.6649141489681716 1.3974213402761702 1.0828152285985613 1.0397181354970038 0.9372991891099697 1.4349104683557474 1.6620614044944535 0.9438566693570595 \n",
      "iteration = 55 12.01240224754235\n",
      "0.9071351165755912 1.1738226280048978 1.648414029138815 1.0770263755407006 1.070163524706728 1.2136469485001755 1.0643190581790447 1.370249850578876 1.6975439709099225 0.9504983783374821 \n",
      "iteration = 56 12.050610961939887\n",
      "0.9082862347974093 1.1731072755732812 1.6617949013965942 1.080274327010027 1.0901780796221232 1.2091020529672567 1.065067305969877 1.376069894105337 1.700629514613268 0.9246603874264594 \n",
      "iteration = 57 12.06743490245298\n",
      "0.9082862347974093 1.1731072755732812 1.6617949013965942 1.080274327010027 1.0901780796221232 1.2091020529672567 1.065067305969877 1.376069894105337 1.700629514613268 0.9246603874264594 \n",
      "iteration = 58 12.06743490245298\n",
      "0.9102355553870681 1.175817316775851 1.6585376656620914 1.0736700198226532 1.0823697923529898 1.2130713649185272 1.065289269314534 1.3768486801945683 1.7075153362006943 0.9334805530257874 \n",
      "iteration = 59 12.074933671201345\n",
      "0.9096120385759685 1.1741820963160794 1.532233874885826 1.2460418792456813 1.1610775801231266 1.1140147411566832 1.0521605934669742 1.3967497222003695 1.7761455971296838 0.9290147373057399 \n",
      "iteration = 60 12.168920812671477\n",
      "0.9096120385759685 1.1741820963160796 1.532233874885826 1.2460418792456813 1.1610775801231266 1.1140147411566832 1.0521605934669742 1.3967497222003695 1.7761455971296838 0.9290147373057399 \n",
      "iteration = 61 12.168920812671477\n",
      "0.9096120385759685 1.1741820963160796 1.532233874885826 1.2460418792456813 1.1610775801231266 1.114014741156683 1.0521605934669742 1.3967497222003695 1.7761455971296838 0.9290147373057399 \n",
      "iteration = 62 12.168920812671477\n",
      "0.9096120385759685 1.1741820963160794 1.532233874885826 1.2460418792456813 1.1610775801231266 1.1140147411566832 1.0521605934669742 1.3967497222003695 1.7761455971296838 0.9290147373057399 \n",
      "iteration = 63 12.168920812671477\n",
      "0.913623302459519 1.1763392562377417 1.5843875488756793 1.2041817894730606 1.1435418863418705 1.1481767156058185 1.069169955847681 1.3950001610578155 1.7382771161270063 0.9401777275709021 \n",
      "iteration = 64 12.193860928161012\n",
      "0.913623302459519 1.1763392562377417 1.5843875488756793 1.2041817894730606 1.1435418863418705 1.1481767156058185 1.069169955847681 1.3950001610578155 1.7382771161270063 0.9401777275709021 \n",
      "iteration = 65 12.193860928161012\n",
      "0.9136233024595187 1.1763392562377417 1.5843875488756793 1.204181789473061 1.1435418863418705 1.1481767156058185 1.069169955847681 1.3950001610578155 1.7382771161270063 0.9401777275709021 \n",
      "iteration = 66 12.193860928161012\n",
      "0.9138549871178416 1.1755358300498122 1.6078425412419362 1.1542004660485508 1.1294122453737374 1.1495574433211495 1.0832846125802456 1.395192524759231 1.7725216166884774 0.9481136235359227 \n",
      "iteration = 67 12.21043260281351\n",
      "0.913854987117842 1.1755358300498122 1.607842541241936 1.1542004660485508 1.1294122453737374 1.1495574433211495 1.0832846125802456 1.395192524759231 1.7725216166884774 0.9481136235359227 \n",
      "iteration = 68 12.21043260281351\n",
      "0.913854987117842 1.1755358300498122 1.607842541241936 1.1542004660485508 1.1294122453737374 1.1495574433211495 1.0832846125802456 1.395192524759231 1.7725216166884774 0.9481136235359227 \n",
      "iteration = 69 12.21043260281351\n",
      "0.913854987117842 1.1755358300498122 1.607842541241936 1.1542004660485508 1.1294122453737374 1.1495574433211495 1.0832846125802456 1.395192524759231 1.7725216166884774 0.9481136235359227 \n",
      "iteration = 70 12.21043260281351\n",
      "0.9138549871178416 1.1755358300498122 1.607842541241936 1.1542004660485508 1.1294122453737374 1.1495574433211495 1.0832846125802456 1.395192524759231 1.7725216166884774 0.9481136235359227 \n",
      "iteration = 71 12.21043260281351\n",
      "0.913854987117842 1.1755358300498122 1.607842541241936 1.1542004660485508 1.1294122453737374 1.1495574433211495 1.0832846125802456 1.395192524759231 1.7725216166884774 0.9481136235359227 \n",
      "iteration = 72 12.21043260281351\n",
      "0.9138549871178416 1.1755358300498124 1.607842541241936 1.1542004660485508 1.1294122453737374 1.1495574433211495 1.0832846125802456 1.395192524759231 1.7725216166884774 0.9481136235359227 \n",
      "iteration = 73 12.21043260281351\n",
      "0.9138549871178416 1.1755358300498124 1.607842541241936 1.1542004660485508 1.1294122453737374 1.1495574433211495 1.0832846125802456 1.395192524759231 1.7725216166884774 0.9481136235359227 \n",
      "iteration = 74 12.21043260281351\n",
      "0.9128288018286557 1.1752102781269234 1.5713505269212265 1.1985791978803277 1.1472137527424129 1.132346077569123 1.0738910856752863 1.3971220774537676 1.7813605022339716 0.9422002390572993 \n",
      "iteration = 75 12.211665157737674\n",
      "0.9128288018286557 1.1752102781269238 1.5713505269212265 1.1985791978803277 1.1472137527424129 1.132346077569123 1.0738910856752863 1.3971220774537676 1.7813605022339714 0.9422002390572993 \n",
      "iteration = 76 12.211665157737674\n",
      "0.9128288018286557 1.1752102781269234 1.5713505269212265 1.1985791978803277 1.1472137527424129 1.132346077569123 1.0738910856752863 1.3971220774537676 1.7813605022339714 0.9422002390572993 \n",
      "iteration = 77 12.211665157737674\n",
      "0.9243935610677187 1.1676901631145447 1.6171091977458316 1.2288618504322366 1.1444274061949318 1.0266479443915102 1.0623699937025715 1.4404346917190838 1.7896946046535467 0.9402570377447812 \n",
      "iteration = 78 12.221559143848218\n",
      "0.9168078742281658 1.2089541285589236 1.5916846514161056 1.269580583910475 1.1428274467591744 1.121623113729288 0.9869089486473197 1.3767020255629656 1.730887312214617 1.0085543065417875 \n",
      "iteration = 79 12.235075315530196\n",
      "0.9168078742281656 1.2089541285589236 1.5916846514161056 1.269580583910475 1.1428274467591744 1.121623113729288 0.9869089486473197 1.3767020255629656 1.730887312214617 1.0085543065417875 \n",
      "iteration = 80 12.235075315530196\n",
      "0.9166187110656014 1.2088875331995816 1.5927418722990065 1.2670128114027608 1.1418827318912637 1.1226020786072866 0.9876623641045535 1.376468935587014 1.732221938845994 1.0085479659764744 \n",
      "iteration = 81 12.235168822590609\n",
      "0.9177445611720809 1.2092797148420529 1.5879185755060283 1.2729022826309866 1.1443788702216977 1.122144343073785 0.9865540327069124 1.377292050746391 1.7302978688490747 1.0086197192488784 \n",
      "iteration = 82 12.237735183873628\n",
      "0.9143361920225064 1.2093953084751536 1.5889958942482065 1.2731636476482995 1.1431499710608584 1.1240258070523383 0.9884647146132011 1.3738317874631063 1.7319712757049845 1.0147578260632761 \n",
      "iteration = 83 12.24231082373782\n",
      "0.9136550067714744 1.2799054940883567 1.4537701961442642 1.2610602144449272 1.1743761598978473 1.1322329407279774 1.051160895182615 1.313641418312566 1.8251156760023017 0.9865540525935881 \n",
      "iteration = 84 12.273640962034511\n",
      "0.9138716664922303 1.2328588679609764 1.521018050914478 1.248369000406265 1.1640913188719804 1.1299563079059718 1.053409062356342 1.3677087600208924 1.7907407728674745 0.9699767543646091 \n",
      "iteration = 85 12.274292923623776\n",
      "0.9914188592679841 1.2033105642981743 1.4374504732099795 1.2430798886022847 1.1656988908373338 1.1456935540578472 1.0297935596966377 1.4114600834586435 1.791155668329784 1.0262542663844587 \n",
      "iteration = 86 12.328462948983837\n",
      "0.9933472819486626 1.1927105400552154 1.443987982839735 1.2291605179111955 1.1668795085932906 1.1197281960375327 1.0531410391763432 1.430596376462394 1.8100240629548359 1.0072544705285467 \n",
      "iteration = 87 12.329475678403234\n",
      "0.9902649600198509 1.2061871358110754 1.438329660282676 1.2479671450003014 1.1648015466549524 1.1452316008231866 1.0229697379124367 1.4078033205665095 1.7925859645300435 1.0353278079273283 \n",
      "iteration = 88 12.334458458967699\n",
      "0.9876232487285368 1.2010176576919347 1.4359443735787532 1.240508818549378 1.164722451567554 1.1468923760746028 1.0411611800544087 1.4107383246205911 1.7917058694407484 1.031929879711724 \n",
      "iteration = 89 12.334581207730528\n",
      "0.9876232487285368 1.2010176576919347 1.4359443735787532 1.240508818549378 1.164722451567554 1.1468923760746026 1.0411611800544087 1.4107383246205911 1.7917058694407484 1.031929879711724 \n",
      "iteration = 90 12.334581207730528\n",
      "0.9876232487285365 1.2010176576919347 1.4359443735787532 1.240508818549378 1.164722451567554 1.1468923760746026 1.0411611800544087 1.4107383246205911 1.7917058694407484 1.031929879711724 \n",
      "iteration = 91 12.334581207730528\n",
      "0.953726572919414 1.2218370819788482 1.4707692734578406 1.2490418465370228 1.1662837560207244 1.1426891475999077 1.045881990107081 1.3957266738444 1.8055563249083693 1.0121035571629082 \n",
      "iteration = 92 12.34741661636492\n",
      "0.9603748960840861 1.221921460429828 1.461205629959119 1.2484448346987744 1.168008400372612 1.1436412647442669 1.044333753785763 1.3977363128615539 1.8067729802825832 1.0114635293973773 \n",
      "iteration = 93 12.34791090490085\n",
      "0.9603748960840861 1.2219214604298279 1.461205629959119 1.2484448346987744 1.168008400372612 1.1436412647442669 1.044333753785763 1.3977363128615539 1.8067729802825832 1.0114635293973773 \n",
      "iteration = 94 12.34791090490085\n",
      "0.9603748960840861 1.2219214604298279 1.461205629959119 1.2484448346987744 1.168008400372612 1.1436412647442669 1.044333753785763 1.3977363128615539 1.8067729802825832 1.0114635293973773 \n",
      "iteration = 95 12.34791090490085\n",
      "0.9918985173664622 1.2256604301972396 1.5332356583085998 1.0767459093566076 1.1827985128337986 1.1590226601437565 1.1190285413428653 1.4400387759190874 1.7864582573374839 0.9876864400453703 \n",
      "iteration = 96 12.38911078914547\n",
      "0.9918985173664622 1.225660430197239 1.5332356583085998 1.0767459093566076 1.1827985128337986 1.1590226601437565 1.1190285413428653 1.4400387759190874 1.7864582573374839 0.9876864400453703 \n",
      "iteration = 97 12.38911078914547\n",
      "0.9918985173664622 1.225660430197239 1.5332356583085998 1.0767459093566076 1.1827985128337986 1.1590226601437565 1.1190285413428653 1.4400387759190874 1.7864582573374839 0.9876864400453703 \n",
      "iteration = 98 12.38911078914547\n",
      "0.9968962908017128 1.2426583847213963 1.4850061163875963 1.0363169911350303 1.014563115591489 1.074357431109168 1.3261156391970939 1.5352710105410974 1.9769455202652582 0.9393380113112697 \n",
      "iteration = 99 12.495037174125562\n",
      "0.98605368459585 1.256359792507433 1.5046382227831745 0.9466285065983963 1.0533138954551011 1.1207673782373122 1.3087854483126236 1.5416681542617703 1.9563788772039992 0.9624351657806414 \n",
      "iteration = 100 12.512658705167492\n",
      "1.0322028719950989 1.2476440168045746 1.5099819958535103 0.9550461268356851 1.0874907861790413 1.1351931573112115 1.1907996430511856 1.509422156203089 1.9528280720931797 1.015174929497269 \n",
      "iteration = 101 12.51426614447207\n",
      "1.0322028719950989 1.2476440168045746 1.5099819958535103 0.9550461268356851 1.0874907861790413 1.1351931573112115 1.1907996430511856 1.509422156203089 1.9528280720931797 1.015174929497269 \n",
      "iteration = 102 12.51426614447207\n",
      "1.0322028719950989 1.2476440168045746 1.5099819958535103 0.9550461268356851 1.0874907861790413 1.1351931573112115 1.1907996430511856 1.509422156203089 1.9528280720931797 1.015174929497269 \n",
      "iteration = 103 12.51426614447207\n",
      "1.0322028719950986 1.247644016804574 1.5099819958535103 0.9550461268356851 1.0874907861790413 1.1351931573112115 1.1907996430511856 1.509422156203089 1.9528280720931797 1.015174929497269 \n",
      "iteration = 104 12.51426614447207\n",
      "0.9972756234731452 1.2543606089843935 1.5013367411420713 0.9389570192463295 1.0712811089958154 1.1318044485411143 1.2912865867706909 1.5402124410710938 1.9414189587444877 0.973668864423603 \n",
      "iteration = 105 12.51939128129641\n",
      "1.0022615448299006 1.2538005569406934 1.4957215737688707 0.942354383806126 1.061430305393351 1.125607388493997 1.2895307661114441 1.5420694652863889 1.9556301630267008 0.9752587237412234 \n",
      "iteration = 106 12.519946725656421\n",
      "0.9973294634557741 1.2529299593376988 1.5100250768748382 0.9481290941124398 1.056163032397605 1.1135302332305737 1.2998047650152347 1.5411661815534201 1.9572770639845316 0.9692306961469022 \n",
      "iteration = 107 12.52137047375205\n",
      "0.9973294634557741 1.2529299593376988 1.5100250768748382 0.9481290941124398 1.0561630323976055 1.1135302332305737 1.2998047650152347 1.5411661815534201 1.9572770639845316 0.9692306961469023 \n",
      "iteration = 108 12.52137047375205\n",
      "0.9973294634557741 1.2529299593376988 1.5100250768748382 0.9481290941124398 1.056163032397605 1.1135302332305737 1.2998047650152347 1.5411661815534201 1.9572770639845316 0.9692306961469023 \n",
      "iteration = 109 12.52137047375205\n",
      "1.0159979320006793 1.252637554263935 1.5045155649086985 0.9426159645673784 1.0701021199630087 1.1296468595923939 1.2504001643393718 1.5300488045245126 1.9573912364599622 0.9914664987370039 \n",
      "iteration = 110 12.521957703347265\n",
      "1.0159979320006793 1.252637554263935 1.5045155649086985 0.9426159645673784 1.0701021199630087 1.1296468595923939 1.2504001643393718 1.5300488045245126 1.9573912364599622 0.9914664987370039 \n",
      "iteration = 111 12.521957703347265\n",
      "1.0159979320006793 1.252637554263935 1.5045155649086985 0.9426159645673784 1.0701021199630085 1.1296468595923939 1.2504001643393718 1.5300488045245126 1.957391236459962 0.9914664987370039 \n",
      "iteration = 112 12.521957703347265\n",
      "0.9904095513280562 1.3349908565427757 1.5643357698979785 0.9484696191959614 1.093973207913309 1.1042577230395525 1.2437109539232882 1.465160288837176 2.00898588031609 0.9925273269227226 \n",
      "iteration = 113 12.623037867097201\n",
      "0.9904095513280562 1.3349908565427757 1.5643357698979785 0.9484696191959614 1.093973207913309 1.1042577230395525 1.2437109539232882 1.465160288837176 2.00898588031609 0.9925273269227226 \n",
      "iteration = 114 12.623037867097201\n",
      "0.9904095513280562 1.3349908565427757 1.5643357698979785 0.9484696191959614 1.093973207913309 1.1042577230395525 1.2437109539232882 1.465160288837176 2.00898588031609 0.9925273269227226 \n",
      "iteration = 115 12.623037867097201\n",
      "0.9809745983383484 1.2784706985036252 1.4774230175950915 0.9505166750695178 1.181980853738149 1.1136808521609272 1.2477327456253324 1.500665567774394 1.9645915996573362 1.0698624895683548 \n",
      "iteration = 116 12.652295461886398\n",
      "0.981101060013368 1.2782945030442519 1.4785164118646776 0.950671049907869 1.181124313191827 1.1117121627158861 1.2479339567914023 1.5009696277216726 1.9661817606859209 1.0700011445174487 \n",
      "iteration = 117 12.652804950222404\n",
      "0.9808848768902386 1.278157792815588 1.4767235000342154 0.9486837064622355 1.178711456847497 1.111540834196739 1.2507929761457073 1.5037917500412976 1.9691994720270258 1.0687615434010342 \n",
      "iteration = 118 12.653182898143017\n",
      "0.9846893917479824 1.2520975846389044 1.3369466392140315 0.9483189772420367 1.162546588702123 1.1026674378491514 1.3034852206742593 1.6083754050395744 1.9736210505699119 1.111258428144496 \n",
      "iteration = 119 12.665862590793498\n",
      "0.9846893917479825 1.2520975846389044 1.3369466392140315 0.9483189772420371 1.162546588702123 1.1026674378491514 1.3034852206742593 1.6083754050395744 1.9736210505699119 1.1112584281444957 \n",
      "iteration = 120 12.665862590793498\n",
      "0.983842339976673 1.3108860821592334 1.529378230135294 0.9492519669017524 1.146362631374894 1.1124029906719102 1.2618784183179002 1.4944462587524703 1.9929487009950275 1.0388937713297586 \n",
      "iteration = 121 12.701740941982273\n",
      "0.983842339976673 1.3108860821592334 1.529378230135294 0.9492519669017524 1.1463626313748936 1.1124029906719102 1.2618784183179002 1.4944462587524703 1.9929487009950275 1.0388937713297586 \n",
      "iteration = 122 12.701740941982273\n",
      "0.983842339976673 1.3108860821592334 1.529378230135294 0.9492519669017521 1.146362631374894 1.1124029906719102 1.2618784183179002 1.4944462587524703 1.9929487009950275 1.0388937713297586 \n",
      "iteration = 123 12.701740941982273\n",
      "1.0043742451084643 1.2814987085027834 1.4805161728673455 0.9604310049678315 1.0740273954519954 1.1268835015394372 1.2933914801719917 1.5303924512709821 2.049502064954694 1.0412410657957982 \n",
      "iteration = 124 12.725552452049246\n",
      "1.0043742451084638 1.2814987085027834 1.4805161728673453 0.9604310049678315 1.0740273954519954 1.1268835015394372 1.2933914801719917 1.5303924512709821 2.049502064954694 1.0412410657957982 \n",
      "iteration = 125 12.725552452049246\n",
      "1.0043742451084638 1.2814987085027834 1.4805161728673453 0.9604310049678315 1.0740273954519954 1.1268835015394372 1.2933914801719917 1.5303924512709821 2.049502064954694 1.0412410657957982 \n",
      "iteration = 126 12.725552452049246\n",
      "1.0043742451084638 1.2814987085027834 1.4805161728673453 0.9604310049678315 1.0740273954519954 1.1268835015394372 1.2933914801719917 1.5303924512709821 2.049502064954694 1.0412410657957982 \n",
      "iteration = 127 12.725552452049246\n",
      "1.0043742451084638 1.2814987085027834 1.4805161728673453 0.9604310049678315 1.0740273954519954 1.1268835015394372 1.2933914801719917 1.5303924512709821 2.049502064954694 1.0412410657957982 \n",
      "iteration = 128 12.725552452049246\n",
      "0.9960167608190297 1.308165505357587 1.4546368205653253 1.0029093325017564 1.1218508990316785 1.1082118805790908 1.29497831463572 1.6302916327009536 1.9279954282186613 1.0718384471304234 \n",
      "iteration = 129 12.794147749151335\n",
      "0.9960167608190297 1.3081655053575865 1.4546368205653253 1.0029093325017564 1.1218508990316785 1.1082118805790908 1.29497831463572 1.6302916327009536 1.9279954282186613 1.0718384471304234 \n",
      "iteration = 130 12.794147749151335\n",
      "0.9960167608190297 1.308165505357587 1.4546368205653253 1.0029093325017564 1.1218508990316785 1.1082118805790908 1.29497831463572 1.6302916327009536 1.9279954282186613 1.0718384471304234 \n",
      "iteration = 131 12.794147749151335\n",
      "0.9960167608190297 1.308165505357587 1.4546368205653253 1.0029093325017564 1.1218508990316785 1.1082118805790908 1.29497831463572 1.6302916327009536 1.9279954282186613 1.0718384471304234 \n",
      "iteration = 132 12.794147749151335\n",
      "0.9960167608190297 1.3081655053575865 1.4546368205653253 1.0029093325017564 1.1218508990316785 1.1082118805790908 1.29497831463572 1.6302916327009536 1.9279954282186613 1.0718384471304234 \n",
      "iteration = 133 12.794147749151335\n",
      "0.9960167608190297 1.3081655053575865 1.4546368205653253 1.0029093325017564 1.1218508990316785 1.1082118805790908 1.29497831463572 1.6302916327009536 1.9279954282186613 1.0718384471304234 \n",
      "iteration = 134 12.794147749151335\n",
      "0.9960167608190297 1.3081655053575865 1.4546368205653253 1.0029093325017564 1.1218508990316785 1.1082118805790908 1.29497831463572 1.6302916327009536 1.9279954282186613 1.0718384471304234 \n",
      "iteration = 135 12.794147749151335\n",
      "1.037919326395019 1.2724067398093266 1.4867603043693063 1.000964457221011 1.1311144263950623 1.1118982897756104 1.2212504417089525 1.6015983245026804 1.9824647667429824 1.0785435365880238 \n",
      "iteration = 136 12.80547210212442\n",
      "1.014735713244216 1.3253659244176756 1.5713730205464385 1.0667690426165717 1.077999791749904 1.1209388998851053 1.1706784347243768 1.433221314682511 2.187567336257932 1.0869551714701406 \n",
      "iteration = 137 12.937470432288901\n",
      "1.014735713244216 1.3253659244176756 1.5713730205464385 1.0667690426165717 1.077999791749904 1.1209388998851053 1.1706784347243768 1.433221314682511 2.187567336257932 1.0869551714701406 \n",
      "iteration = 138 12.937470432288901\n",
      "1.014735713244216 1.3253659244176756 1.5713730205464385 1.0667690426165717 1.077999791749904 1.1209388998851053 1.1706784347243768 1.433221314682511 2.187567336257932 1.0869551714701406 \n",
      "iteration = 139 12.937470432288901\n",
      "1.014735713244216 1.3253659244176756 1.5713730205464385 1.0667690426165717 1.077999791749904 1.1209388998851053 1.1706784347243768 1.433221314682511 2.187567336257932 1.0869551714701406 \n",
      "iteration = 140 12.937470432288901\n",
      "1.0219691613763173 1.3255488266101916 1.5540131140250888 1.0600990658783567 1.105983432022397 1.1117321308406054 1.205191387417229 1.5251516039223225 2.1621455398296128 0.993372793701901 \n",
      "iteration = 141 12.946167237125774\n",
      "1.0219691613763173 1.3255488266101916 1.5540131140250888 1.0600990658783567 1.1059834320223967 1.1117321308406054 1.205191387417229 1.5251516039223225 2.1621455398296128 0.993372793701901 \n",
      "iteration = 142 12.946167237125774\n",
      "1.0483807821509787 1.3165385179691804 1.4954753760456134 1.0722904748316964 1.0880623637394513 1.162718667466819 1.2019949101938057 1.498183099192688 2.1375562053498682 1.0601877148260455 \n",
      "iteration = 143 12.962556640214071\n",
      "1.0483807821509787 1.3165385179691804 1.4954753760456134 1.0722904748316964 1.0880623637394513 1.162718667466819 1.2019949101938057 1.498183099192688 2.1375562053498682 1.0601877148260455 \n",
      "iteration = 144 12.962556640214071\n",
      "1.0249556619759428 1.2901430915136336 1.537768342412451 1.113366051131719 1.1641238243159964 1.1140580432182994 1.3050621978639936 1.4897547234894457 2.003437364447442 1.0527640160772402 \n",
      "iteration = 145 12.981293676614886\n",
      "1.0740363067919398 1.315635081951242 1.523975670944277 1.0908495685449182 1.1018059289132165 1.1675008024713533 1.0107027958125847 1.4615225844485253 2.249010088485475 1.141679663948063 \n",
      "iteration = 146 13.017683754230431\n",
      "1.0546194500830637 1.3156733041112667 1.556634414086679 1.098633154680534 1.1090089177242854 1.1455727842189416 1.0997008876514158 1.4547799682896783 2.189126231330154 1.1196118759881837 \n",
      "iteration = 147 13.026102976252028\n",
      "1.0974289500963552 1.2863236667259212 1.5293735071093137 1.1036776884935013 1.0915913204266774 1.2506537819175048 1.0855286501920582 1.4842911614825869 2.118123727330867 1.0982982418761065 \n",
      "iteration = 148 13.028143049274437\n",
      "1.0897883855094819 1.3071697792026349 1.5506591510680106 1.0936561790520087 1.1453411287715727 1.2254117443017063 1.1636900485598975 1.5228429298966528 2.1185942621897373 0.9517420745706998 \n",
      "iteration = 149 13.05245858825105\n",
      "1.0897883855094812 1.3071697792026349 1.5506591510680106 1.0936561790520083 1.1453411287715727 1.2254117443017063 1.1636900485598975 1.5228429298966528 2.1185942621897373 0.9517420745706998 \n",
      "iteration = 150 13.05245858825105\n",
      "1.0722414413100188 1.2976106156622063 1.5860740137221165 1.1233970047669395 1.1730550609101307 1.1907386704681728 1.2329680849729912 1.494072741335853 2.0715351087125016 0.9373929324674586 \n",
      "iteration = 151 13.065251284112174\n",
      "1.0718974703054531 1.3011878489013364 1.575354382822248 1.1252147590262898 1.17911097831439 1.183334988642938 1.231140907218462 1.5002217835464193 2.0714134772669666 0.9483621170485098 \n",
      "iteration = 152 13.072917115433828\n",
      "1.0608934724709487 1.3272419584352293 1.5642052348418654 1.1208867052683602 1.1525866395312583 1.1740008207653043 1.1397110897736575 1.4932392745206697 2.1473254708389997 1.0156880394750851 \n",
      "iteration = 153 13.079014830464185\n",
      "1.0608934724709487 1.3272419584352293 1.5642052348418654 1.1208867052683602 1.152586639531258 1.1740008207653043 1.1397110897736575 1.4932392745206697 2.1473254708389997 1.0156880394750856 \n",
      "iteration = 154 13.079014830464185\n",
      "1.070490902863669 1.3140823028405988 1.5769768327916582 1.1232814698503968 1.1680563297721802 1.185968236112716 1.1810169873109886 1.497795860202654 2.1123797442093175 0.967540320728134 \n",
      "iteration = 155 13.082194534837885\n",
      "1.070490902863669 1.3140823028405988 1.5769768327916582 1.1232814698503968 1.1680563297721802 1.185968236112716 1.1810169873109886 1.497795860202654 2.1123797442093175 0.967540320728134 \n",
      "iteration = 156 13.082194534837885\n",
      "1.070490902863669 1.3140823028405988 1.5769768327916582 1.1232814698503968 1.1680563297721802 1.185968236112716 1.1810169873109886 1.497795860202654 2.1123797442093175 0.967540320728134 \n",
      "iteration = 157 13.082194534837885\n",
      "1.0704909028636684 1.3140823028405988 1.5769768327916582 1.1232814698503968 1.1680563297721802 1.185968236112716 1.1810169873109886 1.497795860202654 2.1123797442093175 0.967540320728134 \n",
      "iteration = 158 13.082194534837885\n",
      "1.0583507453733827 1.322913647547063 1.5751309058565885 1.124434112773893 1.1403326314273576 1.1580200266034437 1.1812339608693294 1.5166532662643433 2.1767145379884885 0.9619907824494304 \n",
      "iteration = 159 13.102469978649902\n",
      "1.0583507453733827 1.322913647547063 1.5751309058565885 1.124434112773893 1.1403326314273574 1.1580200266034437 1.1812339608693294 1.5166532662643433 2.1767145379884885 0.9619907824494304 \n",
      "iteration = 160 13.102469978649902\n",
      "1.1075165939553135 1.2616057017566884 1.5896113093614175 1.1124916484475804 1.1200396410715525 1.169786501655467 1.2001169645121716 1.4550629835596305 2.1862795062729843 1.0219568253057782 \n",
      "iteration = 161 13.107094404541423\n",
      "1.0923741188694474 1.2941418156649138 1.5956634960184672 1.12008115033956 1.1339871973044697 1.170271067089751 1.1837148909859245 1.4790554749237905 2.1767399829362293 1.0117731216490986 \n",
      "iteration = 162 13.141886139982063\n",
      "1.0923741188694474 1.2941418156649138 1.5956634960184672 1.12008115033956 1.1339871973044697 1.170271067089751 1.1837148909859245 1.4790554749237905 2.1767399829362293 1.0117731216490986 \n",
      "iteration = 163 13.141886139982063\n",
      "1.0923741188694474 1.2941418156649138 1.5956634960184672 1.12008115033956 1.1339871973044704 1.170271067089751 1.1837148909859245 1.4790554749237905 2.1767399829362293 1.0117731216490986 \n",
      "iteration = 164 13.141886139982063\n",
      "1.0869080671685853 1.298366868045645 1.5947787817429173 1.1224265167621412 1.1352711688174892 1.1700400543582379 1.194759413494197 1.4829061410946627 2.1723448986643206 1.0013281168494512 \n",
      "iteration = 165 13.143184873422806\n",
      "1.0869080671685853 1.2983668680456448 1.5947787817429173 1.1224265167621412 1.1352711688174892 1.1700400543582379 1.194759413494197 1.4829061410946627 2.1723448986643206 1.001328116849451 \n",
      "iteration = 166 13.143184873422806\n",
      "1.0869080671685853 1.298366868045645 1.5947787817429173 1.1224265167621412 1.1352711688174892 1.1700400543582379 1.194759413494197 1.4829061410946627 2.1723448986643206 1.001328116849451 \n",
      "iteration = 167 13.143184873422806\n",
      "1.0869080671685853 1.2983668680456448 1.5947787817429173 1.1224265167621412 1.1352711688174892 1.1700400543582379 1.194759413494197 1.4829061410946627 2.1723448986643206 1.001328116849451 \n",
      "iteration = 168 13.143184873422806\n",
      "1.0869080671685853 1.298366868045645 1.5947787817429173 1.1224265167621412 1.1352711688174892 1.1700400543582379 1.194759413494197 1.4829061410946627 2.1723448986643206 1.001328116849451 \n",
      "iteration = 169 13.143184873422806\n",
      "0.9288062794992668 1.3219585527496727 1.8253386679462298 1.0913778513606285 1.2205740945263113 1.0698098457470928 1.1593327085373542 1.4843486454578512 2.1120007372111496 1.0504633902737652 \n",
      "iteration = 170 13.147241419023093\n",
      "0.9288062794992668 1.3219585527496727 1.8253386679462298 1.0913778513606285 1.2205740945263113 1.0698098457470928 1.1593327085373542 1.4843486454578512 2.1120007372111496 1.0504633902737652 \n",
      "iteration = 171 13.147241419023093\n",
      "0.9760377098283917 1.3575273718935703 1.7226446306578842 1.1122448447918383 1.2214807191862376 1.1306412919565882 1.197682157911396 1.4896706100037787 2.1388287291758177 1.0486385227009727 \n",
      "iteration = 172 13.279192104400934\n",
      "0.98026239209329 1.3519564959739547 1.7241636029064256 1.111058825246579 1.2187259125214553 1.1304396856319354 1.1993528276282093 1.4861193300704962 2.141452769902705 1.0532981357561537 \n",
      "iteration = 173 13.280477491227247\n",
      "0.9814504234638405 1.350297773298588 1.7246770358019847 1.1108433638491735 1.218201372032117 1.1303184813674754 1.1997025793926763 1.484713388601684 2.141860430159068 1.0548504916211834 \n",
      "iteration = 174 13.280518394020392\n",
      "0.9814504234638405 1.350297773298588 1.7246770358019847 1.1108433638491735 1.218201372032117 1.1303184813674754 1.1997025793926763 1.484713388601684 2.141860430159068 1.0548504916211834 \n",
      "iteration = 175 13.280518394020392\n",
      "0.9814504234638405 1.350297773298588 1.7246770358019847 1.1108433638491735 1.218201372032117 1.1303184813674754 1.1997025793926763 1.484713388601684 2.141860430159068 1.0548504916211834 \n",
      "iteration = 176 13.280518394020392\n",
      "0.9814504234638407 1.350297773298588 1.7246770358019847 1.1108433638491735 1.218201372032117 1.1303184813674754 1.1997025793926763 1.484713388601684 2.141860430159068 1.0548504916211834 \n",
      "iteration = 177 13.280518394020392\n",
      "0.9814504234638407 1.350297773298588 1.7246770358019847 1.1108433638491735 1.218201372032117 1.1303184813674754 1.1997025793926763 1.484713388601684 2.141860430159068 1.0548504916211834 \n",
      "iteration = 178 13.280518394020392\n",
      "0.9814504234638405 1.350297773298588 1.7246770358019847 1.1108433638491735 1.218201372032117 1.1303184813674754 1.1997025793926763 1.484713388601684 2.141860430159068 1.0548504916211834 \n",
      "iteration = 179 13.280518394020392\n",
      "1.079928847234948 1.3451418290025219 1.5842617668842125 1.1177927395814866 1.2010746642178154 1.1811832076003397 1.18998282193837 1.4834172889084645 2.1597495946077543 1.060027181001231 \n",
      "iteration = 180 13.28634936097869\n",
      "1.079928847234948 1.3451418290025219 1.5842617668842125 1.1177927395814866 1.2010746642178154 1.1811832076003397 1.18998282193837 1.4834172889084645 2.1597495946077543 1.060027181001231 \n",
      "iteration = 181 13.28634936097869\n",
      "1.042123656592634 1.3367014389820677 1.6334245874602062 1.142782393700598 1.2530306678467074 1.1533471656425465 1.079512475929104 1.5280253190255315 2.197642293697429 1.0580977150181625 \n",
      "iteration = 182 13.30920671867643\n",
      "1.063015973381882 1.3421944430198203 1.6101685272100252 1.1318440026659031 1.2302835274866413 1.167500266271285 1.1331572233921512 1.5086743324566174 2.1822353690265968 1.059580707718115 \n",
      "iteration = 183 13.313150572184007\n",
      "1.0368783969716835 1.3393771532488306 1.6391356207141063 1.1424744141125038 1.2572040631556323 1.1513200481127035 1.080526698843743 1.5284088317154105 2.196289039605533 1.0601023025677656 \n",
      "iteration = 184 13.316219377964655\n",
      "1.034419721888644 1.3410839668048549 1.642162775735616 1.1420088184620454 1.2605853317736653 1.1505567237177077 1.0804571200601019 1.5283281164683449 2.195119523944777 1.0624693103329883 \n",
      "iteration = 185 13.321656275982274\n",
      "1.0152671035821452 1.3480888561458448 1.6666856624387711 1.1395508238267913 1.2752831921055043 1.1418697063327419 1.0811395191589803 1.528337910342695 2.189490265730131 1.0710500515828434 \n",
      "iteration = 186 13.341119515166048\n",
      "1.015267103582145 1.3480888561458448 1.6666856624387711 1.1395508238267913 1.2752831921055043 1.1418697063327419 1.0811395191589803 1.528337910342695 2.189490265730131 1.0710500515828434 \n",
      "iteration = 187 13.341119515166048\n",
      "1.015267103582145 1.3480888561458448 1.6666856624387711 1.1395508238267913 1.2752831921055043 1.1418697063327419 1.0811395191589803 1.528337910342695 2.189490265730131 1.0710500515828434 \n",
      "iteration = 188 13.341119515166048\n",
      "1.015267103582145 1.3480888561458448 1.6666856624387711 1.1395508238267913 1.2752831921055043 1.1418697063327419 1.0811395191589803 1.528337910342695 2.189490265730131 1.0710500515828434 \n",
      "iteration = 189 13.341119515166048\n",
      "1.015267103582145 1.3480888561458448 1.6666856624387711 1.1395508238267913 1.2752831921055043 1.1418697063327419 1.0811395191589803 1.528337910342695 2.189490265730131 1.0710500515828434 \n",
      "iteration = 190 13.341119515166048\n",
      "0.9264902271149202 1.3347954379614937 1.6948777446129906 1.1435789595214285 1.2500601788348695 1.1232094450140275 1.1071639494581478 1.517251447084316 2.3377353342205573 1.070857812315502 \n",
      "iteration = 191 13.393129220634801\n",
      "0.9633583428702088 1.3443020722433998 1.6831856262082039 1.1452342639556599 1.258085783035267 1.1406604235092581 1.12621257811361 1.5230862480891239 2.292836532339721 1.0730270082791162 \n",
      "iteration = 192 13.436370273507213\n",
      "0.9633583428702085 1.3443020722433998 1.6831856262082039 1.14523426395566 1.258085783035267 1.1406604235092581 1.12621257811361 1.5230862480891239 2.292836532339721 1.0730270082791162 \n",
      "iteration = 193 13.436370273507213\n",
      "0.8600185619540973 1.5223686105996543 1.605181520208875 1.126856838992954 1.27058172821893 1.1481232742009688 1.133210606871076 1.5224002596720523 2.348942035354715 1.0259153396303764 \n",
      "iteration = 194 13.449884229228664\n",
      "0.9731815182927234 1.3433998496310022 1.7096052650959206 1.1404478431876677 1.2521247962440574 1.092000245510505 1.1289645785212303 1.5349454679408112 2.3354414988723757 1.059694261595419 \n",
      "iteration = 195 13.456248830299888\n",
      "0.9731815182927234 1.3433998496310022 1.7096052650959206 1.1404478431876677 1.2521247962440574 1.092000245510505 1.1289645785212303 1.5349454679408112 2.3354414988723757 1.059694261595419 \n",
      "iteration = 196 13.456248830299888\n",
      "0.9358319767575451 1.4344066925593655 1.6398200612842913 1.1349191401774548 1.2671568535170024 1.1421044647331726 1.1269715872589436 1.5284913103713411 2.318432348304633 1.0433346557858256 \n",
      "iteration = 197 13.45729134512014\n",
      "0.9358319767575451 1.4344066925593655 1.6398200612842913 1.1349191401774548 1.2671568535170024 1.1421044647331726 1.1269715872589436 1.5284913103713411 2.318432348304633 1.0433346557858252 \n",
      "iteration = 198 13.45729134512014\n",
      "0.9358319767575451 1.4344066925593655 1.6398200612842913 1.1349191401774548 1.2671568535170024 1.1421044647331724 1.1269715872589436 1.5284913103713411 2.318432348304633 1.0433346557858252 \n",
      "iteration = 199 13.45729134512014\n",
      "0.9455017690854437 1.3667808467750795 1.6844183407249822 1.1449717474641596 1.2693070764746948 1.135719462684169 1.116690237632704 1.5310622152388498 2.3102094023248196 1.0667270422623634 \n",
      "Initial Secrecy Rate GA: 8.760058732423133\n",
      "[np.float64(8.760058732423133), np.float64(10.341293270811377), np.float64(10.365817363916834), np.float64(10.76576233895609), np.float64(11.174720756218868), np.float64(11.359274373138064), np.float64(11.359274373138064), np.float64(11.359274373138064), np.float64(11.359274373138064), np.float64(11.359274373138064), np.float64(11.372136453794981), np.float64(11.455195235393969), np.float64(11.455195235393969), np.float64(11.510085841906136), np.float64(11.510085841906136), np.float64(11.585517729283858), np.float64(11.585517729283858), np.float64(11.585517729283858), np.float64(11.585517729283858), np.float64(11.585517729283858), np.float64(11.585517729283858), np.float64(11.585517729283858), np.float64(11.585517729283858), np.float64(11.626398913996162), np.float64(11.634488430591418), np.float64(11.634488430591418), np.float64(11.634488430591418), np.float64(11.634488430591418), np.float64(11.634488430591418), np.float64(11.735573893519517), np.float64(11.735573893519517), np.float64(11.735573893519517), np.float64(11.735573893519517), np.float64(11.762111998298154), np.float64(11.762111998298154), np.float64(11.762111998298154), np.float64(11.778033609338209), np.float64(11.77834910405411), np.float64(11.77834910405411), np.float64(11.814120931605421), np.float64(11.814120931605421), np.float64(11.824994180976157), np.float64(11.824994180976157), np.float64(11.824994180976157), np.float64(11.824994180976157), np.float64(11.837936548904969), np.float64(11.837936548904969), np.float64(11.837936548904969), np.float64(11.844357588864076), np.float64(11.844357588864076), np.float64(11.844357588864076), np.float64(11.924377975108772), np.float64(12.01240224754235), np.float64(12.01240224754235), np.float64(12.01240224754235), np.float64(12.01240224754235), np.float64(12.050610961939887), np.float64(12.06743490245298), np.float64(12.06743490245298), np.float64(12.074933671201345), np.float64(12.168920812671477), np.float64(12.168920812671477), np.float64(12.168920812671477), np.float64(12.168920812671477), np.float64(12.193860928161012), np.float64(12.193860928161012), np.float64(12.193860928161012), np.float64(12.21043260281351), np.float64(12.21043260281351), np.float64(12.21043260281351), np.float64(12.21043260281351), np.float64(12.21043260281351), np.float64(12.21043260281351), np.float64(12.21043260281351), np.float64(12.21043260281351), np.float64(12.211665157737674), np.float64(12.211665157737674), np.float64(12.211665157737674), np.float64(12.221559143848218), np.float64(12.235075315530196), np.float64(12.235075315530196), np.float64(12.235168822590609), np.float64(12.237735183873628), np.float64(12.24231082373782), np.float64(12.273640962034511), np.float64(12.274292923623776), np.float64(12.328462948983837), np.float64(12.329475678403234), np.float64(12.334458458967699), np.float64(12.334581207730528), np.float64(12.334581207730528), np.float64(12.334581207730528), np.float64(12.34741661636492), np.float64(12.34791090490085), np.float64(12.34791090490085), np.float64(12.34791090490085), np.float64(12.38911078914547), np.float64(12.38911078914547), np.float64(12.38911078914547), np.float64(12.495037174125562), np.float64(12.512658705167492), np.float64(12.51426614447207), np.float64(12.51426614447207), np.float64(12.51426614447207), np.float64(12.51426614447207), np.float64(12.51939128129641), np.float64(12.519946725656421), np.float64(12.52137047375205), np.float64(12.52137047375205), np.float64(12.52137047375205), np.float64(12.521957703347265), np.float64(12.521957703347265), np.float64(12.521957703347265), np.float64(12.623037867097201), np.float64(12.623037867097201), np.float64(12.623037867097201), np.float64(12.652295461886398), np.float64(12.652804950222404), np.float64(12.653182898143017), np.float64(12.665862590793498), np.float64(12.665862590793498), np.float64(12.701740941982273), np.float64(12.701740941982273), np.float64(12.701740941982273), np.float64(12.725552452049246), np.float64(12.725552452049246), np.float64(12.725552452049246), np.float64(12.725552452049246), np.float64(12.725552452049246), np.float64(12.794147749151335), np.float64(12.794147749151335), np.float64(12.794147749151335), np.float64(12.794147749151335), np.float64(12.794147749151335), np.float64(12.794147749151335), np.float64(12.794147749151335), np.float64(12.80547210212442), np.float64(12.937470432288901), np.float64(12.937470432288901), np.float64(12.937470432288901), np.float64(12.937470432288901), np.float64(12.946167237125774), np.float64(12.946167237125774), np.float64(12.962556640214071), np.float64(12.962556640214071), np.float64(12.981293676614886), np.float64(13.017683754230431), np.float64(13.026102976252028), np.float64(13.028143049274437), np.float64(13.05245858825105), np.float64(13.05245858825105), np.float64(13.065251284112174), np.float64(13.072917115433828), np.float64(13.079014830464185), np.float64(13.079014830464185), np.float64(13.082194534837885), np.float64(13.082194534837885), np.float64(13.082194534837885), np.float64(13.082194534837885), np.float64(13.102469978649902), np.float64(13.102469978649902), np.float64(13.107094404541423), np.float64(13.141886139982063), np.float64(13.141886139982063), np.float64(13.141886139982063), np.float64(13.143184873422806), np.float64(13.143184873422806), np.float64(13.143184873422806), np.float64(13.143184873422806), np.float64(13.143184873422806), np.float64(13.147241419023093), np.float64(13.147241419023093), np.float64(13.279192104400934), np.float64(13.280477491227247), np.float64(13.280518394020392), np.float64(13.280518394020392), np.float64(13.280518394020392), np.float64(13.280518394020392), np.float64(13.280518394020392), np.float64(13.280518394020392), np.float64(13.28634936097869), np.float64(13.28634936097869), np.float64(13.30920671867643), np.float64(13.313150572184007), np.float64(13.316219377964655), np.float64(13.321656275982274), np.float64(13.341119515166048), np.float64(13.341119515166048), np.float64(13.341119515166048), np.float64(13.341119515166048), np.float64(13.341119515166048), np.float64(13.393129220634801), np.float64(13.436370273507213), np.float64(13.436370273507213), np.float64(13.449884229228664), np.float64(13.456248830299888), np.float64(13.456248830299888), np.float64(13.45729134512014), np.float64(13.45729134512014), np.float64(13.45729134512014), np.float64(13.457714097721054)]\n",
      "Final Secrecy Rate GA: 13.457714097721054\n"
     ]
    }
   ],
   "source": [
    "population_size = 100\n",
    "num_generations = 200\n",
    "crossover_rate = 0.9\n",
    "mutation_rate = 0.3\n",
    "\n",
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# GA Algorithm\n",
    "GA_results = GA_optimize_w_theta(population_size, num_generations, crossover_rate, mutation_rate)\n",
    "print(\"Initial Secrecy Rate GA:\", GA_results[0])\n",
    "print(GA_results)\n",
    "print(\"Final Secrecy Rate GA:\", GA_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_update_w_only(w, theta, learning_rate):\n",
    "    grad_w = compute_gradient_w(theta, w)\n",
    "    w_new = [w[i] - learning_rate * grad_w[i] for i in range (number_of_users)]\n",
    "    w_new = normalise_beamforming_vectors(w_new)\n",
    "    theta_new = theta\n",
    "\n",
    "    return w_new, theta_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of PSO and GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_GD(max_pso_iter, max_gd_iter, number_of_particles, learning_rate, w_max, w_min, c1, c2):\n",
    "    particles = [PSOParticle() for _ in range(number_of_particles)]\n",
    "    global_best_secrecy_rate = -np.inf\n",
    "    global_best_theta = np.zeros((1, Nris))\n",
    "    global_best_w = [np.zeros((N, 1)) for i in range(number_of_users)]\n",
    "\n",
    "    results_secrecy_rate = []\n",
    "\n",
    "    for particle in particles:\n",
    "        if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "            global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "            global_best_theta = deepcopy(particle.best_theta)\n",
    "            global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "    results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "    \n",
    "    for iteration in range(max_pso_iter):\n",
    "        print(\"iteration =\", iteration, \"Global Best Secrecy Rate:\", global_best_secrecy_rate)\n",
    "        inertia = dynamic_inertia(iteration, max_iter, w_max, w_min)\n",
    "\n",
    "        \"\"\"\n",
    "            Update particles theta by velocity\n",
    "        \"\"\"\n",
    "        for particle in particles:\n",
    "            particle.update_velocity(inertia, c1, c2, global_best_theta, global_best_w)\n",
    "            particle.update_position()\n",
    "            particle.update_best()\n",
    "            \n",
    "            if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "                global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "                global_best_theta = deepcopy(particle.best_theta)\n",
    "                global_best_w = deepcopy(particle.best_w)\n",
    "        \n",
    "        # GD\n",
    "        for particle in particles:\n",
    "            for _ in range (max_gd_iter):\n",
    "                new_w, new_theta = gradient_descent_update(particle.w, theta_angles_to_theta_vector(particle.theta), learning_rate)\n",
    "                new_secrecy_rate = secrecy_rate_objective_function(new_theta, new_w)\n",
    "                if (new_secrecy_rate - particle.current_secrecy_rate) < 1e-9:\n",
    "                    break\n",
    "                \n",
    "                particle.w = new_w\n",
    "                particle.theta = theta_vector_to_theta_angles(new_theta)\n",
    "                particle.current_secrecy_rate = new_secrecy_rate\n",
    "\n",
    "            particle.update_best()\n",
    "            \n",
    "            if particle.best_secrecy_rate > global_best_secrecy_rate: \n",
    "                # No need to check validity as we already checked it in the inner loop\n",
    "                global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "                global_best_theta = deepcopy(particle.best_theta)\n",
    "                global_best_w = deepcopy(particle.best_w)\n",
    "       \n",
    "        results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "    return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0\n",
      "iteration = 1\n",
      "iteration = 2\n",
      "iteration = 3\n",
      "iteration = 4\n",
      "iteration = 5\n",
      "iteration = 6\n",
      "iteration = 7\n",
      "iteration = 8\n",
      "iteration = 9\n",
      "iteration = 10\n",
      "iteration = 11\n",
      "iteration = 12\n",
      "iteration = 13\n",
      "iteration = 14\n",
      "iteration = 15\n",
      "iteration = 16\n",
      "iteration = 17\n",
      "iteration = 18\n",
      "iteration = 19\n",
      "iteration = 20\n",
      "iteration = 21\n",
      "iteration = 22\n",
      "iteration = 23\n",
      "iteration = 24\n",
      "iteration = 25\n",
      "iteration = 26\n",
      "iteration = 27\n",
      "iteration = 28\n",
      "iteration = 29\n",
      "iteration = 30\n",
      "iteration = 31\n",
      "iteration = 32\n",
      "iteration = 33\n",
      "iteration = 34\n",
      "iteration = 35\n",
      "iteration = 36\n",
      "iteration = 37\n",
      "iteration = 38\n",
      "iteration = 39\n",
      "iteration = 40\n",
      "iteration = 41\n",
      "iteration = 42\n",
      "iteration = 43\n",
      "iteration = 44\n",
      "iteration = 45\n",
      "iteration = 46\n",
      "iteration = 47\n",
      "iteration = 48\n",
      "iteration = 49\n",
      "iteration = 50\n",
      "iteration = 51\n",
      "iteration = 52\n",
      "iteration = 53\n",
      "iteration = 54\n",
      "iteration = 55\n",
      "iteration = 56\n",
      "iteration = 57\n",
      "iteration = 58\n",
      "iteration = 59\n",
      "iteration = 60\n",
      "iteration = 61\n",
      "iteration = 62\n",
      "iteration = 63\n",
      "iteration = 64\n",
      "iteration = 65\n",
      "iteration = 66\n",
      "iteration = 67\n",
      "iteration = 68\n",
      "iteration = 69\n",
      "iteration = 70\n",
      "iteration = 71\n",
      "iteration = 72\n",
      "iteration = 73\n",
      "iteration = 74\n",
      "iteration = 75\n",
      "iteration = 76\n",
      "iteration = 77\n",
      "iteration = 78\n",
      "iteration = 79\n",
      "iteration = 80\n",
      "iteration = 81\n",
      "iteration = 82\n",
      "iteration = 83\n",
      "iteration = 84\n",
      "iteration = 85\n",
      "iteration = 86\n",
      "iteration = 87\n",
      "iteration = 88\n",
      "iteration = 89\n",
      "iteration = 90\n",
      "iteration = 91\n",
      "iteration = 92\n",
      "iteration = 93\n",
      "iteration = 94\n",
      "iteration = 95\n",
      "iteration = 96\n",
      "iteration = 97\n",
      "iteration = 98\n",
      "iteration = 99\n",
      "iteration = 100\n",
      "iteration = 101\n",
      "iteration = 102\n",
      "iteration = 103\n",
      "iteration = 104\n",
      "iteration = 105\n",
      "iteration = 106\n",
      "iteration = 107\n",
      "iteration = 108\n",
      "iteration = 109\n",
      "iteration = 110\n",
      "iteration = 111\n",
      "iteration = 112\n",
      "iteration = 113\n",
      "iteration = 114\n",
      "iteration = 115\n",
      "iteration = 116\n",
      "iteration = 117\n",
      "iteration = 118\n",
      "iteration = 119\n",
      "iteration = 120\n",
      "iteration = 121\n",
      "iteration = 122\n",
      "iteration = 123\n",
      "iteration = 124\n",
      "iteration = 125\n",
      "iteration = 126\n",
      "iteration = 127\n",
      "iteration = 128\n",
      "iteration = 129\n",
      "iteration = 130\n",
      "iteration = 131\n",
      "iteration = 132\n",
      "iteration = 133\n",
      "iteration = 134\n",
      "iteration = 135\n",
      "iteration = 136\n",
      "iteration = 137\n",
      "iteration = 138\n",
      "iteration = 139\n",
      "iteration = 140\n",
      "iteration = 141\n",
      "iteration = 142\n",
      "iteration = 143\n",
      "iteration = 144\n",
      "iteration = 145\n",
      "iteration = 146\n",
      "iteration = 147\n",
      "iteration = 148\n",
      "iteration = 149\n",
      "iteration = 150\n",
      "iteration = 151\n",
      "iteration = 152\n",
      "iteration = 153\n",
      "iteration = 154\n",
      "iteration = 155\n",
      "iteration = 156\n",
      "iteration = 157\n",
      "iteration = 158\n",
      "iteration = 159\n",
      "iteration = 160\n",
      "iteration = 161\n",
      "iteration = 162\n",
      "iteration = 163\n",
      "iteration = 164\n",
      "iteration = 165\n",
      "iteration = 166\n",
      "iteration = 167\n",
      "iteration = 168\n",
      "iteration = 169\n",
      "iteration = 170\n",
      "iteration = 171\n",
      "iteration = 172\n",
      "iteration = 173\n",
      "iteration = 174\n",
      "iteration = 175\n",
      "iteration = 176\n",
      "iteration = 177\n",
      "iteration = 178\n",
      "iteration = 179\n",
      "iteration = 180\n",
      "iteration = 181\n",
      "iteration = 182\n",
      "iteration = 183\n",
      "iteration = 184\n",
      "iteration = 185\n",
      "iteration = 186\n",
      "iteration = 187\n",
      "iteration = 188\n",
      "iteration = 189\n",
      "iteration = 190\n",
      "iteration = 191\n",
      "iteration = 192\n",
      "iteration = 193\n",
      "iteration = 194\n",
      "iteration = 195\n",
      "iteration = 196\n",
      "iteration = 197\n",
      "iteration = 198\n",
      "iteration = 199\n",
      "Initial Secrecy Rate PSO-GD: 8.760058732423133\n",
      "Final Secrecy Rate PSO-GD: 19.42312619148822\n"
     ]
    }
   ],
   "source": [
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "max_pso_iter = 200\n",
    "max_gd_iter = 50\n",
    "number_of_particles = 50\n",
    "w_max = 0.9\n",
    "w_min = 0.5\n",
    "c1 = 1.5\n",
    "c2 = 1.5\n",
    "\n",
    "PSO_GD_results = PSO_GD(max_pso_iter, max_gd_iter, number_of_particles, learning_rate, w_max, w_min, c1, c2)\n",
    "print(\"Initial Secrecy Rate PSO-GD:\", PSO_GD_results[0])\n",
    "print(\"Final Secrecy Rate PSO-GD:\", PSO_GD_results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of GA and GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_GD_optimize_w_theta(population_size: int, max_iter: int, max_iter_gd: int, crossover_rate: float = 0.85, mutation_rate: float = 0.85):\n",
    "  population = GAPopulation(population_size, crossover_rate, mutation_rate)\n",
    "  population.sort_population()\n",
    "  results_secrecy_rate = []\n",
    "  results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "\n",
    "  for iteration in range(max_iter):\n",
    "    print(\"iteration =\", iteration)\n",
    "    print(\"Best secrecy rate:\", population.individuals[0].fitness)\n",
    "    # Crossover\n",
    "    for _ in range(population_size):\n",
    "      if np.random.rand() < population.crossover_rate:\n",
    "        parent1, parent2 = population.select_parents()\n",
    "        child = population.crossover(parent1, parent2)\n",
    "    #Mutate \n",
    "        population.mutate(child)\n",
    "        population.add_individual(child)\n",
    "\n",
    "\n",
    "    # GD\n",
    "    for individual in population.individuals:\n",
    "      for _ in range(max_iter_gd):\n",
    "        new_w, new_theta = gradient_descent_update(individual.w, theta_angles_to_theta_vector(individual.theta), learning_rate)\n",
    "        new_secrecy_rate = secrecy_rate_objective_function(new_theta, new_w)\n",
    "        if (new_secrecy_rate - individual.fitness) < 1e-9:\n",
    "          break\n",
    "        \n",
    "        individual.w = new_w\n",
    "        individual.theta = theta_vector_to_theta_angles(new_theta)\n",
    "        individual.update_fitness()\n",
    "\n",
    "      individual.theta, individual.w = repair(theta_angles_to_theta_vector(individual.theta), individual.w)\n",
    "      individual.theta = theta_vector_to_theta_angles(individual.theta)\n",
    "      individual.update_fitness()\n",
    "\n",
    "    # Filter\n",
    "    population.filter_population() \n",
    "\n",
    "    # Sort\n",
    "    population.sort_population()\n",
    "    \n",
    "    #print(f\"[Generation {iteration + 1}] Population before GD: {list(map(lambda x: x.fitness, population.individuals))}\")\n",
    "\n",
    "    print(\"Best secrecy rate:\", population.individuals[0].fitness)\n",
    "    results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "\n",
    "  return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0\n",
      "Best secrecy rate: 8.760058732423133\n",
      "Best secrecy rate: 12.193339136327316\n",
      "iteration = 1\n",
      "Best secrecy rate: 12.193339136327316\n",
      "Best secrecy rate: 12.760571565882191\n",
      "iteration = 2\n",
      "Best secrecy rate: 12.760571565882191\n",
      "Best secrecy rate: 12.951624154876127\n",
      "iteration = 3\n",
      "Best secrecy rate: 12.951624154876127\n",
      "Best secrecy rate: 12.951624154876127\n",
      "iteration = 4\n",
      "Best secrecy rate: 12.951624154876127\n",
      "Best secrecy rate: 13.113608419686262\n",
      "iteration = 5\n",
      "Best secrecy rate: 13.113608419686262\n",
      "Best secrecy rate: 13.112029129245368\n",
      "iteration = 6\n",
      "Best secrecy rate: 13.112029129245368\n",
      "Best secrecy rate: 13.550520084824718\n",
      "iteration = 7\n",
      "Best secrecy rate: 13.550520084824718\n",
      "Best secrecy rate: 13.630467973278321\n",
      "iteration = 8\n",
      "Best secrecy rate: 13.630467973278321\n",
      "Best secrecy rate: 13.672665621099366\n",
      "iteration = 9\n",
      "Best secrecy rate: 13.672665621099366\n",
      "Best secrecy rate: 13.780882136012421\n",
      "iteration = 10\n",
      "Best secrecy rate: 13.780882136012421\n",
      "Best secrecy rate: 13.901953834319016\n",
      "iteration = 11\n",
      "Best secrecy rate: 13.901953834319016\n",
      "Best secrecy rate: 13.922835510774162\n",
      "iteration = 12\n",
      "Best secrecy rate: 13.922835510774162\n",
      "Best secrecy rate: 14.21151598258529\n",
      "iteration = 13\n",
      "Best secrecy rate: 14.21151598258529\n",
      "Best secrecy rate: 14.21151598258529\n",
      "iteration = 14\n",
      "Best secrecy rate: 14.21151598258529\n",
      "Best secrecy rate: 14.21151598258529\n",
      "iteration = 15\n",
      "Best secrecy rate: 14.21151598258529\n",
      "Best secrecy rate: 14.21151598258529\n",
      "iteration = 16\n",
      "Best secrecy rate: 14.21151598258529\n",
      "Best secrecy rate: 14.259055455032328\n",
      "iteration = 17\n",
      "Best secrecy rate: 14.259055455032328\n",
      "Best secrecy rate: 14.280737883235041\n",
      "iteration = 18\n",
      "Best secrecy rate: 14.280737883235041\n",
      "Best secrecy rate: 14.351076880724047\n",
      "iteration = 19\n",
      "Best secrecy rate: 14.351076880724047\n",
      "Best secrecy rate: 14.351076880724047\n",
      "iteration = 20\n",
      "Best secrecy rate: 14.351076880724047\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 21\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 22\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 23\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 24\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 25\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 26\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 27\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 28\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 29\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 30\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.509286831247767\n",
      "iteration = 31\n",
      "Best secrecy rate: 14.509286831247767\n",
      "Best secrecy rate: 14.52644998159139\n",
      "iteration = 32\n",
      "Best secrecy rate: 14.52644998159139\n",
      "Best secrecy rate: 14.52644998159139\n",
      "iteration = 33\n",
      "Best secrecy rate: 14.52644998159139\n",
      "Best secrecy rate: 14.52644998159139\n",
      "iteration = 34\n",
      "Best secrecy rate: 14.52644998159139\n",
      "Best secrecy rate: 14.52644998159139\n",
      "iteration = 35\n",
      "Best secrecy rate: 14.52644998159139\n",
      "Best secrecy rate: 14.52644998159139\n",
      "iteration = 36\n",
      "Best secrecy rate: 14.52644998159139\n",
      "Best secrecy rate: 14.54170324686021\n",
      "iteration = 37\n",
      "Best secrecy rate: 14.54170324686021\n",
      "Best secrecy rate: 14.54170324686021\n",
      "iteration = 38\n",
      "Best secrecy rate: 14.54170324686021\n",
      "Best secrecy rate: 14.54170324686021\n",
      "iteration = 39\n",
      "Best secrecy rate: 14.54170324686021\n",
      "Best secrecy rate: 14.54170324686021\n",
      "iteration = 40\n",
      "Best secrecy rate: 14.54170324686021\n",
      "Best secrecy rate: 14.54170324686021\n",
      "iteration = 41\n",
      "Best secrecy rate: 14.54170324686021\n",
      "Best secrecy rate: 14.54170324686021\n",
      "iteration = 42\n",
      "Best secrecy rate: 14.54170324686021\n",
      "Best secrecy rate: 14.54170324686021\n",
      "iteration = 43\n",
      "Best secrecy rate: 14.54170324686021\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 44\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 45\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 46\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 47\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 48\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 49\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 50\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 51\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 52\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 53\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 54\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 55\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 56\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 57\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 58\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 59\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 60\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 61\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 62\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 63\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 64\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 65\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 66\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 67\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 68\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 69\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 70\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 71\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543360149509038\n",
      "iteration = 72\n",
      "Best secrecy rate: 14.543360149509038\n",
      "Best secrecy rate: 14.543365894306342\n",
      "iteration = 73\n",
      "Best secrecy rate: 14.543365894306342\n",
      "Best secrecy rate: 14.543365894306342\n",
      "iteration = 74\n",
      "Best secrecy rate: 14.543365894306342\n",
      "Best secrecy rate: 14.543365894306342\n",
      "iteration = 75\n",
      "Best secrecy rate: 14.543365894306342\n",
      "Best secrecy rate: 14.543365894306342\n",
      "iteration = 76\n",
      "Best secrecy rate: 14.543365894306342\n",
      "Best secrecy rate: 14.555928639822836\n",
      "iteration = 77\n",
      "Best secrecy rate: 14.555928639822836\n",
      "Best secrecy rate: 14.56454361237972\n",
      "iteration = 78\n",
      "Best secrecy rate: 14.56454361237972\n",
      "Best secrecy rate: 14.56454361237972\n",
      "iteration = 79\n",
      "Best secrecy rate: 14.56454361237972\n",
      "Best secrecy rate: 14.56454361237972\n",
      "iteration = 80\n",
      "Best secrecy rate: 14.56454361237972\n",
      "Best secrecy rate: 14.56454361237972\n",
      "iteration = 81\n",
      "Best secrecy rate: 14.56454361237972\n",
      "Best secrecy rate: 14.56454361237972\n",
      "iteration = 82\n",
      "Best secrecy rate: 14.56454361237972\n",
      "Best secrecy rate: 14.56454361237972\n",
      "iteration = 83\n",
      "Best secrecy rate: 14.56454361237972\n",
      "Best secrecy rate: 14.56454361237972\n",
      "iteration = 84\n",
      "Best secrecy rate: 14.56454361237972\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 85\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 86\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 87\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 88\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 89\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 90\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 91\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 92\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 93\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 94\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 95\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 96\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 97\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 98\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 99\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 100\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 101\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 102\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 103\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 104\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 105\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 106\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 107\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 108\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 109\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 110\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 111\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 112\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 113\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 114\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 115\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 116\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 117\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 118\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 119\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 120\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 121\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.579511856248596\n",
      "iteration = 122\n",
      "Best secrecy rate: 14.579511856248596\n",
      "Best secrecy rate: 14.579511856248596\n",
      "iteration = 123\n",
      "Best secrecy rate: 14.579511856248596\n",
      "Best secrecy rate: 14.579511856248596\n",
      "iteration = 124\n",
      "Best secrecy rate: 14.579511856248596\n",
      "Best secrecy rate: 14.579511856248596\n",
      "iteration = 125\n",
      "Best secrecy rate: 14.579511856248596\n",
      "Best secrecy rate: 14.585549079909352\n",
      "iteration = 126\n",
      "Best secrecy rate: 14.585549079909352\n",
      "Best secrecy rate: 14.585549079909352\n",
      "iteration = 127\n",
      "Best secrecy rate: 14.585549079909352\n",
      "Best secrecy rate: 14.585549079909352\n",
      "iteration = 128\n",
      "Best secrecy rate: 14.585549079909352\n",
      "Best secrecy rate: 14.585549079909352\n",
      "iteration = 129\n",
      "Best secrecy rate: 14.585549079909352\n",
      "Best secrecy rate: 14.590103859691594\n",
      "iteration = 130\n",
      "Best secrecy rate: 14.590103859691594\n",
      "Best secrecy rate: 14.591941713079597\n",
      "iteration = 131\n",
      "Best secrecy rate: 14.591941713079597\n",
      "Best secrecy rate: 14.594699454653522\n",
      "iteration = 132\n",
      "Best secrecy rate: 14.594699454653522\n",
      "Best secrecy rate: 14.59699156115945\n",
      "iteration = 133\n",
      "Best secrecy rate: 14.59699156115945\n",
      "Best secrecy rate: 14.658014401484959\n",
      "iteration = 134\n",
      "Best secrecy rate: 14.658014401484959\n",
      "Best secrecy rate: 14.723495216108446\n",
      "iteration = 135\n",
      "Best secrecy rate: 14.723495216108446\n",
      "Best secrecy rate: 14.723495216108446\n",
      "iteration = 136\n",
      "Best secrecy rate: 14.723495216108446\n",
      "Best secrecy rate: 14.73045372708136\n",
      "iteration = 137\n",
      "Best secrecy rate: 14.73045372708136\n",
      "Best secrecy rate: 14.73045372708136\n",
      "iteration = 138\n",
      "Best secrecy rate: 14.73045372708136\n",
      "Best secrecy rate: 14.73045372708136\n",
      "iteration = 139\n",
      "Best secrecy rate: 14.73045372708136\n",
      "Best secrecy rate: 14.73045372708136\n",
      "iteration = 140\n",
      "Best secrecy rate: 14.73045372708136\n",
      "Best secrecy rate: 14.73045372708136\n",
      "iteration = 141\n",
      "Best secrecy rate: 14.73045372708136\n",
      "Best secrecy rate: 14.73045372708136\n",
      "iteration = 142\n",
      "Best secrecy rate: 14.73045372708136\n",
      "Best secrecy rate: 14.73045372708136\n",
      "iteration = 143\n",
      "Best secrecy rate: 14.73045372708136\n",
      "Best secrecy rate: 14.746496812430445\n",
      "iteration = 144\n",
      "Best secrecy rate: 14.746496812430445\n",
      "Best secrecy rate: 14.746496812430445\n",
      "iteration = 145\n",
      "Best secrecy rate: 14.746496812430445\n",
      "Best secrecy rate: 14.746496812430445\n",
      "iteration = 146\n",
      "Best secrecy rate: 14.746496812430445\n",
      "Best secrecy rate: 14.746496812430445\n",
      "iteration = 147\n",
      "Best secrecy rate: 14.746496812430445\n",
      "Best secrecy rate: 14.74657164975042\n",
      "iteration = 148\n",
      "Best secrecy rate: 14.74657164975042\n",
      "Best secrecy rate: 14.758101835928588\n",
      "iteration = 149\n",
      "Best secrecy rate: 14.758101835928588\n",
      "Best secrecy rate: 14.758101835928588\n",
      "iteration = 150\n",
      "Best secrecy rate: 14.758101835928588\n",
      "Best secrecy rate: 14.792449283691997\n",
      "iteration = 151\n",
      "Best secrecy rate: 14.792449283691997\n",
      "Best secrecy rate: 14.792449283691997\n",
      "iteration = 152\n",
      "Best secrecy rate: 14.792449283691997\n",
      "Best secrecy rate: 14.794353974078724\n",
      "iteration = 153\n",
      "Best secrecy rate: 14.794353974078724\n",
      "Best secrecy rate: 14.794353974078724\n",
      "iteration = 154\n",
      "Best secrecy rate: 14.794353974078724\n",
      "Best secrecy rate: 14.794353974078724\n",
      "iteration = 155\n",
      "Best secrecy rate: 14.794353974078724\n",
      "Best secrecy rate: 14.794353974078724\n",
      "iteration = 156\n",
      "Best secrecy rate: 14.794353974078724\n",
      "Best secrecy rate: 14.794854765429585\n",
      "iteration = 157\n",
      "Best secrecy rate: 14.794854765429585\n",
      "Best secrecy rate: 14.794854765429585\n",
      "iteration = 158\n",
      "Best secrecy rate: 14.794854765429585\n",
      "Best secrecy rate: 14.794854765429585\n",
      "iteration = 159\n",
      "Best secrecy rate: 14.794854765429585\n",
      "Best secrecy rate: 14.799809566672467\n",
      "iteration = 160\n",
      "Best secrecy rate: 14.799809566672467\n",
      "Best secrecy rate: 14.80774126528311\n",
      "iteration = 161\n",
      "Best secrecy rate: 14.80774126528311\n",
      "Best secrecy rate: 14.80774126528311\n",
      "iteration = 162\n",
      "Best secrecy rate: 14.80774126528311\n",
      "Best secrecy rate: 14.809102385038518\n",
      "iteration = 163\n",
      "Best secrecy rate: 14.809102385038518\n",
      "Best secrecy rate: 14.946236927728707\n",
      "iteration = 164\n",
      "Best secrecy rate: 14.946236927728707\n",
      "Best secrecy rate: 14.976620495536064\n",
      "iteration = 165\n",
      "Best secrecy rate: 14.976620495536064\n",
      "Best secrecy rate: 14.988135941574829\n",
      "iteration = 166\n",
      "Best secrecy rate: 14.988135941574829\n",
      "Best secrecy rate: 14.988135941574829\n",
      "iteration = 167\n",
      "Best secrecy rate: 14.988135941574829\n",
      "Best secrecy rate: 14.988135941574829\n",
      "iteration = 168\n",
      "Best secrecy rate: 14.988135941574829\n",
      "Best secrecy rate: 14.988923831949428\n",
      "iteration = 169\n",
      "Best secrecy rate: 14.988923831949428\n",
      "Best secrecy rate: 14.989225323200388\n",
      "iteration = 170\n",
      "Best secrecy rate: 14.989225323200388\n",
      "Best secrecy rate: 14.989225323200388\n",
      "iteration = 171\n",
      "Best secrecy rate: 14.989225323200388\n",
      "Best secrecy rate: 14.989225323200388\n",
      "iteration = 172\n",
      "Best secrecy rate: 14.989225323200388\n",
      "Best secrecy rate: 14.989225323200388\n",
      "iteration = 173\n",
      "Best secrecy rate: 14.989225323200388\n",
      "Best secrecy rate: 14.999204428290211\n",
      "iteration = 174\n",
      "Best secrecy rate: 14.999204428290211\n",
      "Best secrecy rate: 14.999204428290211\n",
      "iteration = 175\n",
      "Best secrecy rate: 14.999204428290211\n",
      "Best secrecy rate: 14.999204428290211\n",
      "iteration = 176\n",
      "Best secrecy rate: 14.999204428290211\n",
      "Best secrecy rate: 15.036894372056059\n",
      "iteration = 177\n",
      "Best secrecy rate: 15.036894372056059\n",
      "Best secrecy rate: 15.036894372056059\n",
      "iteration = 178\n",
      "Best secrecy rate: 15.036894372056059\n",
      "Best secrecy rate: 15.043468674015703\n",
      "iteration = 179\n",
      "Best secrecy rate: 15.043468674015703\n",
      "Best secrecy rate: 15.043468674015703\n",
      "iteration = 180\n",
      "Best secrecy rate: 15.043468674015703\n",
      "Best secrecy rate: 15.043468674015703\n",
      "iteration = 181\n",
      "Best secrecy rate: 15.043468674015703\n",
      "Best secrecy rate: 15.059597653425225\n",
      "iteration = 182\n",
      "Best secrecy rate: 15.059597653425225\n",
      "Best secrecy rate: 15.059597653425225\n",
      "iteration = 183\n",
      "Best secrecy rate: 15.059597653425225\n",
      "Best secrecy rate: 15.059597653425225\n",
      "iteration = 184\n",
      "Best secrecy rate: 15.059597653425225\n",
      "Best secrecy rate: 15.059597653425225\n",
      "iteration = 185\n",
      "Best secrecy rate: 15.059597653425225\n",
      "Best secrecy rate: 15.063148394205433\n",
      "iteration = 186\n",
      "Best secrecy rate: 15.063148394205433\n",
      "Best secrecy rate: 15.063148394205433\n",
      "iteration = 187\n",
      "Best secrecy rate: 15.063148394205433\n",
      "Best secrecy rate: 15.065328334946605\n",
      "iteration = 188\n",
      "Best secrecy rate: 15.065328334946605\n",
      "Best secrecy rate: 15.067520512465904\n",
      "iteration = 189\n",
      "Best secrecy rate: 15.067520512465904\n",
      "Best secrecy rate: 15.067520512465904\n",
      "iteration = 190\n",
      "Best secrecy rate: 15.067520512465904\n",
      "Best secrecy rate: 15.067520512465904\n",
      "iteration = 191\n",
      "Best secrecy rate: 15.067520512465904\n",
      "Best secrecy rate: 15.067520512465904\n",
      "iteration = 192\n",
      "Best secrecy rate: 15.067520512465904\n",
      "Best secrecy rate: 15.067520512465904\n",
      "iteration = 193\n",
      "Best secrecy rate: 15.067520512465904\n",
      "Best secrecy rate: 15.067520512465904\n",
      "iteration = 194\n",
      "Best secrecy rate: 15.067520512465904\n",
      "Best secrecy rate: 15.06788089888\n",
      "iteration = 195\n",
      "Best secrecy rate: 15.06788089888\n",
      "Best secrecy rate: 15.06788089888\n",
      "iteration = 196\n",
      "Best secrecy rate: 15.06788089888\n",
      "Best secrecy rate: 15.06788089888\n",
      "iteration = 197\n",
      "Best secrecy rate: 15.06788089888\n",
      "Best secrecy rate: 15.068181708696923\n",
      "iteration = 198\n",
      "Best secrecy rate: 15.068181708696923\n",
      "Best secrecy rate: 15.068444638401472\n",
      "iteration = 199\n",
      "Best secrecy rate: 15.068444638401472\n",
      "Best secrecy rate: 15.06870984347262\n",
      "Initial Secrecy Rate GA-GD: 8.760058732423133\n",
      "[np.float64(8.760058732423133), np.float64(12.193339136327316), np.float64(12.760571565882191), np.float64(12.951624154876127), np.float64(12.951624154876127), np.float64(13.113608419686262), np.float64(13.112029129245368), np.float64(13.550520084824718), np.float64(13.630467973278321), np.float64(13.672665621099366), np.float64(13.780882136012421), np.float64(13.901953834319016), np.float64(13.922835510774162), np.float64(14.21151598258529), np.float64(14.21151598258529), np.float64(14.21151598258529), np.float64(14.21151598258529), np.float64(14.259055455032328), np.float64(14.280737883235041), np.float64(14.351076880724047), np.float64(14.351076880724047), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.509286831247767), np.float64(14.52644998159139), np.float64(14.52644998159139), np.float64(14.52644998159139), np.float64(14.52644998159139), np.float64(14.52644998159139), np.float64(14.54170324686021), np.float64(14.54170324686021), np.float64(14.54170324686021), np.float64(14.54170324686021), np.float64(14.54170324686021), np.float64(14.54170324686021), np.float64(14.54170324686021), np.float64(14.543250251556712), np.float64(14.543250251556712), np.float64(14.543250251556712), np.float64(14.543250251556712), np.float64(14.543250251556712), np.float64(14.543250251556712), np.float64(14.543250251556712), np.float64(14.543250251556712), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543360149509038), np.float64(14.543365894306342), np.float64(14.543365894306342), np.float64(14.543365894306342), np.float64(14.543365894306342), np.float64(14.555928639822836), np.float64(14.56454361237972), np.float64(14.56454361237972), np.float64(14.56454361237972), np.float64(14.56454361237972), np.float64(14.56454361237972), np.float64(14.56454361237972), np.float64(14.56454361237972), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.579511856248596), np.float64(14.579511856248596), np.float64(14.579511856248596), np.float64(14.579511856248596), np.float64(14.585549079909352), np.float64(14.585549079909352), np.float64(14.585549079909352), np.float64(14.585549079909352), np.float64(14.590103859691594), np.float64(14.591941713079597), np.float64(14.594699454653522), np.float64(14.59699156115945), np.float64(14.658014401484959), np.float64(14.723495216108446), np.float64(14.723495216108446), np.float64(14.73045372708136), np.float64(14.73045372708136), np.float64(14.73045372708136), np.float64(14.73045372708136), np.float64(14.73045372708136), np.float64(14.73045372708136), np.float64(14.73045372708136), np.float64(14.746496812430445), np.float64(14.746496812430445), np.float64(14.746496812430445), np.float64(14.746496812430445), np.float64(14.74657164975042), np.float64(14.758101835928588), np.float64(14.758101835928588), np.float64(14.792449283691997), np.float64(14.792449283691997), np.float64(14.794353974078724), np.float64(14.794353974078724), np.float64(14.794353974078724), np.float64(14.794353974078724), np.float64(14.794854765429585), np.float64(14.794854765429585), np.float64(14.794854765429585), np.float64(14.799809566672467), np.float64(14.80774126528311), np.float64(14.80774126528311), np.float64(14.809102385038518), np.float64(14.946236927728707), np.float64(14.976620495536064), np.float64(14.988135941574829), np.float64(14.988135941574829), np.float64(14.988135941574829), np.float64(14.988923831949428), np.float64(14.989225323200388), np.float64(14.989225323200388), np.float64(14.989225323200388), np.float64(14.989225323200388), np.float64(14.999204428290211), np.float64(14.999204428290211), np.float64(14.999204428290211), np.float64(15.036894372056059), np.float64(15.036894372056059), np.float64(15.043468674015703), np.float64(15.043468674015703), np.float64(15.043468674015703), np.float64(15.059597653425225), np.float64(15.059597653425225), np.float64(15.059597653425225), np.float64(15.059597653425225), np.float64(15.063148394205433), np.float64(15.063148394205433), np.float64(15.065328334946605), np.float64(15.067520512465904), np.float64(15.067520512465904), np.float64(15.067520512465904), np.float64(15.067520512465904), np.float64(15.067520512465904), np.float64(15.067520512465904), np.float64(15.06788089888), np.float64(15.06788089888), np.float64(15.06788089888), np.float64(15.068181708696923), np.float64(15.068444638401472), np.float64(15.06870984347262)]\n",
      "Final Secrecy Rate GA-GD: 15.06870984347262\n"
     ]
    }
   ],
   "source": [
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# GA-GD\n",
    "population_size = 50\n",
    "num_generations = 200\n",
    "num_iter_gd = 50\n",
    "crossover_rate = 0.9\n",
    "mutation_rate = 0.3\n",
    "learning_rate = 0.01\n",
    "\n",
    "GA_GD_results = GA_GD_optimize_w_theta(population_size, num_generations, num_iter_gd, crossover_rate, mutation_rate)\n",
    "print(\"Initial Secrecy Rate GA-GD:\", GA_GD_results[0])\n",
    "print(GA_GD_results)\n",
    "print(\"Final Secrecy Rate GA-GD:\", GA_GD_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(8.760058732423133),\n",
       " np.float64(12.193339136327316),\n",
       " np.float64(12.760571565882191),\n",
       " np.float64(12.951624154876127),\n",
       " np.float64(12.951624154876127),\n",
       " np.float64(13.113608419686262),\n",
       " np.float64(13.112029129245368),\n",
       " np.float64(13.550520084824718),\n",
       " np.float64(13.630467973278321),\n",
       " np.float64(13.672665621099366),\n",
       " np.float64(13.780882136012421),\n",
       " np.float64(13.901953834319016),\n",
       " np.float64(13.922835510774162),\n",
       " np.float64(14.21151598258529),\n",
       " np.float64(14.21151598258529),\n",
       " np.float64(14.21151598258529),\n",
       " np.float64(14.21151598258529),\n",
       " np.float64(14.259055455032328),\n",
       " np.float64(14.280737883235041),\n",
       " np.float64(14.351076880724047),\n",
       " np.float64(14.351076880724047),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.509286831247767),\n",
       " np.float64(14.52644998159139),\n",
       " np.float64(14.52644998159139),\n",
       " np.float64(14.52644998159139),\n",
       " np.float64(14.52644998159139),\n",
       " np.float64(14.52644998159139),\n",
       " np.float64(14.54170324686021),\n",
       " np.float64(14.54170324686021),\n",
       " np.float64(14.54170324686021),\n",
       " np.float64(14.54170324686021),\n",
       " np.float64(14.54170324686021),\n",
       " np.float64(14.54170324686021),\n",
       " np.float64(14.54170324686021),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543360149509038),\n",
       " np.float64(14.543365894306342),\n",
       " np.float64(14.543365894306342),\n",
       " np.float64(14.543365894306342),\n",
       " np.float64(14.543365894306342),\n",
       " np.float64(14.555928639822836),\n",
       " np.float64(14.56454361237972),\n",
       " np.float64(14.56454361237972),\n",
       " np.float64(14.56454361237972),\n",
       " np.float64(14.56454361237972),\n",
       " np.float64(14.56454361237972),\n",
       " np.float64(14.56454361237972),\n",
       " np.float64(14.56454361237972),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.579511856248596),\n",
       " np.float64(14.579511856248596),\n",
       " np.float64(14.579511856248596),\n",
       " np.float64(14.579511856248596),\n",
       " np.float64(14.585549079909352),\n",
       " np.float64(14.585549079909352),\n",
       " np.float64(14.585549079909352),\n",
       " np.float64(14.585549079909352),\n",
       " np.float64(14.590103859691594),\n",
       " np.float64(14.591941713079597),\n",
       " np.float64(14.594699454653522),\n",
       " np.float64(14.59699156115945),\n",
       " np.float64(14.658014401484959),\n",
       " np.float64(14.723495216108446),\n",
       " np.float64(14.723495216108446),\n",
       " np.float64(14.73045372708136),\n",
       " np.float64(14.73045372708136),\n",
       " np.float64(14.73045372708136),\n",
       " np.float64(14.73045372708136),\n",
       " np.float64(14.73045372708136),\n",
       " np.float64(14.73045372708136),\n",
       " np.float64(14.73045372708136),\n",
       " np.float64(14.746496812430445),\n",
       " np.float64(14.746496812430445),\n",
       " np.float64(14.746496812430445),\n",
       " np.float64(14.746496812430445),\n",
       " np.float64(14.74657164975042),\n",
       " np.float64(14.758101835928588),\n",
       " np.float64(14.758101835928588),\n",
       " np.float64(14.792449283691997),\n",
       " np.float64(14.792449283691997),\n",
       " np.float64(14.794353974078724),\n",
       " np.float64(14.794353974078724),\n",
       " np.float64(14.794353974078724),\n",
       " np.float64(14.794353974078724),\n",
       " np.float64(14.794854765429585),\n",
       " np.float64(14.794854765429585),\n",
       " np.float64(14.794854765429585),\n",
       " np.float64(14.799809566672467),\n",
       " np.float64(14.80774126528311),\n",
       " np.float64(14.80774126528311),\n",
       " np.float64(14.809102385038518),\n",
       " np.float64(14.946236927728707),\n",
       " np.float64(14.976620495536064),\n",
       " np.float64(14.988135941574829),\n",
       " np.float64(14.988135941574829),\n",
       " np.float64(14.988135941574829),\n",
       " np.float64(14.988923831949428),\n",
       " np.float64(14.989225323200388),\n",
       " np.float64(14.989225323200388),\n",
       " np.float64(14.989225323200388),\n",
       " np.float64(14.989225323200388),\n",
       " np.float64(14.999204428290211),\n",
       " np.float64(14.999204428290211),\n",
       " np.float64(14.999204428290211),\n",
       " np.float64(15.036894372056059),\n",
       " np.float64(15.036894372056059),\n",
       " np.float64(15.043468674015703),\n",
       " np.float64(15.043468674015703),\n",
       " np.float64(15.043468674015703),\n",
       " np.float64(15.059597653425225),\n",
       " np.float64(15.059597653425225),\n",
       " np.float64(15.059597653425225),\n",
       " np.float64(15.059597653425225),\n",
       " np.float64(15.063148394205433),\n",
       " np.float64(15.063148394205433),\n",
       " np.float64(15.065328334946605),\n",
       " np.float64(15.067520512465904),\n",
       " np.float64(15.067520512465904),\n",
       " np.float64(15.067520512465904),\n",
       " np.float64(15.067520512465904),\n",
       " np.float64(15.067520512465904),\n",
       " np.float64(15.067520512465904),\n",
       " np.float64(15.06788089888),\n",
       " np.float64(15.06788089888),\n",
       " np.float64(15.06788089888),\n",
       " np.float64(15.068181708696923),\n",
       " np.float64(15.068444638401472),\n",
       " np.float64(15.06870984347262)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GA_GD_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# iterations = range(0, num_cycles+10, 10)\n",
    "\n",
    "iterations = range(0, 100)\n",
    "# Extend the results to the same length\n",
    "GD_results_draw = GD_results[:100]\n",
    "PSO_results_draw = PSO_results[:100]\n",
    "GA_results_draw = GA_results[:100]\n",
    "PSO_GD_results_draw = PSO_GD_results[:100]\n",
    "GA_GD_results_draw = GA_GD_results[:100]\n",
    "\n",
    "\n",
    "#plt.plot(iterations, GD_results_draw, label='Gradient Descent')\n",
    "plt.plot(iterations, PSO_results_draw, label='PSO')\n",
    "plt.plot(iterations, GA_results_draw, label='Genetic Algorithm')\n",
    "plt.plot(iterations, PSO_GD_results_draw, label='PSO-GD')\n",
    "plt.plot(iterations, GA_GD_results_draw, label='GA-GD')\n",
    "\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Secrecy rate (bps/Hz)')\n",
    "plt.title('gamma = 0.8')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Secrecy Rate GD: 14.55176659777728\n",
      "Best Secrecy Rate PSO: 12.476866173861348\n",
      "Best Secrecy Rate GA: 13.457714097721054\n",
      "Best Secrecy Rate PSO-GD: 19.42312619148822\n",
      "Best Secrecy Rate GA-GD: 15.06870984347262\n"
     ]
    }
   ],
   "source": [
    "# Best results of each methods\n",
    "print(\"Best Secrecy Rate GD:\", max(GD_results))\n",
    "print(\"Best Secrecy Rate PSO:\", max(PSO_results))\n",
    "print(\"Best Secrecy Rate GA:\", max(GA_results))\n",
    "print(\"Best Secrecy Rate PSO-GD:\", max(PSO_GD_results))\n",
    "print(\"Best Secrecy Rate GA-GD:\", max(GA_GD_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

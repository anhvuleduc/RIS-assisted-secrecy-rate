{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy, copy\n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 18\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transfer from dBW to W (power)\n",
    "def db2pow(db: float) -> float:\n",
    "    return 10**(db/10)\n",
    "\n",
    "# Function to transfer from W to dBW (power)\n",
    "def pow2db(pow: float) -> float:\n",
    "    return 10*np.log10(pow)\n",
    "\n",
    "# Hermitian transpose of a matrix\n",
    "def HermTranspose(x: np.ndarray) -> np.ndarray:\n",
    "    return x.conj().T\n",
    "\n",
    "def chanGen(zeta: float, d: float, dim1: int, dim2: int) -> np.ndarray:\n",
    "    \"\"\"Function to generate Rayleigh fading channel coefficients\n",
    "\n",
    "    Args:\n",
    "        zeta: Î¾ is the path loss exponent\n",
    "        d: the distance between the transmitter and the receiver\n",
    "        dim1: the number of rows in the channel matrix\n",
    "        dim2: the number of columns in the channel matrix\n",
    "    \"\"\"\n",
    "    pl_ref: float = -30                                    # pathloss (dBW) at reference distance\n",
    "    pl: float = db2pow(pl_ref - 10*zeta*np.log10(d))       # pathloss model at distance d\n",
    "    y: np.ndarray = np.sqrt(0.5*pl)*(np.random.randn(dim1,dim2)\\\n",
    "        + 1j*np.random.randn(dim1,dim2))            # Rayleigh distribution\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = db2pow(-75)                                                                 # noise power\n",
    "N = 10                                                                              # number of transmit antennas\n",
    "Nris = 100                                                                          # number of RIS elements\n",
    "number_of_users = 10                                                                 # number of users\n",
    "number_of_eavesdroppers = 3                                                         # number of eavesdroppers\n",
    "zetaAI = 2.2                                                                        # Path loss exponent of the channel between the Alice and the RIS\n",
    "zetaIB = 2.5                                                                        # Path loss exponent of the channel between the legitimate receivers and the RIS\n",
    "zetaIE = 2.5                                                                        # Path loss exponent of the channel between the eavesdroppers and the RIS\n",
    "zetaAB = 3.5                                                                        # Path loss exponent of the channel between the Alice and the legitimate receivers\n",
    "zetaAE = 3.5                                                                        # Path loss exponent of the channel between the Alice and the eavesdroppers\n",
    "\n",
    "dAI = 50                                                                            # distance between Alice and the RIS\n",
    "dv = 2                                                                              # Vertical distance between the Alice and the Eve and Bob\n",
    "dABh = np.random.uniform(5, 10, size=number_of_users)                               # Horizontal distance between Alice and the legitimate receivers\n",
    "dAEh = np.random.uniform(50, 150, size=number_of_eavesdroppers)                     # Horizontal distance between Alice and the eavesdroppers\n",
    "dAB = [np.sqrt(dABh[i]**2 + dv**2) for i in range(number_of_users)]                 # Distance between Alice and the legitimate receivers\n",
    "dAE = [np.sqrt(dAEh[i]**2 + dv**2) for i in range(number_of_eavesdroppers)]         # Distance between Alice and the eavesdroppers\n",
    "dIB = [np.sqrt((dABh[i]-dAI)**2 + dv**2) for i in range(number_of_users)]           # Distance between the legitimate receivers and the RIS\n",
    "dIE = [np.sqrt((dAEh[i]-dAI)**2 + dv**2) for i in range(number_of_eavesdroppers)]   # Distance between the eavesdroppers and the RIS\n",
    "\n",
    "gamma = 0.8 # Lower bound for user's link quality\n",
    "pmax = 1000  # Maximum transmit power of Alice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_beamforming_vectors(w: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Function to normalise the beamforming vectors\n",
    "\n",
    "    Args:\n",
    "        w: the beamforming vectors\n",
    "    \"\"\"\n",
    "    total_norm_squared = 0\n",
    "    for i in range(number_of_users):\n",
    "        total_norm_squared += (np.linalg.norm(w[i]) ** 2)\n",
    "    if total_norm_squared <= pmax:\n",
    "        return w\n",
    "    for i in range(number_of_users):\n",
    "        w[i] = w[i] / (total_norm_squared ** 0.5) * np.sqrt(pmax)\n",
    "    return w\n",
    "\n",
    "def generate_random_beamforming_vector():\n",
    "  '''\n",
    "  Generate one random beamforming vector\n",
    "  '''\n",
    "  return np.random.uniform(-1, 1, (N, 1)) + 1j * np.random.uniform(-1, 1, (N, 1))\n",
    "\n",
    "def generate_random_beamforming_vectors():\n",
    "    # Generate random complex numbers for each element of the beamforming vector\n",
    "    beamforming_vectors = [generate_random_beamforming_vector() for _ in range (number_of_users)]\n",
    "    \n",
    "    # Normalize the vectors\n",
    "    beamforming_vectors = normalise_beamforming_vectors(beamforming_vectors)\n",
    "    return beamforming_vectors\n",
    "    #w: list of beamforming vectors, length = number of users, elements are N x 1\n",
    "\n",
    "def generate_random_theta():\n",
    "    theta = np.random.uniform(-np.pi, np.pi, (1, Nris))\n",
    "    theta = np.exp(1j * theta)\n",
    "    return theta\n",
    "    #theta: phase shift of RIS, size 1 x Nris\n",
    "\n",
    "def generate_random_theta_angles(size: int):\n",
    "  \"\"\"\n",
    "    Generate a random vector of angles from -pi to pi\n",
    "  \"\"\"\n",
    "  return np.random.uniform(-np.pi, np.pi, size=(1, size))\n",
    "\n",
    "def theta_angles_to_theta_vector(angles: np.ndarray[np.float64]) -> np.ndarray[np.complex128]:\n",
    "  \"\"\"\n",
    "    Convert a vector of angles to a vector of complex numbers on the unit circle\n",
    "  \"\"\"\n",
    "  return np.exp(1j * angles)\n",
    "\n",
    "def theta_vector_to_theta_angles(theta: np.ndarray[np.complex128]) -> np.ndarray[np.float64]:\n",
    "  \"\"\"\n",
    "    Convert a vector of complex numbers on the unit circle to a vector of angles\n",
    "  \"\"\"\n",
    "  return np.angle(theta)\n",
    "\n",
    "def generateChannel():\n",
    "    normFact: float = 1/np.sqrt(sigma)\n",
    "    Hai = chanGen(zetaAI, dAI, Nris, N)                                                         # Alice to RIS channel\n",
    "    hib = [normFact*chanGen(zetaIB, dIB[i], 1, Nris) for i in range(number_of_users)]           # Channel between the RIS and the legitimate receivers\n",
    "    hie = [normFact*chanGen(zetaIE, dIE[i], 1, Nris) for i in range(number_of_eavesdroppers)]   # Channel between the RIS and the eavesdroppers\n",
    "    hab = [normFact*chanGen(zetaAB, dAB[i], 1, N) for i in range(number_of_users)]              # Channel between Alice and the legitimate receivers\n",
    "    hae = [normFact*chanGen(zetaAE, dAE[i], 1, N) for i in range(number_of_eavesdroppers)]      # Channel between Alice and the eavesdroppers\n",
    "    return Hai, hib, hie, hab, hae\n",
    "\n",
    "    #Hai: Channel between Alice and RIS: Nris x N  \n",
    "    #hib: Channel between RIS and users: List of length number_of_users, elements are 1 x Nris\n",
    "    #hab: Channel between Alice and users: List of length number_of_users, elements are 1 x N\n",
    "    #hie: Channel between RIS and eavesdroppers: List of length number_of_eavesdroppers, elements are 1 x Nris\n",
    "    #hae: Channel between Alice and eavesdroppers: List of length number_of_eavesdroppers, elements are 1 x N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseed\n",
    "# np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Channel generation\n",
    "Hai, hib, hie, hab, hae = generateChannel()\n",
    "\n",
    "# Generate random theta and w\n",
    "theta_init = generate_random_theta()\n",
    "w_init = generate_random_beamforming_vectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secrecy_rate_objective_function(theta, w) -> float:\n",
    "    secrecy_rate: float = 0\n",
    "    for k in range(number_of_users):\n",
    "        R_bk = []\n",
    "        # Legitimate user k\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        C_bk = np.log2(1 + gamma_bk)\n",
    "        \n",
    "        for m in range(number_of_eavesdroppers):\n",
    "            # Eavesdropper i\n",
    "            Z_em = hie[m] @ np.diag(theta.flatten()) @ Hai + hae[m]\n",
    "            numGamma_em = np.abs(Z_em @ w[k])**2\n",
    "            denGamma_em = 1 + np.sum([np.abs(Z_em @ w[j])**2 for j in range(number_of_users) if j != k])\n",
    "            gamma_em = numGamma_em/denGamma_em\n",
    "            C_em = np.log2(1 + gamma_em)\n",
    "            R_bk.append(C_bk - C_em)\n",
    "        \n",
    "        secrecy_rate += max(min(R_bk),0)\n",
    "\n",
    "    # Return the only element in the matrix as it is currently a 1x1 np array\n",
    "    return secrecy_rate[0, 0]\n",
    "\n",
    "# Check if the current set up is valid (every users' C_bk >= gamma)\n",
    "# Returns the index of the invalid user whose C_bk is highest among the invalid or -1 if all users are valid\n",
    "def check_validity(theta, w) -> int:\n",
    "    user = -1\n",
    "    maxx = 0\n",
    "    for k in range(number_of_users):\n",
    "        # Legitimate user k\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        C_bk = np.log2(1 + gamma_bk)\n",
    "        \n",
    "        if (C_bk < gamma):\n",
    "            if C_bk > maxx:\n",
    "                maxx = C_bk\n",
    "                user = k\n",
    "    return user\n",
    "\n",
    "# Print the C_bk of each user\n",
    "def print_users_Cbk(theta, w) -> None:\n",
    "    for k in range(number_of_users):\n",
    "        # Legitimate user k\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        C_bk = np.log2(1 + gamma_bk)\n",
    "        print(float(C_bk), end = \" \")\n",
    "    print()\n",
    "\n",
    "# Calculate the C_bk of a user\n",
    "def calculate_user_Cbk(theta, w, user) -> float:\n",
    "    Z_bk = hib[user] @ np.diag(theta.flatten()) @ Hai + hab[user]\n",
    "    numGamma_bk = np.abs(Z_bk @ w[user])**2\n",
    "    denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != user])\n",
    "    gamma_bk = numGamma_bk/denGamma_bk\n",
    "    C_bk = np.log2(1 + gamma_bk)\n",
    "    return C_bk\n",
    "\n",
    "# Using gradient descent to repair the beamforming vector of a user\n",
    "# Try to make that user's C_bk >= gamma\n",
    "def repair_beamforming_vectors(theta, w, user, learning_rate = 0.01, max_iter = 500):\n",
    "    #print(\"Initial norm of user beamforming vector: \", np.linalg.norm(w[user]))\n",
    "    #print(\"Before update beamforming of user \", user, \": \")\n",
    "    #print_users_Cbk(theta, w)\n",
    "    while (calculate_user_Cbk(theta, w, user) < gamma + 0.2 and max_iter > 0):\n",
    "        Z_bk = hib[user] @ np.diag(theta.flatten()) @ Hai + hab[user]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[user])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != user])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        \n",
    "        num_grad_C_bk_to_w_k = 2 * (HermTranspose(Z_bk) @ Z_bk @ w[user])\n",
    "        den_grad_C_bk_to_w_k = (1 + gamma_bk) * np.log(2) * (1 + sum([abs(Z_bk @ w[j]) for j in range (number_of_users) if j != user]))\n",
    "        grad_C_bk_to_w_k = num_grad_C_bk_to_w_k / den_grad_C_bk_to_w_k\n",
    "        w[user] = w[user] + learning_rate * grad_C_bk_to_w_k\n",
    "        #w[user] *= 2\n",
    "        max_iter -= 1\n",
    "\n",
    "        w = normalise_beamforming_vectors(w)\n",
    "    #print(\"New norm of user beamforming vector: \", np.linalg.norm(w[user]))\n",
    "    #print(\"After update beamforming of user \", user, \": \")\n",
    "    #print_users_Cbk(theta, w)\n",
    "    return w\n",
    "\n",
    "# Using gradient descent to repair the whole (theta, w) set up\n",
    "def repair(theta, w, iter = 100):\n",
    "    invalid_user = check_validity(theta, w)\n",
    "    while (invalid_user != -1 and iter > 0):\n",
    "        w = repair_beamforming_vectors(theta, w, invalid_user)\n",
    "        invalid_user = check_validity(theta, w)\n",
    "        iter -= 1\n",
    "    if (invalid_user != -1):\n",
    "        theta, w = generate_random_theta(), generate_random_beamforming_vectors()\n",
    "        return repair(theta, w)\n",
    "    return theta, w\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between Alice and the receivers:  [8.490781968990742, 7.788436718125179, 9.603571583724229, 6.238482023509884, 9.474660073970615, 8.976325835141209, 8.567226456673964, 10.13869852751857, 6.595395392664417, 5.516822173929771]\n",
      "distance between Alice and the eavesdroppers:  [113.58952016905081, 134.74608229833302, 123.63364039696921]\n",
      "Secrecy Rate: 2.405041669607317\n"
     ]
    }
   ],
   "source": [
    "# print(theta_init)\n",
    "print(\"distance between Alice and the receivers: \", dAB)\n",
    "print(\"distance between Alice and the eavesdroppers: \", dAE)\n",
    "print(\"Secrecy Rate:\", secrecy_rate_objective_function(theta_init, w_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent for Maximization (GD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_w(theta, w):\n",
    "    grad_w = []\n",
    "    Z_e_max = [] #Z_e_max[k] = Z_e_max for user k\n",
    "    gamma_e_max = [] #gamma_e_max[k] = gamma_e_max for user k\n",
    "    Z_b = [] #Z_b[k] = Z_bk\n",
    "    gamma_b = [] #gamma_b[k] = gamma_bk\n",
    "    counted = [] #counted[k] = true if gamma_k > gamma_e_max[k]\n",
    "    \n",
    "    #Precalculation \n",
    "    for k in range(number_of_users):\n",
    "        gamma_e = []\n",
    "        for m in range (number_of_eavesdroppers):\n",
    "            Z_em = hie[m] @ np.diag(theta.flatten()) @ Hai + hae[m]\n",
    "            numGamma_em = np.abs(Z_em @ w[k])**2\n",
    "            denGamma_em = 1 + np.sum([np.abs(Z_em @ w[j])**2 for j in range(number_of_users) if j != k])\n",
    "            gamma_em = numGamma_em/denGamma_em\n",
    "            gamma_e.append(gamma_em)\n",
    "        \n",
    "        gamma_e_max.append(max(gamma_e))\n",
    "        index_e_max = gamma_e.index(max(gamma_e))\n",
    "        Z_e = hie[index_e_max] @ np.diag(theta.flatten()) @ Hai + hae[index_e_max]\n",
    "        Z_e_max.append(Z_e)\n",
    "\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "\n",
    "        Z_b.append(Z_bk)\n",
    "        gamma_b.append(gamma_bk)\n",
    "\n",
    "        counted.append(gamma_bk > gamma_e[index_e_max])\n",
    "\n",
    "\n",
    "    #Calculating grad for i-th beamforming vector\n",
    "    for i in range(number_of_users):\n",
    "        grad = np.zeros((N, 1))\n",
    "        for k in range (number_of_users):\n",
    "            if (counted[k] == False):\n",
    "                continue\n",
    "            if (k == i):\n",
    "                num_grad_C_bk_to_w_k = 2 * (HermTranspose(Z_b[k]) @ Z_b[k] @ w[k])\n",
    "                den_grad_C_bk_to_w_k = (1 + gamma_b[k]) * np.log(2) * (1 + sum([abs(Z_b[k] @ w[j]) for j in range (number_of_users) if j != k]))\n",
    "                grad_C_bk_to_w_k = num_grad_C_bk_to_w_k / den_grad_C_bk_to_w_k\n",
    "\n",
    "                num_grad_C_e_max_to_w_k = 2 * (HermTranspose(Z_e_max[k]) @ Z_e_max[k] @ w[k])\n",
    "                den_grad_C_e_max_to_w_k = (1 + gamma_e_max[k]) * np.log(2) * (1 + sum([abs(Z_e_max[k] @ w[j]) for j in range (number_of_users) if j != k]))\n",
    "                grad_C_e_max_to_w_k = num_grad_C_e_max_to_w_k / den_grad_C_e_max_to_w_k\n",
    "                \n",
    "                grad = grad - (grad_C_bk_to_w_k - grad_C_e_max_to_w_k)\n",
    "            else:\n",
    "                num_grad_C_bk_to_w_i = -2 * abs(Z_b[k] @ w[k]) * (HermTranspose(Z_b[k]) @ Z_b[k] @ w[i])\n",
    "                den_grad_C_bk_to_w_i = (1 + gamma_b[k]) * np.log(2) * (1 + sum([abs(Z_b[k] @ w[j]) for j in range (number_of_users) if j != k])) ** 2\n",
    "                grad_C_bk_to_w_i = num_grad_C_bk_to_w_i / den_grad_C_bk_to_w_i\n",
    "\n",
    "                num_grad_C_e_max_to_w_i = -2 * abs(Z_e_max[k] @ w[k]) * (HermTranspose(Z_e_max[k]) @ Z_e_max[k] @ w[i])\n",
    "                den_grad_C_e_max_to_w_i = (1 + gamma_e_max[k]) * np.log(2) * (1 + sum([abs(Z_e_max[k] @ w[j]) for j in range (number_of_users) if j != k])) ** 2\n",
    "                grad_C_e_max_to_w_i = num_grad_C_e_max_to_w_i / den_grad_C_e_max_to_w_i\n",
    "\n",
    "                grad = grad - (grad_C_bk_to_w_i - grad_C_e_max_to_w_i)\n",
    "            \n",
    "        grad_w.append(grad)\n",
    "    return grad_w\n",
    "\n",
    "def compute_gradient_theta_central(theta, w, epsilon=1e-3):\n",
    "    perturbation = epsilon #+ epsilon * 1j\n",
    "    grad_theta = []\n",
    "    for i in range(Nris):\n",
    "        theta_plus = copy(theta)\n",
    "        theta_plus[0, i] += perturbation\n",
    "        theta_minus = copy(theta)\n",
    "        theta_minus[0, i] -= perturbation\n",
    "        grad_theta_i = (secrecy_rate_objective_function(theta_plus, w) - secrecy_rate_objective_function(theta_minus, w)) / (2*epsilon)\n",
    "        grad_theta.append(grad_theta_i)\n",
    "            \n",
    "    return np.array(grad_theta)\n",
    "\n",
    "def compute_gradient_theta_forward(theta, w, original_secrecy_rate=None, epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Faster implementation of the gradient calculation\n",
    "\n",
    "    Improvements:\n",
    "    - Use forward difference instead of central difference\n",
    "    \"\"\"\n",
    "    perturbation = epsilon + epsilon * 1j\n",
    "    grad_theta = []\n",
    "    for i in range(Nris):\n",
    "        theta_plus = copy(theta)\n",
    "        theta_plus[0, i] += perturbation\n",
    "        grad_theta_i = (secrecy_rate_objective_function(theta_plus, w) - original_secrecy_rate) / epsilon\n",
    "        grad_theta.append(grad_theta_i)\n",
    "\n",
    "    return np.array(grad_theta)\n",
    "\n",
    "def compute_gradient_theta(theta, w):\n",
    "    Z_e_max = [] #Z_e_max[k] = Z_e_max for user k\n",
    "    gamma_e_max = [] #gamma_e_max[k] = gamma_e_max for user k\n",
    "    Z_b = [] #Z_b[k] = Z_bk\n",
    "    gamma_b = [] #gamma_b[k] = gamma_bk\n",
    "    counted = [] #counted[k] = true if gamma_k > gamma_e_max[k]\n",
    "    index_e_max_list = []\n",
    "    #Precalculation\n",
    "    for k in range(number_of_users):\n",
    "        gamma_e = []\n",
    "        for m in range (number_of_eavesdroppers):\n",
    "            Z_em = hie[m] @ np.diag(theta.flatten()) @ Hai + hae[m]\n",
    "            numGamma_em = np.abs(Z_em @ w[k])**2\n",
    "            denGamma_em = 1 + np.sum([np.abs(Z_em @ w[j])**2 for j in range(number_of_users) if j != k])\n",
    "            gamma_em = numGamma_em/denGamma_em\n",
    "            gamma_e.append(gamma_em)\n",
    "        \n",
    "        gamma_e_max.append(max(gamma_e))\n",
    "        index_e_max = gamma_e.index(max(gamma_e))\n",
    "        index_e_max_list.append(index_e_max)\n",
    "        Z_e = hie[index_e_max] @ np.diag(theta.flatten()) @ Hai + hae[index_e_max]\n",
    "        Z_e_max.append(Z_e)\n",
    "\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "\n",
    "        Z_b.append(Z_bk)\n",
    "        gamma_b.append(gamma_bk)\n",
    "\n",
    "        counted.append(gamma_bk > gamma_e[index_e_max])\n",
    "\n",
    "\n",
    "    grad_theta = 0\n",
    "\n",
    "\n",
    "    for k in range(number_of_users):\n",
    "        if (counted[k] == False):\n",
    "            continue\n",
    "\n",
    "        grad_Z_bk_wk_to_theta = (1/sigma) * np.diag(hib[k].flatten()) @ Hai @ w[k]\n",
    "        grad_gamma_bk_to_theta_first_term = (2 * (Z_b[k] @ w[k]) * grad_Z_bk_wk_to_theta) * (1 + sum([np.linalg.norm(Z_b[k] @ w[j])**2 for j in range (number_of_users) if j != k]))\n",
    "        grad_gamma_bk_to_theta_second_term = sum([2 * (Z_b[k] @ w[j]) * grad_Z_bk_wk_to_theta for j in range(number_of_users) if j != k]) * (np.linalg.norm(Z_b[k] @ w[k]) ** 2)\n",
    "        grad_gamma_bk_to_theta_third_term = (1 + sum([np.linalg.norm(Z_b[k] @ w[j]) for j in range (number_of_users) if j != k])**2) ** 2\n",
    "        grad_gamma_bk_to_theta = (grad_gamma_bk_to_theta_first_term - grad_gamma_bk_to_theta_second_term) / grad_gamma_bk_to_theta_third_term\n",
    "\n",
    "        grad_C_bk_to_theta = 1 / ((1 + gamma_b[k]) * np.log(2)) * grad_gamma_bk_to_theta\n",
    "\n",
    "        grad_Z_emax_wk_to_theta = (1/sigma) * np.diag(hie[index_e_max_list[k]].flatten()) @ Hai @ w[k]\n",
    "\n",
    "        grad_gamma_emax_to_theta_first_term = (2 * (Z_e_max[k] @ w[k]) * grad_Z_emax_wk_to_theta) * (1 + sum([np.linalg.norm(Z_e_max[k] @ w[j])**2 for j in range (number_of_users) if j != k]))\n",
    "        grad_gamma_emax_to_theta_second_term = sum([2 * (Z_e_max[k] @ w[j]) * grad_Z_emax_wk_to_theta for j in range(number_of_users) if j != k]) * (np.linalg.norm(Z_e_max[k] @ w[k]) ** 2)\n",
    "        grad_gamma_emax_to_theta_third_term = (1 + sum([np.linalg.norm(Z_e_max[k] @ w[j]) for j in range (number_of_users) if j != k])**2) ** 2\n",
    "        grad_gamma_emax_to_theta = (grad_gamma_emax_to_theta_first_term - grad_gamma_emax_to_theta_second_term) / grad_gamma_emax_to_theta_third_term\n",
    "\n",
    "        grad_C_emax_to_theta = 1 / ((1 + gamma_e_max[k]) * np.log(2)) * grad_gamma_emax_to_theta\n",
    "\n",
    "        grad_theta -= (grad_C_bk_to_theta - grad_C_emax_to_theta)\n",
    "    \n",
    "    return np.array(grad_theta).reshape((1, Nris))\n",
    "    \n",
    "\n",
    "\n",
    "def gradient_descent_update(w, theta, learning_rate, original_secrecy_rate=None):\n",
    "    grad_w = compute_gradient_w(theta, w)\n",
    "    grad_theta = compute_gradient_theta(theta, w)\n",
    "    w_new = [w[i] - learning_rate * grad_w[i] for i in range (number_of_users)]\n",
    "    w_new = normalise_beamforming_vectors(w_new)\n",
    "        \n",
    "    theta_new = theta - learning_rate * grad_theta\n",
    "    theta_new = np.exp(1j * np.angle(theta_new))\n",
    "\n",
    "    return w_new, theta_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Secrecy Rate GD: 8.699681395518992\n",
      "Iteration 0\n",
      "Secrecy Rate: 8.699681395518992\n",
      "Iteration 1\n",
      "Secrecy Rate: 8.901927576581638\n",
      "Iteration 2\n",
      "Secrecy Rate: 9.080896832818697\n",
      "Iteration 3\n",
      "Secrecy Rate: 9.244444622040335\n",
      "Iteration 4\n",
      "Secrecy Rate: 9.40418182148963\n",
      "Iteration 5\n",
      "Secrecy Rate: 9.558978996319762\n",
      "Iteration 6\n",
      "Secrecy Rate: 9.708608369689669\n",
      "Iteration 7\n",
      "Secrecy Rate: 9.85306946927965\n",
      "Iteration 8\n",
      "Secrecy Rate: 9.992404573354381\n",
      "Iteration 9\n",
      "Secrecy Rate: 10.126692563097183\n",
      "Iteration 10\n",
      "Secrecy Rate: 10.25604216228187\n",
      "Iteration 11\n",
      "Secrecy Rate: 10.380444687253885\n",
      "Iteration 12\n",
      "Secrecy Rate: 10.499771925204728\n",
      "Iteration 13\n",
      "Secrecy Rate: 10.614019325408291\n",
      "Iteration 14\n",
      "Secrecy Rate: 10.723003815574728\n",
      "Iteration 15\n",
      "Secrecy Rate: 10.824711845591866\n",
      "Iteration 16\n",
      "Secrecy Rate: 10.925911096762182\n",
      "Iteration 17\n",
      "Secrecy Rate: 11.023135975565388\n",
      "Iteration 18\n",
      "Secrecy Rate: 11.116269529925304\n",
      "Iteration 19\n",
      "Secrecy Rate: 11.205923007806987\n",
      "Iteration 20\n",
      "Secrecy Rate: 11.292325227857422\n",
      "Iteration 21\n",
      "Secrecy Rate: 11.375006588950948\n",
      "Iteration 22\n",
      "Secrecy Rate: 11.44699702712448\n",
      "Iteration 23\n",
      "Secrecy Rate: 11.527696262718516\n",
      "Iteration 24\n",
      "Secrecy Rate: 11.59660986435504\n",
      "Iteration 25\n",
      "Secrecy Rate: 11.670654694718287\n",
      "Iteration 26\n",
      "Secrecy Rate: 11.733571130578609\n",
      "Iteration 27\n",
      "Secrecy Rate: 11.796950402247553\n",
      "Iteration 28\n",
      "Secrecy Rate: 11.865867599421504\n",
      "Iteration 29\n",
      "Secrecy Rate: 11.919653098606126\n",
      "Iteration 30\n",
      "Secrecy Rate: 11.97731261447121\n",
      "Iteration 31\n",
      "Secrecy Rate: 12.03282100479801\n",
      "Iteration 32\n",
      "Secrecy Rate: 12.086318813493397\n",
      "Iteration 33\n",
      "Secrecy Rate: 12.13785255936322\n",
      "Iteration 34\n",
      "Secrecy Rate: 12.187505416237318\n",
      "Iteration 35\n",
      "Secrecy Rate: 12.235361301813143\n",
      "Iteration 36\n",
      "Secrecy Rate: 12.281499723026581\n",
      "Iteration 37\n",
      "Secrecy Rate: 12.325996145302772\n",
      "Iteration 38\n",
      "Secrecy Rate: 12.368922205919795\n",
      "Iteration 39\n",
      "Secrecy Rate: 12.410345884578144\n",
      "Iteration 40\n",
      "Secrecy Rate: 12.450331636821236\n",
      "Iteration 41\n",
      "Secrecy Rate: 12.488940501929214\n",
      "Iteration 42\n",
      "Secrecy Rate: 12.526230194612928\n",
      "Iteration 43\n",
      "Secrecy Rate: 12.56225519223995\n",
      "Iteration 44\n",
      "Secrecy Rate: 12.597066833592745\n",
      "Iteration 45\n",
      "Secrecy Rate: 12.63071344767034\n",
      "Iteration 46\n",
      "Secrecy Rate: 12.663240527755644\n",
      "Iteration 47\n",
      "Secrecy Rate: 12.694690953286237\n",
      "Iteration 48\n",
      "Secrecy Rate: 12.7251052432232\n",
      "Iteration 49\n",
      "Secrecy Rate: 12.754521811453792\n",
      "Iteration 50\n",
      "Secrecy Rate: 12.782977197334866\n",
      "Iteration 51\n",
      "Secrecy Rate: 12.810506259079162\n",
      "Iteration 52\n",
      "Secrecy Rate: 12.837142331447513\n",
      "Iteration 53\n",
      "Secrecy Rate: 12.862917354383082\n",
      "Iteration 54\n",
      "Secrecy Rate: 12.887861977562498\n",
      "Iteration 55\n",
      "Secrecy Rate: 12.912005642585608\n",
      "Iteration 56\n",
      "Secrecy Rate: 12.935376643004556\n",
      "Iteration 57\n",
      "Secrecy Rate: 12.958002163181249\n",
      "Iteration 58\n",
      "Secrecy Rate: 12.97990829917367\n",
      "Iteration 59\n",
      "Secrecy Rate: 13.00112006728581\n",
      "Iteration 60\n",
      "Secrecy Rate: 13.0216614076133\n",
      "Iteration 61\n",
      "Secrecy Rate: 13.041555190326076\n",
      "Iteration 62\n",
      "Secrecy Rate: 13.060823231418588\n",
      "Iteration 63\n",
      "Secrecy Rate: 13.079486322462875\n",
      "Iteration 64\n",
      "Secrecy Rate: 13.09756427601806\n",
      "Iteration 65\n",
      "Secrecy Rate: 13.11507598540869\n",
      "Iteration 66\n",
      "Secrecy Rate: 13.13203949517839\n",
      "Iteration 67\n",
      "Secrecy Rate: 13.148472077078113\n",
      "Iteration 68\n",
      "Secrecy Rate: 13.16439030611684\n",
      "Iteration 69\n",
      "Secrecy Rate: 13.17981013186682\n",
      "Iteration 70\n",
      "Secrecy Rate: 13.194746941547557\n",
      "Iteration 71\n",
      "Secrecy Rate: 13.209215613001005\n",
      "Iteration 72\n",
      "Secrecy Rate: 13.22323055714853\n",
      "Iteration 73\n",
      "Secrecy Rate: 13.23680575065141\n",
      "Iteration 74\n",
      "Secrecy Rate: 13.2499547601949\n",
      "Iteration 75\n",
      "Secrecy Rate: 13.262690760114292\n",
      "Iteration 76\n",
      "Secrecy Rate: 13.275026545078813\n",
      "Iteration 77\n",
      "Secrecy Rate: 13.2869745393604\n",
      "Iteration 78\n",
      "Secrecy Rate: 13.298546803938292\n",
      "Iteration 79\n",
      "Secrecy Rate: 13.309755042397242\n",
      "Iteration 80\n",
      "Secrecy Rate: 13.320610606308943\n",
      "Iteration 81\n",
      "Secrecy Rate: 13.33112450056175\n",
      "Iteration 82\n",
      "Secrecy Rate: 13.341307388928499\n",
      "Iteration 83\n",
      "Secrecy Rate: 13.351169600031946\n",
      "Iteration 84\n",
      "Secrecy Rate: 13.36072113377531\n",
      "Iteration 85\n",
      "Secrecy Rate: 13.36997166824342\n",
      "Iteration 86\n",
      "Secrecy Rate: 13.378930567040715\n",
      "Iteration 87\n",
      "Secrecy Rate: 13.387606887009206\n",
      "Iteration 88\n",
      "Secrecy Rate: 13.396009386257944\n",
      "Iteration 89\n",
      "Secrecy Rate: 13.404146532431557\n",
      "Iteration 90\n",
      "Secrecy Rate: 13.412026511146218\n",
      "Iteration 91\n",
      "Secrecy Rate: 13.419657234525413\n",
      "Iteration 92\n",
      "Secrecy Rate: 13.427046349773391\n",
      "Iteration 93\n",
      "Secrecy Rate: 13.434201247730684\n",
      "Iteration 94\n",
      "Secrecy Rate: 13.441129071362585\n",
      "Iteration 95\n",
      "Secrecy Rate: 13.44783672413827\n",
      "Iteration 96\n",
      "Secrecy Rate: 13.454330878264418\n",
      "Iteration 97\n",
      "Secrecy Rate: 13.460617982743159\n",
      "Iteration 98\n",
      "Secrecy Rate: 13.466704271229652\n",
      "Iteration 99\n",
      "Secrecy Rate: 13.47259576966964\n",
      "Iteration 100\n",
      "Secrecy Rate: 13.478298303701887\n",
      "Iteration 101\n",
      "Secrecy Rate: 13.483817505814525\n",
      "Iteration 102\n",
      "Secrecy Rate: 13.489158822248031\n",
      "Iteration 103\n",
      "Secrecy Rate: 13.494327519640851\n",
      "Iteration 104\n",
      "Secrecy Rate: 13.499328691416551\n",
      "Iteration 105\n",
      "Secrecy Rate: 13.504167263913926\n",
      "Iteration 106\n",
      "Secrecy Rate: 13.508848002263564\n",
      "Iteration 107\n",
      "Secrecy Rate: 13.513375516016328\n",
      "Iteration 108\n",
      "Secrecy Rate: 13.517754264530595\n",
      "Iteration 109\n",
      "Secrecy Rate: 13.52198856212642\n",
      "Iteration 110\n",
      "Secrecy Rate: 13.526082583015745\n",
      "Iteration 111\n",
      "Secrecy Rate: 13.530040366018543\n",
      "Iteration 112\n",
      "Secrecy Rate: 13.533865819075313\n",
      "Iteration 113\n",
      "Secrecy Rate: 13.537562723566834\n",
      "Iteration 114\n",
      "Secrecy Rate: 13.541134738452262\n",
      "Iteration 115\n",
      "Secrecy Rate: 13.544585404236805\n",
      "Iteration 116\n",
      "Secrecy Rate: 13.547362202843326\n",
      "Iteration 117\n",
      "Secrecy Rate: 13.568404153389444\n",
      "Iteration 118\n",
      "Secrecy Rate: 13.575723408297618\n",
      "Iteration 119\n",
      "Secrecy Rate: 13.5779196911799\n",
      "Iteration 120\n",
      "Secrecy Rate: 13.580243175702204\n",
      "Iteration 121\n",
      "Secrecy Rate: 13.590034776853287\n",
      "Iteration 122\n",
      "Secrecy Rate: 13.599805141425763\n",
      "Iteration 123\n",
      "Secrecy Rate: 13.609503064313564\n",
      "Iteration 124\n",
      "Secrecy Rate: 13.619117000012821\n",
      "Iteration 125\n",
      "Secrecy Rate: 13.628647192863827\n",
      "Iteration 126\n",
      "Secrecy Rate: 13.638094702821876\n",
      "Iteration 127\n",
      "Secrecy Rate: 13.647460432675425\n",
      "Iteration 128\n",
      "Secrecy Rate: 13.656745304804048\n",
      "Iteration 129\n",
      "Secrecy Rate: 13.665950229964906\n",
      "Iteration 130\n",
      "Secrecy Rate: 13.675076108883488\n",
      "Iteration 131\n",
      "Secrecy Rate: 13.68412383240721\n",
      "Iteration 132\n",
      "Secrecy Rate: 13.693094281589735\n",
      "Iteration 133\n",
      "Secrecy Rate: 13.701988327799338\n",
      "Iteration 134\n",
      "Secrecy Rate: 13.710806832812047\n",
      "Iteration 135\n",
      "Secrecy Rate: 13.719550648895803\n",
      "Iteration 136\n",
      "Secrecy Rate: 13.728220618886485\n",
      "Iteration 137\n",
      "Secrecy Rate: 13.736817576256982\n",
      "Iteration 138\n",
      "Secrecy Rate: 13.745342345180386\n",
      "Iteration 139\n",
      "Secrecy Rate: 13.753795740588327\n",
      "Iteration 140\n",
      "Secrecy Rate: 13.762178568225401\n",
      "Iteration 141\n",
      "Secrecy Rate: 13.770491624700472\n",
      "Iteration 142\n",
      "Secrecy Rate: 13.77873569753569\n",
      "Iteration 143\n",
      "Secrecy Rate: 13.786911565213833\n",
      "Iteration 144\n",
      "Secrecy Rate: 13.795019997224646\n",
      "Iteration 145\n",
      "Secrecy Rate: 13.803061754110661\n",
      "Iteration 146\n",
      "Secrecy Rate: 13.81103758751302\n",
      "Iteration 147\n",
      "Secrecy Rate: 13.818948240217658\n",
      "Iteration 148\n",
      "Secrecy Rate: 13.82679444620219\n",
      "Iteration 149\n",
      "Secrecy Rate: 13.834576930683866\n",
      "Iteration 150\n",
      "Secrecy Rate: 13.842296410168704\n",
      "Iteration 151\n",
      "Secrecy Rate: 13.849953592502136\n",
      "Iteration 152\n",
      "Secrecy Rate: 13.857549176921184\n",
      "Iteration 153\n",
      "Secrecy Rate: 13.865083854108384\n",
      "Iteration 154\n",
      "Secrecy Rate: 13.87255830624747\n",
      "Iteration 155\n",
      "Secrecy Rate: 13.879973207080898\n",
      "Iteration 156\n",
      "Secrecy Rate: 13.887329221969196\n",
      "Iteration 157\n",
      "Secrecy Rate: 13.894627007952193\n",
      "Iteration 158\n",
      "Secrecy Rate: 13.901867213812025\n",
      "Iteration 159\n",
      "Secrecy Rate: 13.909050480137983\n",
      "Iteration 160\n",
      "Secrecy Rate: 13.91617743939302\n",
      "Iteration 161\n",
      "Secrecy Rate: 13.92324871598196\n",
      "Iteration 162\n",
      "Secrecy Rate: 13.930264926321241\n",
      "Iteration 163\n",
      "Secrecy Rate: 13.937226678910209\n",
      "Iteration 164\n",
      "Secrecy Rate: 13.944134574403732\n",
      "Iteration 165\n",
      "Secrecy Rate: 13.950989205686163\n",
      "Iteration 166\n",
      "Secrecy Rate: 13.957791157946478\n",
      "Iteration 167\n",
      "Secrecy Rate: 13.964541008754487\n",
      "Iteration 168\n",
      "Secrecy Rate: 13.971239328138061\n",
      "Iteration 169\n",
      "Secrecy Rate: 13.977886678661203\n",
      "Iteration 170\n",
      "Secrecy Rate: 13.984483615502901\n",
      "Iteration 171\n",
      "Secrecy Rate: 13.99103068653665\n",
      "Iteration 172\n",
      "Secrecy Rate: 13.997528432410542\n",
      "Iteration 173\n",
      "Secrecy Rate: 14.003977386627806\n",
      "Iteration 174\n",
      "Secrecy Rate: 14.010378075627735\n",
      "Iteration 175\n",
      "Secrecy Rate: 14.016731018866874\n",
      "Iteration 176\n",
      "Secrecy Rate: 14.02303672890043\n",
      "Iteration 177\n",
      "Secrecy Rate: 14.029295711463718\n",
      "Iteration 178\n",
      "Secrecy Rate: 14.035508465553715\n",
      "Iteration 179\n",
      "Secrecy Rate: 14.041675483510488\n",
      "Iteration 180\n",
      "Secrecy Rate: 14.04779725109854\n",
      "Iteration 181\n",
      "Secrecy Rate: 14.053874247587945\n",
      "Iteration 182\n",
      "Secrecy Rate: 14.059906945835223\n",
      "Iteration 183\n",
      "Secrecy Rate: 14.065895812363918\n",
      "Iteration 184\n",
      "Secrecy Rate: 14.071841307444789\n",
      "Iteration 185\n",
      "Secrecy Rate: 14.077743885175579\n",
      "Iteration 186\n",
      "Secrecy Rate: 14.083603993560349\n",
      "Iteration 187\n",
      "Secrecy Rate: 14.089422074588244\n",
      "Iteration 188\n",
      "Secrecy Rate: 14.095198564311774\n",
      "Iteration 189\n",
      "Secrecy Rate: 14.100845436250149\n",
      "Iteration 190\n",
      "Secrecy Rate: 14.109506661190114\n",
      "Iteration 191\n",
      "Secrecy Rate: 14.113170789389466\n",
      "Iteration 192\n",
      "Secrecy Rate: 14.118511624010468\n",
      "Iteration 193\n",
      "Secrecy Rate: 14.123960581572513\n",
      "Iteration 194\n",
      "Secrecy Rate: 14.129392706277407\n",
      "Iteration 195\n",
      "Secrecy Rate: 14.13478921197851\n",
      "Iteration 196\n",
      "Secrecy Rate: 14.140147549209019\n",
      "Iteration 197\n",
      "Secrecy Rate: 14.145467833859454\n",
      "Iteration 198\n",
      "Secrecy Rate: 14.15075040668173\n",
      "Iteration 199\n",
      "Secrecy Rate: 14.155995617538377\n",
      "Iteration 200\n",
      "Secrecy Rate: 14.161203812341757\n",
      "Iteration 201\n",
      "Secrecy Rate: 14.166375332604986\n",
      "Iteration 202\n",
      "Secrecy Rate: 14.171510515487789\n",
      "Iteration 203\n",
      "Secrecy Rate: 14.176609693868452\n",
      "Iteration 204\n",
      "Secrecy Rate: 14.181673196413774\n",
      "Iteration 205\n",
      "Secrecy Rate: 14.18670134764812\n",
      "Iteration 206\n",
      "Secrecy Rate: 14.191694468021929\n",
      "Iteration 207\n",
      "Secrecy Rate: 14.196652873979819\n",
      "Iteration 208\n",
      "Secrecy Rate: 14.20157687802829\n",
      "Iteration 209\n",
      "Secrecy Rate: 14.206466788803066\n",
      "Iteration 210\n",
      "Secrecy Rate: 14.211322911136078\n",
      "Iteration 211\n",
      "Secrecy Rate: 14.21614554612217\n",
      "Iteration 212\n",
      "Secrecy Rate: 14.22093499118547\n",
      "Iteration 213\n",
      "Secrecy Rate: 14.225691540145545\n",
      "Iteration 214\n",
      "Secrecy Rate: 14.230415483283283\n",
      "Iteration 215\n",
      "Secrecy Rate: 14.235107107406558\n",
      "Iteration 216\n",
      "Secrecy Rate: 14.239766695915705\n",
      "Iteration 217\n",
      "Secrecy Rate: 14.244394528868792\n",
      "Iteration 218\n",
      "Secrecy Rate: 14.248990883046718\n",
      "Iteration 219\n",
      "Secrecy Rate: 14.253556032018171\n",
      "Iteration 220\n",
      "Secrecy Rate: 14.258090246204413\n",
      "Iteration 221\n",
      "Secrecy Rate: 14.26259379294392\n",
      "Iteration 222\n",
      "Secrecy Rate: 14.267066936556887\n",
      "Iteration 223\n",
      "Secrecy Rate: 14.271509938409567\n",
      "Iteration 224\n",
      "Secrecy Rate: 14.275923056978492\n",
      "Iteration 225\n",
      "Secrecy Rate: 14.280306547914474\n",
      "Iteration 226\n",
      "Secrecy Rate: 14.284660664106513\n",
      "Iteration 227\n",
      "Secrecy Rate: 14.288985655745412\n",
      "Iteration 228\n",
      "Secrecy Rate: 14.29328177038725\n",
      "Iteration 229\n",
      "Secrecy Rate: 14.297549253016564\n",
      "Iteration 230\n",
      "Secrecy Rate: 14.30178834610926\n",
      "Iteration 231\n",
      "Secrecy Rate: 14.305999289695194\n",
      "Iteration 232\n",
      "Secrecy Rate: 14.31018232142035\n",
      "Iteration 233\n",
      "Secrecy Rate: 14.314337676608641\n",
      "Iteration 234\n",
      "Secrecy Rate: 14.318465588323173\n",
      "Iteration 235\n",
      "Secrecy Rate: 14.322566287426966\n",
      "Iteration 236\n",
      "Secrecy Rate: 14.326640002643027\n",
      "Iteration 237\n",
      "Secrecy Rate: 14.330686960613736\n",
      "Iteration 238\n",
      "Secrecy Rate: 14.33470738595939\n",
      "Iteration 239\n",
      "Secrecy Rate: 14.33870150133587\n",
      "Iteration 240\n",
      "Secrecy Rate: 14.342669527491292\n",
      "Iteration 241\n",
      "Secrecy Rate: 14.34661168332155\n",
      "Iteration 242\n",
      "Secrecy Rate: 14.350528185924654\n",
      "Iteration 243\n",
      "Secrecy Rate: 14.354419250653667\n",
      "Iteration 244\n",
      "Secrecy Rate: 14.358285091168234\n",
      "Iteration 245\n",
      "Secrecy Rate: 14.36212591948447\n",
      "Iteration 246\n",
      "Secrecy Rate: 14.365941946023133\n",
      "Iteration 247\n",
      "Secrecy Rate: 14.369733379655916\n",
      "Iteration 248\n",
      "Secrecy Rate: 14.373500427749756\n",
      "Iteration 249\n",
      "Secrecy Rate: 14.377243296208981\n",
      "Iteration 250\n",
      "Secrecy Rate: 14.380962189515179\n",
      "Iteration 251\n",
      "Secrecy Rate: 14.384657310764684\n",
      "Iteration 252\n",
      "Secrecy Rate: 14.388328861703483\n",
      "Iteration 253\n",
      "Secrecy Rate: 14.39197704275949\n",
      "Iteration 254\n",
      "Secrecy Rate: 14.395602053072016\n",
      "Iteration 255\n",
      "Secrecy Rate: 14.39920409051837\n",
      "Iteration 256\n",
      "Secrecy Rate: 14.402783351737439\n",
      "Iteration 257\n",
      "Secrecy Rate: 14.40634003215025\n",
      "Iteration 258\n",
      "Secrecy Rate: 14.409874325977329\n",
      "Iteration 259\n",
      "Secrecy Rate: 14.413386426252885\n",
      "Iteration 260\n",
      "Secrecy Rate: 14.416876524835796\n",
      "Iteration 261\n",
      "Secrecy Rate: 14.420344812417287\n",
      "Iteration 262\n",
      "Secrecy Rate: 14.423791478525402\n",
      "Iteration 263\n",
      "Secrecy Rate: 14.42721671152624\n",
      "Iteration 264\n",
      "Secrecy Rate: 14.430620698622047\n",
      "Iteration 265\n",
      "Secrecy Rate: 14.433974581719657\n",
      "Iteration 266\n",
      "Secrecy Rate: 14.436876289079757\n",
      "Iteration 267\n",
      "Secrecy Rate: 14.442033470437526\n",
      "Iteration 268\n",
      "Secrecy Rate: 14.44405208135221\n",
      "Iteration 269\n",
      "Secrecy Rate: 14.447170874375374\n",
      "Iteration 270\n",
      "Secrecy Rate: 14.45196529875767\n",
      "Iteration 271\n",
      "Secrecy Rate: 14.453813064944233\n",
      "Iteration 272\n",
      "Secrecy Rate: 14.45729709228972\n",
      "Iteration 273\n",
      "Secrecy Rate: 14.461715037058472\n",
      "Iteration 274\n",
      "Secrecy Rate: 14.463396198336024\n",
      "Iteration 275\n",
      "Secrecy Rate: 14.467254173004296\n",
      "Iteration 276\n",
      "Secrecy Rate: 14.471289069864572\n",
      "Iteration 277\n",
      "Secrecy Rate: 14.472806454660152\n",
      "Iteration 278\n",
      "Secrecy Rate: 14.477044565182394\n",
      "Iteration 279\n",
      "Secrecy Rate: 14.480691981580097\n",
      "Iteration 280\n",
      "Secrecy Rate: 14.482048849017193\n",
      "Iteration 281\n",
      "Secrecy Rate: 14.486670930014434\n",
      "Iteration 282\n",
      "Secrecy Rate: 14.48992826186451\n",
      "Iteration 283\n",
      "Secrecy Rate: 14.491128268653068\n",
      "Iteration 284\n",
      "Secrecy Rate: 14.496136095721315\n",
      "Iteration 285\n",
      "Secrecy Rate: 14.499002289202048\n",
      "Iteration 286\n",
      "Secrecy Rate: 14.500049452947609\n",
      "Iteration 287\n",
      "Secrecy Rate: 14.505443004581625\n",
      "Iteration 288\n",
      "Secrecy Rate: 14.507918314840621\n",
      "Iteration 289\n",
      "Secrecy Rate: 14.508816975678963\n",
      "Iteration 290\n",
      "Secrecy Rate: 14.514594668342333\n",
      "Iteration 291\n",
      "Secrecy Rate: 14.516680445790374\n",
      "Iteration 292\n",
      "Secrecy Rate: 14.517435230468987\n",
      "Iteration 293\n",
      "Secrecy Rate: 14.523594132270004\n",
      "Iteration 294\n",
      "Secrecy Rate: 14.525292628346477\n",
      "Iteration 295\n",
      "Secrecy Rate: 14.525908420643045\n",
      "Iteration 296\n",
      "Secrecy Rate: 14.532444447057177\n",
      "Iteration 297\n",
      "Secrecy Rate: 14.533758633383162\n",
      "Iteration 298\n",
      "Secrecy Rate: 14.534240554442068\n",
      "Iteration 299\n",
      "Secrecy Rate: 14.541148647394005\n",
      "Iteration 300\n",
      "Secrecy Rate: 14.542082044377533\n",
      "Iteration 301\n",
      "Secrecy Rate: 14.542435446155412\n",
      "Iteration 302\n",
      "Secrecy Rate: 14.549709735964065\n",
      "Iteration 303\n",
      "Secrecy Rate: 14.55026624879146\n",
      "Iteration 304\n",
      "Secrecy Rate: 14.55049672334945\n",
      "Iteration 305\n",
      "Secrecy Rate: 14.558130671740074\n",
      "Iteration 306\n",
      "Secrecy Rate: 14.558314433108627\n",
      "Iteration 307\n",
      "Secrecy Rate: 14.558427839998773\n",
      "Iteration 308\n",
      "Secrecy Rate: 14.566414361633216\n",
      "Converged\n",
      "Final Secrecy Rate GD: 12.490742841533333\n",
      "0.9027923993726619 1.6193862633956193 1.1975127554667209 1.7562042420858408 1.003652965041957 1.0372294748555384 1.0005810327234157 1.046814007995107 1.7584169851261717 2.782262660266156 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/42yb86gx3r173cz1j7dwvd5h0000gn/T/ipykernel_2557/4042312889.py:54: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(float(C_bk), end = \" \")\n"
     ]
    }
   ],
   "source": [
    "# Reseed first\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Gradient Descent Algorithm\n",
    "num_cycles = 500\n",
    "learning_rate = 0.01\n",
    "theta_GD = generate_random_theta()\n",
    "w_GD = generate_random_beamforming_vectors()\n",
    "theta_GD, w_GD = repair(theta_GD, w_GD)\n",
    "print(\"Initial Secrecy Rate GD:\", secrecy_rate_objective_function(theta_GD, w_GD))\n",
    "current_secrecy_rate = secrecy_rate_objective_function(theta_GD, w_GD)\n",
    "\n",
    "GD_results = []\n",
    "GD_results.append(current_secrecy_rate)\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    print(\"Iteration\", i)\n",
    "    print(\"Secrecy Rate:\", current_secrecy_rate)\n",
    "    w_new, theta_new = gradient_descent_update(w_GD, theta_GD, learning_rate, original_secrecy_rate=current_secrecy_rate)\n",
    "    #if check_validity(theta_new, w_new) == False:\n",
    "    #    print(\"Stop by invalidity\")\n",
    "    #    break\n",
    "    new_secrecy_rate = secrecy_rate_objective_function(theta_new, w_new)\n",
    "    if (new_secrecy_rate - current_secrecy_rate) < 1e-9:\n",
    "        print(\"Converged\")\n",
    "        break\n",
    "    w_GD = w_new\n",
    "    theta_GD = theta_new\n",
    "    GD_results.append(new_secrecy_rate)\n",
    "    current_secrecy_rate = new_secrecy_rate\n",
    "\n",
    "theta_GD, w_GD = repair(theta_GD, w_GD)\n",
    "#print(GD_results)\n",
    "print(\"Final Secrecy Rate GD:\", secrecy_rate_objective_function(theta_GD, w_GD))\n",
    "print_users_Cbk(theta_GD, w_GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Swarm Optimization (PSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSOParticle:\n",
    "  def __init__(self) -> None:\n",
    "    self.theta = generate_random_theta_angles(Nris)\n",
    "    self.w = generate_random_beamforming_vectors()\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "    self.best_theta = deepcopy(self.theta)\n",
    "    self.best_w = deepcopy(self.w)\n",
    "    self.best_secrecy_rate = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.best_theta), self.best_w)\n",
    "    self.current_secrecy_rate = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.theta), self.w)\n",
    "    self.velocity_theta = np.zeros((1, Nris))\n",
    "    self.velocity_w = [np.zeros((N, 1)) for i in range(number_of_users)]\n",
    "\n",
    "  \n",
    "  def update_velocity(self, inertia, c1, c2, global_best_theta, global_best_w):\n",
    "    r1 = np.random.rand()\n",
    "    r2 = np.random.rand()\n",
    "    self.velocity_theta = inertia * self.velocity_theta + c1 * r1 * (self.best_theta - self.theta) + c2 * r2 * (global_best_theta - self.theta)\n",
    "    self.velocity_w = [inertia * self.velocity_w[i] + c1 * r1 * (self.best_w[i] - self.w[i]) + c2 * r2 * (global_best_w[i] - self.w[i]) for i in range(number_of_users)]\n",
    "\n",
    "  def update_position(self):\n",
    "    self.theta = self.theta + self.velocity_theta\n",
    "    self.w = [self.w[i] + self.velocity_w[i] for i in range(number_of_users)]\n",
    "    self.w = normalise_beamforming_vectors(self.w)\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "\n",
    "  def update_velocity_theta(self, inertia, c1, c2, global_best_theta): #Used for PSO_GD\n",
    "    self.velocity_theta = inertia * self.velocity_theta + c1 * np.random.rand() * (self.best_theta - self.theta) + c2 * np.random.rand() * (global_best_theta - self.theta)\n",
    "  \n",
    "  def update_position_theta(self): #Used for PSO_GD\n",
    "    self.theta = self.theta + self.velocity_theta\n",
    "\n",
    "  def update_best(self):\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "    self.current_secrecy_rate = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.theta), self.w)\n",
    "    if self.current_secrecy_rate > self.best_secrecy_rate:\n",
    "      self.best_secrecy_rate = self.current_secrecy_rate\n",
    "      self.best_theta = deepcopy(self.theta)\n",
    "      self.best_w = deepcopy(self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_inertia(i: int, max_iter: int, inertia_max: float, inertia_min: float) -> float:\n",
    "  E_t = float((max_iter - i - 1)/max_iter)\n",
    "  inertia = inertia_min + (inertia_max - inertia_min) * (2 /(1 + (np.e ** (-5 * E_t))) - 1)\n",
    "  return inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_optimize_w_theta(max_iter: int, num_particles: int, w_min: float, w_max: float, c1: float, c2: float):\n",
    "  particles = [PSOParticle() for _ in range(num_particles)]\n",
    "  global_best_secrecy_rate = -np.inf\n",
    "  global_best_theta = np.zeros((1, Nris))\n",
    "  global_best_w = [np.zeros((N, 1)) for i in range(number_of_users)]\n",
    "\n",
    "  results_secrecy_rate = []\n",
    "\n",
    "  for particle in particles:\n",
    "    if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "      global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "      global_best_theta = deepcopy(particle.best_theta)\n",
    "      global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "  results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "\n",
    "  for iteration in range(max_iter):\n",
    "    print(\"iteration =\", iteration, global_best_secrecy_rate)\n",
    "    inertia = dynamic_inertia(iteration, max_iter, w_max, w_min)\n",
    "\n",
    "    for particle in particles:\n",
    "      particle.update_velocity(inertia, c1, c2, global_best_theta, global_best_w)\n",
    "      particle.update_position()\n",
    "      particle.update_best()\n",
    "\n",
    "      if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "        global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "        global_best_theta = deepcopy(particle.best_theta)\n",
    "        global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "    results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "   \n",
    "\n",
    "  return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0 8.698405811598713\n",
      "iteration = 1 11.244665756531374\n",
      "iteration = 2 11.35425809694848\n",
      "iteration = 3 11.35425809694848\n",
      "iteration = 4 11.35425809694848\n",
      "iteration = 5 11.35425809694848\n",
      "iteration = 6 11.35425809694848\n",
      "iteration = 7 11.371873717912791\n",
      "iteration = 8 11.623853963255415\n",
      "iteration = 9 11.867802435078858\n",
      "iteration = 10 11.867802435078858\n",
      "iteration = 11 12.082047471243875\n",
      "iteration = 12 12.082047471243875\n",
      "iteration = 13 12.082047471243875\n",
      "iteration = 14 12.082047471243875\n",
      "iteration = 15 12.082047471243875\n",
      "iteration = 16 12.082047471243875\n",
      "iteration = 17 12.44453417516366\n",
      "iteration = 18 12.44453417516366\n",
      "iteration = 19 12.44453417516366\n",
      "iteration = 20 12.44453417516366\n",
      "iteration = 21 12.44453417516366\n",
      "iteration = 22 12.44453417516366\n",
      "iteration = 23 12.44453417516366\n",
      "iteration = 24 12.44453417516366\n",
      "iteration = 25 12.44453417516366\n",
      "iteration = 26 12.44453417516366\n",
      "iteration = 27 12.44453417516366\n",
      "iteration = 28 12.44453417516366\n",
      "iteration = 29 12.44453417516366\n",
      "iteration = 30 12.44453417516366\n",
      "iteration = 31 12.44453417516366\n",
      "iteration = 32 12.44453417516366\n",
      "iteration = 33 12.44453417516366\n",
      "iteration = 34 12.44453417516366\n",
      "iteration = 35 12.44453417516366\n",
      "iteration = 36 12.44453417516366\n",
      "iteration = 37 12.44453417516366\n",
      "iteration = 38 12.44453417516366\n",
      "iteration = 39 12.44453417516366\n",
      "iteration = 40 12.44453417516366\n",
      "iteration = 41 12.44453417516366\n",
      "iteration = 42 12.506196241676278\n",
      "iteration = 43 12.506196241676278\n",
      "iteration = 44 12.506196241676278\n",
      "iteration = 45 12.506196241676278\n",
      "iteration = 46 12.506196241676278\n",
      "iteration = 47 12.506196241676278\n",
      "iteration = 48 12.506196241676278\n",
      "iteration = 49 12.506196241676278\n",
      "iteration = 50 12.506196241676278\n",
      "iteration = 51 12.600834964088797\n",
      "iteration = 52 12.600834964088797\n",
      "iteration = 53 12.600834964088797\n",
      "iteration = 54 12.600834964088797\n",
      "iteration = 55 12.600834964088797\n",
      "iteration = 56 12.600834964088797\n",
      "iteration = 57 12.600834964088797\n",
      "iteration = 58 12.600834964088797\n",
      "iteration = 59 12.600834964088797\n",
      "iteration = 60 12.600834964088797\n",
      "iteration = 61 12.600834964088797\n",
      "iteration = 62 12.600834964088797\n",
      "iteration = 63 12.602742300303454\n",
      "iteration = 64 12.602742300303454\n",
      "iteration = 65 12.602742300303454\n",
      "iteration = 66 12.659039023685727\n",
      "iteration = 67 12.659039023685727\n",
      "iteration = 68 12.659039023685727\n",
      "iteration = 69 12.659589308323426\n",
      "iteration = 70 12.659589308323426\n",
      "iteration = 71 12.659589308323426\n",
      "iteration = 72 12.659589308323426\n",
      "iteration = 73 12.659589308323426\n",
      "iteration = 74 12.659589308323426\n",
      "iteration = 75 12.659589308323426\n",
      "iteration = 76 12.720124097353352\n",
      "iteration = 77 12.720124097353352\n",
      "iteration = 78 12.79412040144944\n",
      "iteration = 79 12.79412040144944\n",
      "iteration = 80 12.79412040144944\n",
      "iteration = 81 12.79412040144944\n",
      "iteration = 82 12.79412040144944\n",
      "iteration = 83 12.79412040144944\n",
      "iteration = 84 12.79412040144944\n",
      "iteration = 85 13.014059993158032\n",
      "iteration = 86 13.014059993158032\n",
      "iteration = 87 13.014059993158032\n",
      "iteration = 88 13.014059993158032\n",
      "iteration = 89 13.014059993158032\n",
      "iteration = 90 13.014059993158032\n",
      "iteration = 91 13.014059993158032\n",
      "iteration = 92 13.014059993158032\n",
      "iteration = 93 13.014059993158032\n",
      "iteration = 94 13.014059993158032\n",
      "iteration = 95 13.014059993158032\n",
      "iteration = 96 13.014059993158032\n",
      "iteration = 97 13.014059993158032\n",
      "iteration = 98 13.014059993158032\n",
      "iteration = 99 13.014059993158032\n",
      "iteration = 100 13.014059993158032\n",
      "iteration = 101 13.027846996104444\n",
      "iteration = 102 13.027846996104444\n",
      "iteration = 103 13.027846996104444\n",
      "iteration = 104 13.027846996104444\n",
      "iteration = 105 13.027846996104444\n",
      "iteration = 106 13.027846996104444\n",
      "iteration = 107 13.027846996104444\n",
      "iteration = 108 13.027846996104444\n",
      "iteration = 109 13.027846996104444\n",
      "iteration = 110 13.027846996104444\n",
      "iteration = 111 13.027846996104444\n",
      "iteration = 112 13.027846996104444\n",
      "iteration = 113 13.027846996104444\n",
      "iteration = 114 13.053799887173728\n",
      "iteration = 115 13.053799887173728\n",
      "iteration = 116 13.053799887173728\n",
      "iteration = 117 13.053799887173728\n",
      "iteration = 118 13.053799887173728\n",
      "iteration = 119 13.053799887173728\n",
      "iteration = 120 13.053799887173728\n",
      "iteration = 121 13.053799887173728\n",
      "iteration = 122 13.053799887173728\n",
      "iteration = 123 13.141038661006757\n",
      "iteration = 124 13.157077794157948\n",
      "iteration = 125 13.157077794157948\n",
      "iteration = 126 13.157833998829195\n",
      "iteration = 127 13.157833998829195\n",
      "iteration = 128 13.16178277808165\n",
      "iteration = 129 13.16178277808165\n",
      "iteration = 130 13.256468387450266\n",
      "iteration = 131 13.256468387450266\n",
      "iteration = 132 13.256468387450266\n",
      "iteration = 133 13.256468387450266\n",
      "iteration = 134 13.256468387450266\n",
      "iteration = 135 13.256468387450266\n",
      "iteration = 136 13.256468387450266\n",
      "iteration = 137 13.256468387450266\n",
      "iteration = 138 13.256468387450266\n",
      "iteration = 139 13.256468387450266\n",
      "iteration = 140 13.256468387450266\n",
      "iteration = 141 13.256468387450266\n",
      "iteration = 142 13.267802384808487\n",
      "iteration = 143 13.267802384808487\n",
      "iteration = 144 13.26907854575608\n",
      "iteration = 145 13.276055668749036\n",
      "iteration = 146 13.276055668749036\n",
      "iteration = 147 13.276055668749036\n",
      "iteration = 148 13.276055668749036\n",
      "iteration = 149 13.276055668749036\n",
      "iteration = 150 13.276055668749036\n",
      "iteration = 151 13.314821308317779\n",
      "iteration = 152 13.314821308317779\n",
      "iteration = 153 13.314821308317779\n",
      "iteration = 154 13.314821308317779\n",
      "iteration = 155 13.314821308317779\n",
      "iteration = 156 13.351276132517103\n",
      "iteration = 157 13.351276132517103\n",
      "iteration = 158 13.35145614674985\n",
      "iteration = 159 13.35145614674985\n",
      "iteration = 160 13.35145614674985\n",
      "iteration = 161 13.35145614674985\n",
      "iteration = 162 13.35145614674985\n",
      "iteration = 163 13.35145614674985\n",
      "iteration = 164 13.35145614674985\n",
      "iteration = 165 13.35145614674985\n",
      "iteration = 166 13.35145614674985\n",
      "iteration = 167 13.35145614674985\n",
      "iteration = 168 13.37686722110616\n",
      "iteration = 169 13.37686722110616\n",
      "iteration = 170 13.37686722110616\n",
      "iteration = 171 13.377649327146786\n",
      "iteration = 172 13.377649327146786\n",
      "iteration = 173 13.377649327146786\n",
      "iteration = 174 13.377649327146786\n",
      "iteration = 175 13.377649327146786\n",
      "iteration = 176 13.377649327146786\n",
      "iteration = 177 13.39946927542316\n",
      "iteration = 178 13.39946927542316\n",
      "iteration = 179 13.39946927542316\n",
      "iteration = 180 13.39946927542316\n",
      "iteration = 181 13.39946927542316\n",
      "iteration = 182 13.39946927542316\n",
      "iteration = 183 13.39946927542316\n",
      "iteration = 184 13.403104893511628\n",
      "iteration = 185 13.403104893511628\n",
      "iteration = 186 13.43910600832989\n",
      "iteration = 187 13.43910600832989\n",
      "iteration = 188 13.43910600832989\n",
      "iteration = 189 13.43910600832989\n",
      "iteration = 190 13.43910600832989\n",
      "iteration = 191 13.43910600832989\n",
      "iteration = 192 13.43910600832989\n",
      "iteration = 193 13.442322688917145\n",
      "iteration = 194 13.442322688917145\n",
      "iteration = 195 13.442322688917145\n",
      "iteration = 196 13.442322688917145\n",
      "iteration = 197 13.442322688917145\n",
      "iteration = 198 13.442322688917145\n",
      "iteration = 199 13.442322688917145\n",
      "Initial Secrecy Rate PSO: 8.698405811598713\n",
      "[8.698405811598713, 11.244665756531374, 11.35425809694848, 11.35425809694848, 11.35425809694848, 11.35425809694848, 11.35425809694848, 11.371873717912791, 11.623853963255415, 11.867802435078858, 11.867802435078858, 12.082047471243875, 12.082047471243875, 12.082047471243875, 12.082047471243875, 12.082047471243875, 12.082047471243875, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.44453417516366, 12.506196241676278, 12.506196241676278, 12.506196241676278, 12.506196241676278, 12.506196241676278, 12.506196241676278, 12.506196241676278, 12.506196241676278, 12.506196241676278, 12.600834964088797, 12.600834964088797, 12.600834964088797, 12.600834964088797, 12.600834964088797, 12.600834964088797, 12.600834964088797, 12.600834964088797, 12.600834964088797, 12.600834964088797, 12.600834964088797, 12.600834964088797, 12.602742300303454, 12.602742300303454, 12.602742300303454, 12.659039023685727, 12.659039023685727, 12.659039023685727, 12.659589308323426, 12.659589308323426, 12.659589308323426, 12.659589308323426, 12.659589308323426, 12.659589308323426, 12.659589308323426, 12.720124097353352, 12.720124097353352, 12.79412040144944, 12.79412040144944, 12.79412040144944, 12.79412040144944, 12.79412040144944, 12.79412040144944, 12.79412040144944, 13.014059993158032, 13.014059993158032, 13.014059993158032, 13.014059993158032, 13.014059993158032, 13.014059993158032, 13.014059993158032, 13.014059993158032, 13.014059993158032, 13.014059993158032, 13.014059993158032, 13.014059993158032, 13.014059993158032, 13.014059993158032, 13.014059993158032, 13.014059993158032, 13.027846996104444, 13.027846996104444, 13.027846996104444, 13.027846996104444, 13.027846996104444, 13.027846996104444, 13.027846996104444, 13.027846996104444, 13.027846996104444, 13.027846996104444, 13.027846996104444, 13.027846996104444, 13.027846996104444, 13.053799887173728, 13.053799887173728, 13.053799887173728, 13.053799887173728, 13.053799887173728, 13.053799887173728, 13.053799887173728, 13.053799887173728, 13.053799887173728, 13.141038661006757, 13.157077794157948, 13.157077794157948, 13.157833998829195, 13.157833998829195, 13.16178277808165, 13.16178277808165, 13.256468387450266, 13.256468387450266, 13.256468387450266, 13.256468387450266, 13.256468387450266, 13.256468387450266, 13.256468387450266, 13.256468387450266, 13.256468387450266, 13.256468387450266, 13.256468387450266, 13.256468387450266, 13.267802384808487, 13.267802384808487, 13.26907854575608, 13.276055668749036, 13.276055668749036, 13.276055668749036, 13.276055668749036, 13.276055668749036, 13.276055668749036, 13.314821308317779, 13.314821308317779, 13.314821308317779, 13.314821308317779, 13.314821308317779, 13.351276132517103, 13.351276132517103, 13.35145614674985, 13.35145614674985, 13.35145614674985, 13.35145614674985, 13.35145614674985, 13.35145614674985, 13.35145614674985, 13.35145614674985, 13.35145614674985, 13.35145614674985, 13.37686722110616, 13.37686722110616, 13.37686722110616, 13.377649327146786, 13.377649327146786, 13.377649327146786, 13.377649327146786, 13.377649327146786, 13.377649327146786, 13.39946927542316, 13.39946927542316, 13.39946927542316, 13.39946927542316, 13.39946927542316, 13.39946927542316, 13.39946927542316, 13.403104893511628, 13.403104893511628, 13.43910600832989, 13.43910600832989, 13.43910600832989, 13.43910600832989, 13.43910600832989, 13.43910600832989, 13.43910600832989, 13.442322688917145, 13.442322688917145, 13.442322688917145, 13.442322688917145, 13.442322688917145, 13.442322688917145, 13.442322688917145, 13.442322688917145]\n",
      "Final Secrecy Rate PSO: 13.442322688917145\n"
     ]
    }
   ],
   "source": [
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# PSO Algorithm\n",
    "max_iter = 200\n",
    "num_particles = 100\n",
    "w_min = 0.5\n",
    "w_max = 0.9\n",
    "c1 = 1.5\n",
    "c2 = 1.5\n",
    "\n",
    "PSO_results = PSO_optimize_w_theta(max_iter, num_particles, w_min, w_max, c1, c2)\n",
    "print(\"Initial Secrecy Rate PSO:\", PSO_results[0])\n",
    "print(PSO_results)\n",
    "print(\"Final Secrecy Rate PSO:\", PSO_results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm (GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAIndividual:\n",
    "  def __init__(self, theta: np.ndarray[np.float64] = None, w: np.ndarray[np.complex128] = None) -> None:\n",
    "    if theta is None or w is None:\n",
    "      self.theta = generate_random_theta_angles(Nris)\n",
    "      self.w = generate_random_beamforming_vectors()\n",
    "    else:\n",
    "      self.theta = theta\n",
    "      self.w = w\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "    self.update_fitness()\n",
    "  \n",
    "  def update_fitness(self):\n",
    "    self.fitness = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.theta), self.w)\n",
    "\n",
    "\n",
    "class GAPopulation:\n",
    "  def __init__(self, population_size: int, crossover_rate: float = 0.85, mutation_rate: float = 0.3) -> None:\n",
    "    self.population_size = population_size\n",
    "    self.individuals = [GAIndividual() for _ in range(population_size)]\n",
    "    self.crossover_rate = crossover_rate\n",
    "    self.mutation_rate = mutation_rate\n",
    "\n",
    "  def sort_population(self):\n",
    "    self.individuals.sort(key=lambda x: x.fitness, reverse=True)\n",
    "\n",
    "  def filter_population(self):\n",
    "    self.sort_population()\n",
    "    self.individuals = self.individuals[:self.population_size]\n",
    "\n",
    "  def add_individual(self, individual: GAIndividual):\n",
    "    self.individuals.append(individual)\n",
    "\n",
    "  def select_parents(self) -> tuple[GAIndividual, GAIndividual]:\n",
    "    parents = np.random.choice(self.individuals, 2, replace=False)\n",
    "    return parents[0], parents[1]\n",
    "  \n",
    "  def crossover(self, parent1: GAIndividual, parent2: GAIndividual) -> GAIndividual:\n",
    "    theta1, w1 = parent1.theta, parent1.w\n",
    "    theta2, w2 = parent2.theta, parent2.w\n",
    "    theta_child = (theta1 + theta2) / 2\n",
    "    w_child = [(w1[i] + w2[i]) / 2 for i in range(number_of_users)]\n",
    "    w_child = normalise_beamforming_vectors(w_child)\n",
    "    theta_child, w_child = repair(theta_child, w_child)\n",
    "    return GAIndividual(theta_child, w_child)\n",
    "  \n",
    "  def mutate(self, individual: GAIndividual) -> GAIndividual:\n",
    "    if np.random.rand() < self.mutation_rate:\n",
    "      mutation_index = np.random.randint(0, Nris)\n",
    "      individual.theta[0, mutation_index] = np.random.uniform(-np.pi, np.pi)\n",
    "      mutation_index = np.random.randint(len(individual.w))\n",
    "      individual.w[mutation_index] = generate_random_beamforming_vector()\n",
    "      individual.w = normalise_beamforming_vectors(individual.w)\n",
    "      individual.theta, individual.w = repair(individual.theta, individual.w)\n",
    "      individual.update_fitness()\n",
    "\n",
    "    return individual\n",
    "  \n",
    "def GA_optimize_w_theta(population_size: int, max_iter: int, crossover_rate: float = 0.85, mutation_rate: float = 0.85):\n",
    "  population = GAPopulation(population_size, crossover_rate, mutation_rate)\n",
    "  population.sort_population()\n",
    "  results_secrecy_rate = []\n",
    "  results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "\n",
    "  for iteration in range(max_iter):\n",
    "    print(\"iteration =\", iteration, population.individuals[0].fitness)\n",
    "    # Crossover and mutate\n",
    "    for _ in range(population_size):\n",
    "      if np.random.rand() < population.crossover_rate:\n",
    "        parent1, parent2 = population.select_parents()\n",
    "        child = population.crossover(parent1, parent2)\n",
    "        population.mutate(child)\n",
    "        population.add_individual(child)\n",
    "    # Filter\n",
    "    population.filter_population()\n",
    "    \n",
    "    results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "    print_users_Cbk(theta_angles_to_theta_vector(population.individuals[0].theta), population.individuals[0].w)\n",
    "  return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0 8.698405811598713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/42yb86gx3r173cz1j7dwvd5h0000gn/T/ipykernel_2557/4042312889.py:54: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(float(C_bk), end = \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9338980339018439 1.4633767390281989 1.0036758866659756 0.9701665486246487 0.8961831765723899 1.454553184564493 0.9740798262019347 0.9681595288111624 1.0184423477866411 0.9318058720031445 \n",
      "iteration = 1 10.24197660886312\n",
      "1.0809044559333987 1.2485259033943163 1.2478618802489607 1.016978198770041 0.8984373189114733 0.8337183374095265 0.9394381876355272 0.8992393132840962 1.7886753201490475 0.9301835971446356 \n",
      "iteration = 2 10.584381652068682\n",
      "0.8145675158183997 0.9304970603571409 1.625671368449054 0.9109260776376308 1.007136658363999 1.890896513960459 0.9512907158464263 1.002739687533142 0.8336645326268907 1.0787991063957205 \n",
      "iteration = 3 10.816506909188888\n",
      "0.8339551517361546 0.8488457372233867 1.1221381960877193 1.0178241877956287 1.3622534598015117 1.5668894713356805 0.8867747954502072 1.5653484379144034 1.0145672585828818 1.1429580419942384 \n",
      "iteration = 4 11.138319480378708\n",
      "0.8205290653062892 0.9178902864566946 1.6829101455856659 0.8650352027477135 1.0236605059347956 1.9158079132404628 1.039272755362609 1.2561652086083515 0.9871642420608717 0.9653175395907053 \n",
      "iteration = 5 11.338505444329597\n",
      "0.8747616203159668 1.0190017239943858 1.0300683785250926 1.0210723125182277 1.5495914500176022 2.1414314532324954 0.9335725941594276 1.2357023527209554 0.9230471133812495 0.9719450582575709 \n",
      "iteration = 6 11.539022547932266\n",
      "0.8747616203159668 1.0190017239943858 1.0300683785250926 1.0210723125182277 1.5495914500176022 2.1414314532324954 0.9335725941594276 1.2357023527209554 0.9230471133812495 0.9719450582575709 \n",
      "iteration = 7 11.539022547932266\n",
      "0.8747616203159668 1.0190017239943858 1.0300683785250926 1.0210723125182277 1.5495914500176022 2.1414314532324954 0.9335725941594276 1.2357023527209554 0.9230471133812495 0.9719450582575709 \n",
      "iteration = 8 11.539022547932266\n",
      "0.8747616203159668 1.0190017239943858 1.0300683785250926 1.0210723125182277 1.5495914500176022 2.1414314532324954 0.9335725941594276 1.2357023527209554 0.9230471133812495 0.9719450582575709 \n",
      "iteration = 9 11.539022547932266\n",
      "0.9486323626593274 1.3239479493207615 1.200772496261799 0.8213225559652725 1.088152339788149 2.0653268330502783 1.114289360612859 0.9126764352744597 1.1298147428940006 1.1316701384859575 \n",
      "iteration = 10 11.633094919177644\n",
      "0.9486323626593274 1.3239479493207615 1.200772496261799 0.8213225559652725 1.088152339788149 2.0653268330502783 1.114289360612859 0.9126764352744597 1.1298147428940006 1.1316701384859575 \n",
      "iteration = 11 11.633094919177644\n",
      "0.8284410726677123 1.0144861014048179 1.6386818741167026 0.9266655325869319 1.202741147664501 2.10739250034004 0.9306449999305783 1.1489699105909905 1.0286684526009056 1.0606179418969781 \n",
      "iteration = 12 11.774052815468863\n",
      "0.8284410726677123 1.0144861014048179 1.6386818741167026 0.9266655325869319 1.202741147664501 2.10739250034004 0.9306449999305783 1.1489699105909905 1.0286684526009056 1.0606179418969781 \n",
      "iteration = 13 11.774052815468863\n",
      "0.8284410726677123 1.0144861014048179 1.6386818741167026 0.9266655325869319 1.202741147664501 2.10739250034004 0.9306449999305783 1.1489699105909905 1.0286684526009056 1.0606179418969781 \n",
      "iteration = 14 11.774052815468863\n",
      "0.8284410726677123 1.0144861014048179 1.6386818741167026 0.9266655325869319 1.202741147664501 2.10739250034004 0.9306449999305783 1.1489699105909905 1.0286684526009056 1.0606179418969781 \n",
      "iteration = 15 11.774052815468863\n",
      "0.8284410726677123 1.0144861014048179 1.6386818741167026 0.9266655325869319 1.202741147664501 2.10739250034004 0.9306449999305783 1.1489699105909905 1.0286684526009056 1.0606179418969781 \n",
      "iteration = 16 11.774052815468863\n",
      "0.8708406630496108 1.1107900264646948 1.389439880421402 0.947388870632995 1.185399740876837 2.2356194880825626 1.0000049486601679 1.0708500192359145 1.0590569327776933 1.0928215422169334 \n",
      "iteration = 17 11.849998127739932\n",
      "1.011038196014519 0.8089856342075546 1.5174126070544285 0.9033097440132244 1.534402193356975 2.3487471169037355 0.9012186528126723 0.9822212791602547 0.9950132444580723 1.024581617036004 \n",
      "iteration = 18 11.894948353618828\n",
      "1.011038196014519 0.8089856342075546 1.5174126070544285 0.9033097440132244 1.534402193356975 2.3487471169037355 0.9012186528126723 0.9822212791602547 0.9950132444580723 1.024581617036004 \n",
      "iteration = 19 11.894948353618828\n",
      "0.9457168485185055 0.9130595419293344 1.524491791366398 0.9311558364548858 1.3867307335509542 2.3732732304439073 0.9332210146526971 1.0874681743737884 0.9558356421879362 1.0118730330622392 \n",
      "iteration = 20 11.944937995038137\n",
      "0.9458871768827031 0.8673275639211687 1.6516317446806874 0.891302537003106 1.417014175514233 2.4173998000176526 0.9615485736805862 1.041600874894415 0.8955078992663433 0.9998683811429585 \n",
      "iteration = 21 11.973390283908248\n",
      "0.9458871768827031 0.8673275639211687 1.6516317446806874 0.891302537003106 1.417014175514233 2.4173998000176526 0.9615485736805862 1.041600874894415 0.8955078992663433 0.9998683811429585 \n",
      "iteration = 22 11.973390283908248\n",
      "0.9436477343976595 0.9205293523921184 1.5086077038156882 0.8937046323093526 1.3697764928029177 2.46845665431024 0.9982580028514512 1.0808976499157594 0.9178157914816323 0.9986579226180935 \n",
      "iteration = 23 11.989029811870116\n",
      "0.9436477343976595 0.9205293523921184 1.5086077038156882 0.8937046323093526 1.3697764928029177 2.46845665431024 0.9982580028514512 1.0808976499157594 0.9178157914816323 0.9986579226180935 \n",
      "iteration = 24 11.989029811870116\n",
      "0.9436477343976595 0.9205293523921184 1.5086077038156882 0.8937046323093526 1.3697764928029177 2.46845665431024 0.9982580028514512 1.0808976499157594 0.9178157914816323 0.9986579226180935 \n",
      "iteration = 25 11.989029811870116\n",
      "0.9436477343976595 0.9205293523921184 1.5086077038156882 0.8937046323093526 1.3697764928029177 2.46845665431024 0.9982580028514512 1.0808976499157594 0.9178157914816323 0.9986579226180935 \n",
      "iteration = 26 11.989029811870116\n",
      "0.9236814560242838 0.9071681680163604 1.4303935439299837 0.9989325623845973 1.3957667724645375 2.7537581604147348 0.9003189164056115 1.0405744262144552 1.000635410717496 1.0488325459914725 \n",
      "iteration = 27 12.285444459112885\n",
      "0.9236814560242838 0.9071681680163604 1.4303935439299837 0.9989325623845973 1.3957667724645375 2.7537581604147348 0.9003189164056115 1.0405744262144552 1.000635410717496 1.0488325459914725 \n",
      "iteration = 28 12.285444459112885\n",
      "1.0280062664105234 0.9589645901652932 1.6023929836954458 0.8438631690292328 1.4929098600843158 2.409936793761182 1.0955634402213281 1.0201798297302136 0.8230657807563468 1.1389970504781308 \n",
      "iteration = 29 12.295943051594392\n",
      "1.0280062664105234 0.9589645901652932 1.6023929836954458 0.8438631690292328 1.4929098600843158 2.409936793761182 1.0955634402213281 1.0201798297302136 0.8230657807563468 1.1389970504781308 \n",
      "iteration = 30 12.295943051594392\n",
      "1.0280062664105234 0.9589645901652932 1.6023929836954458 0.8438631690292328 1.4929098600843158 2.409936793761182 1.0955634402213281 1.0201798297302136 0.8230657807563468 1.1389970504781308 \n",
      "iteration = 31 12.295943051594392\n",
      "0.9441006210078884 0.9618073003559888 1.4202653917882022 1.039231636434622 1.3608585827346122 2.772351986936635 1.0272432333858819 1.0268156349165438 0.9335121576214237 0.9826713594290928 \n",
      "iteration = 32 12.33689706026468\n",
      "0.9410634622177109 0.952814497416552 1.4976257719013724 0.9181737063517722 1.384042618462831 2.824719928731525 0.9747402174208627 1.0400656758698827 0.9726571139292253 1.0487438421943813 \n",
      "iteration = 33 12.438875333776199\n",
      "0.9410634622177109 0.952814497416552 1.4976257719013724 0.9181737063517722 1.384042618462831 2.824719928731525 0.9747402174208627 1.0400656758698827 0.9726571139292253 1.0487438421943813 \n",
      "iteration = 34 12.438875333776199\n",
      "0.9410634622177109 0.952814497416552 1.4976257719013724 0.9181737063517722 1.384042618462831 2.824719928731525 0.9747402174208627 1.0400656758698827 0.9726571139292253 1.0487438421943813 \n",
      "iteration = 35 12.438875333776199\n",
      "0.9410634622177109 0.952814497416552 1.4976257719013724 0.9181737063517722 1.384042618462831 2.824719928731525 0.9747402174208627 1.0400656758698827 0.9726571139292253 1.0487438421943813 \n",
      "iteration = 36 12.438875333776199\n",
      "0.9410634622177109 0.952814497416552 1.4976257719013724 0.9181737063517722 1.384042618462831 2.824719928731525 0.9747402174208627 1.0400656758698827 0.9726571139292253 1.0487438421943813 \n",
      "iteration = 37 12.438875333776199\n",
      "0.9410634622177109 0.952814497416552 1.4976257719013724 0.9181737063517722 1.384042618462831 2.824719928731525 0.9747402174208627 1.0400656758698827 0.9726571139292253 1.0487438421943813 \n",
      "iteration = 38 12.438875333776199\n",
      "0.9410634622177109 0.952814497416552 1.4976257719013724 0.9181737063517722 1.384042618462831 2.824719928731525 0.9747402174208627 1.0400656758698827 0.9726571139292253 1.0487438421943813 \n",
      "iteration = 39 12.438875333776199\n",
      "0.9410634622177109 0.952814497416552 1.4976257719013724 0.9181737063517722 1.384042618462831 2.824719928731525 0.9747402174208627 1.0400656758698827 0.9726571139292253 1.0487438421943813 \n",
      "iteration = 40 12.438875333776199\n",
      "0.9410634622177109 0.952814497416552 1.4976257719013724 0.9181737063517722 1.384042618462831 2.824719928731525 0.9747402174208627 1.0400656758698827 0.9726571139292253 1.0487438421943813 \n",
      "iteration = 41 12.438875333776199\n",
      "0.9410634622177109 0.952814497416552 1.4976257719013724 0.9181737063517722 1.384042618462831 2.824719928731525 0.9747402174208627 1.0400656758698827 0.9726571139292253 1.0487438421943813 \n",
      "iteration = 42 12.438875333776199\n",
      "0.9410634622177109 0.952814497416552 1.4976257719013724 0.9181737063517722 1.384042618462831 2.824719928731525 0.9747402174208627 1.0400656758698827 0.9726571139292253 1.0487438421943813 \n",
      "iteration = 43 12.438875333776199\n",
      "0.9410634622177109 0.952814497416552 1.4976257719013724 0.9181737063517722 1.384042618462831 2.824719928731525 0.9747402174208627 1.0400656758698827 0.9726571139292253 1.0487438421943813 \n",
      "iteration = 44 12.438875333776199\n",
      "0.8561562463877471 1.0410752940050914 1.5946640137425574 0.8963659433673027 1.3327154805515447 2.697090610489127 0.9824789356568729 1.156691080889612 0.9952204704727291 1.0361362891008317 \n",
      "iteration = 45 12.47516988876878\n",
      "0.8417608389396065 1.014289101027663 1.6736321823403901 0.9511040123923648 1.3856362345508708 2.632365377943613 1.006755009294998 1.1908307662898052 0.924895132149802 1.043026119003931 \n",
      "iteration = 46 12.545978347231008\n",
      "0.8417608389396065 1.014289101027663 1.6736321823403901 0.9511040123923648 1.3856362345508708 2.632365377943613 1.006755009294998 1.1908307662898052 0.924895132149802 1.043026119003931 \n",
      "iteration = 47 12.545978347231008\n",
      "0.8417608389396065 1.014289101027663 1.6736321823403901 0.9511040123923648 1.3856362345508708 2.632365377943613 1.006755009294998 1.1908307662898052 0.924895132149802 1.043026119003931 \n",
      "iteration = 48 12.545978347231008\n",
      "0.8417608389396065 1.014289101027663 1.6736321823403901 0.9511040123923648 1.3856362345508708 2.632365377943613 1.006755009294998 1.1908307662898052 0.924895132149802 1.043026119003931 \n",
      "iteration = 49 12.545978347231008\n",
      "0.8417608389396065 1.014289101027663 1.6736321823403901 0.9511040123923648 1.3856362345508708 2.632365377943613 1.006755009294998 1.1908307662898052 0.924895132149802 1.043026119003931 \n",
      "iteration = 50 12.545978347231008\n",
      "0.8417608389396065 1.014289101027663 1.6736321823403901 0.9511040123923648 1.3856362345508708 2.632365377943613 1.006755009294998 1.1908307662898052 0.924895132149802 1.043026119003931 \n",
      "iteration = 51 12.545978347231008\n",
      "0.872395376217034 1.0175923391868784 1.6218196816592267 0.9520570095648533 1.3688474398719361 2.712863389231898 0.9500395788922487 1.1986957800413471 0.9332375889488795 1.0589240687610448 \n",
      "iteration = 52 12.571274591059773\n",
      "0.872395376217034 1.0175923391868784 1.6218196816592267 0.9520570095648533 1.3688474398719361 2.712863389231898 0.9500395788922487 1.1986957800413471 0.9332375889488795 1.0589240687610448 \n",
      "iteration = 53 12.571274591059773\n",
      "0.872395376217034 1.0175923391868784 1.6218196816592267 0.9520570095648533 1.3688474398719361 2.712863389231898 0.9500395788922487 1.1986957800413471 0.9332375889488795 1.0589240687610448 \n",
      "iteration = 54 12.571274591059773\n",
      "0.872395376217034 1.0175923391868784 1.6218196816592267 0.9520570095648533 1.3688474398719361 2.712863389231898 0.9500395788922487 1.1986957800413471 0.9332375889488795 1.0589240687610448 \n",
      "iteration = 55 12.571274591059773\n",
      "0.8808095540996447 1.0151537870824963 1.6096334413283766 0.958356719853803 1.3654437826073467 2.740721098124329 0.9315048766170516 1.2071578356658745 0.9178105378441459 1.062717816796589 \n",
      "iteration = 56 12.574790485505046\n",
      "0.8653802064271382 1.031408232256441 1.6330887707872772 0.9709041729907262 1.3579147045020075 2.704161818442509 0.940388406931096 1.2056086212472534 0.939984290952106 1.0585617506299159 \n",
      "iteration = 57 12.591918284221801\n",
      "0.8653802064271382 1.031408232256441 1.6330887707872772 0.9709041729907262 1.3579147045020075 2.704161818442509 0.940388406931096 1.2056086212472534 0.939984290952106 1.0585617506299159 \n",
      "iteration = 58 12.591918284221801\n",
      "0.8653802064271382 1.031408232256441 1.6330887707872772 0.9709041729907262 1.3579147045020075 2.704161818442509 0.940388406931096 1.2056086212472534 0.939984290952106 1.0585617506299159 \n",
      "iteration = 59 12.591918284221801\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 60 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 61 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 62 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 63 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 64 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 65 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 66 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 67 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 68 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 69 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 70 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 71 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 72 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 73 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 74 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 75 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 76 12.77985443096356\n",
      "0.9108636099553541 0.9884975986227358 1.6355340619505654 1.1272708209478022 1.425857384626089 2.671594286119026 0.8120436075361943 1.1832314053657076 1.1292146901659408 1.0139948130151224 \n",
      "iteration = 77 12.77985443096356\n",
      "0.9062955977966547 0.9951142512453316 1.6318634634082425 1.1050304890954281 1.4189537886087433 2.708440111037661 0.8114843443378247 1.2014283749149917 1.0945089295834094 1.0256817533142384 \n",
      "iteration = 78 12.781862151096895\n",
      "0.9062955977966547 0.9951142512453316 1.6318634634082425 1.1050304890954281 1.4189537886087433 2.708440111037661 0.8114843443378247 1.2014283749149917 1.0945089295834094 1.0256817533142384 \n",
      "iteration = 79 12.781862151096895\n",
      "0.9112980506518616 1.0129416803465359 1.6386363863930875 1.128157979729377 1.426169541417762 2.671791074317439 0.8213192440951457 1.2124641220979604 1.048124953552413 1.0380896881775319 \n",
      "iteration = 80 12.790557049519759\n",
      "0.9112980506518616 1.0129416803465359 1.6386363863930875 1.128157979729377 1.426169541417762 2.671791074317439 0.8213192440951457 1.2124641220979604 1.048124953552413 1.0380896881775319 \n",
      "iteration = 81 12.790557049519759\n",
      "0.9112980506518616 1.0129416803465359 1.6386363863930875 1.128157979729377 1.426169541417762 2.671791074317439 0.8213192440951457 1.2124641220979604 1.048124953552413 1.0380896881775319 \n",
      "iteration = 82 12.790557049519759\n",
      "0.9112980506518616 1.0129416803465359 1.6386363863930875 1.128157979729377 1.426169541417762 2.671791074317439 0.8213192440951457 1.2124641220979604 1.048124953552413 1.0380896881775319 \n",
      "iteration = 83 12.790557049519759\n",
      "0.9114481385641268 1.0083878802685848 1.6377402282247844 1.126216036789566 1.4261341009015083 2.6798528316886863 0.813507859934683 1.207333747576705 1.069256544838817 1.0335576574945249 \n",
      "iteration = 84 12.795668662958965\n",
      "0.9114481385641268 1.0083878802685848 1.6377402282247844 1.126216036789566 1.4261341009015083 2.6798528316886863 0.813507859934683 1.207333747576705 1.069256544838817 1.0335576574945249 \n",
      "iteration = 85 12.795668662958965\n",
      "0.9114481385641268 1.0083878802685848 1.6377402282247844 1.126216036789566 1.4261341009015083 2.6798528316886863 0.813507859934683 1.207333747576705 1.069256544838817 1.0335576574945249 \n",
      "iteration = 86 12.795668662958965\n",
      "0.9114481385641268 1.0083878802685848 1.6377402282247844 1.126216036789566 1.4261341009015083 2.6798528316886863 0.813507859934683 1.207333747576705 1.069256544838817 1.0335576574945249 \n",
      "iteration = 87 12.795668662958965\n",
      "0.9114481385641268 1.0083878802685848 1.6377402282247844 1.126216036789566 1.4261341009015083 2.6798528316886863 0.813507859934683 1.207333747576705 1.069256544838817 1.0335576574945249 \n",
      "iteration = 88 12.795668662958965\n",
      "0.9114481385641268 1.0083878802685848 1.6377402282247844 1.126216036789566 1.4261341009015083 2.6798528316886863 0.813507859934683 1.207333747576705 1.069256544838817 1.0335576574945249 \n",
      "iteration = 89 12.795668662958965\n",
      "0.8380218520904623 1.162602188973918 1.6305530534911405 1.1104900725434415 1.4477041584810322 2.6709738727108436 0.8483632274724805 1.286397944596986 1.0528452197399107 0.9808603779027544 \n",
      "iteration = 90 12.909171122572102\n",
      "0.8380218520904623 1.162602188973918 1.6305530534911405 1.1104900725434415 1.4477041584810322 2.6709738727108436 0.8483632274724805 1.286397944596986 1.0528452197399107 0.9808603779027544 \n",
      "iteration = 91 12.909171122572102\n",
      "0.8380218520904623 1.162602188973918 1.6305530534911405 1.1104900725434415 1.4477041584810322 2.6709738727108436 0.8483632274724805 1.286397944596986 1.0528452197399107 0.9808603779027544 \n",
      "iteration = 92 12.909171122572102\n",
      "0.8380218520904623 1.162602188973918 1.6305530534911405 1.1104900725434415 1.4477041584810322 2.6709738727108436 0.8483632274724805 1.286397944596986 1.0528452197399107 0.9808603779027544 \n",
      "iteration = 93 12.909171122572102\n",
      "0.8380218520904623 1.162602188973918 1.6305530534911405 1.1104900725434415 1.4477041584810322 2.6709738727108436 0.8483632274724805 1.286397944596986 1.0528452197399107 0.9808603779027544 \n",
      "iteration = 94 12.909171122572102\n",
      "0.8380218520904623 1.162602188973918 1.6305530534911405 1.1104900725434415 1.4477041584810322 2.6709738727108436 0.8483632274724805 1.286397944596986 1.0528452197399107 0.9808603779027544 \n",
      "iteration = 95 12.909171122572102\n",
      "0.832383529953214 1.1258071565278898 1.659426895469708 1.1154765065599255 1.4470473793764835 2.6798684846019722 0.8412388000841632 1.2660733745203294 1.0601823945297875 1.0073625091911438 \n",
      "iteration = 96 12.917092921520217\n",
      "0.832383529953214 1.1258071565278898 1.659426895469708 1.1154765065599255 1.4470473793764835 2.6798684846019722 0.8412388000841632 1.2660733745203294 1.0601823945297875 1.0073625091911438 \n",
      "iteration = 97 12.917092921520217\n",
      "0.8823220064230691 0.9928287634036265 1.5041539935188986 1.2239881226394933 1.4299726287949537 2.990938497630623 0.8973093505095913 1.146402217995153 1.0559622587623556 0.979130618540559 \n",
      "iteration = 98 12.982100084827499\n",
      "0.8709493795686912 1.0363175424743414 1.5977450268413491 1.1741614344498463 1.4667468096712515 3.0157021985572094 0.8671385428048337 1.2221339406754705 1.062535794617965 1.0068004145525404 \n",
      "iteration = 99 13.20205578741819\n",
      "0.8709493795686912 1.0363175424743414 1.5977450268413491 1.1741614344498463 1.4667468096712515 3.0157021985572094 0.8671385428048337 1.2221339406754705 1.062535794617965 1.0068004145525404 \n",
      "iteration = 100 13.20205578741819\n",
      "0.8709493795686912 1.0363175424743414 1.5977450268413491 1.1741614344498463 1.4667468096712515 3.0157021985572094 0.8671385428048337 1.2221339406754705 1.062535794617965 1.0068004145525404 \n",
      "iteration = 101 13.20205578741819\n",
      "0.8727800758999958 1.0309573509661565 1.5877720168208378 1.1845008661448573 1.4665815049349802 3.032751801735615 0.8698065475655476 1.2151219548877716 1.063043178800244 1.0037236825197362 \n",
      "iteration = 102 13.208599417006528\n",
      "0.862386569929798 1.0480624955741396 1.6006494990088953 1.1770632206362808 1.4702177464759412 3.013081582862571 0.8684792104446242 1.2276123669333445 1.0633413447654898 1.0042108309139055 \n",
      "iteration = 103 13.216852912214243\n",
      "0.862386569929798 1.0480624955741396 1.6006494990088953 1.1770632206362808 1.4702177464759412 3.013081582862571 0.8684792104446242 1.2276123669333445 1.0633413447654898 1.0042108309139055 \n",
      "iteration = 104 13.216852912214243\n",
      "0.8615691917762526 1.0417868117756985 1.6108848710276082 1.291651147201932 1.4616781490429316 3.073979522471566 0.8653208249973791 1.1896577308606828 0.9745093979027104 1.0171326572762884 \n",
      "iteration = 105 13.274297507857831\n",
      "0.8615691917762526 1.0417868117756985 1.6108848710276082 1.291651147201932 1.4616781490429316 3.073979522471566 0.8653208249973791 1.1896577308606828 0.9745093979027104 1.0171326572762884 \n",
      "iteration = 106 13.274297507857831\n",
      "0.8615691917762526 1.0417868117756985 1.6108848710276082 1.291651147201932 1.4616781490429316 3.073979522471566 0.8653208249973791 1.1896577308606828 0.9745093979027104 1.0171326572762884 \n",
      "iteration = 107 13.274297507857831\n",
      "0.8615691917762526 1.0417868117756985 1.6108848710276082 1.291651147201932 1.4616781490429316 3.073979522471566 0.8653208249973791 1.1896577308606828 0.9745093979027104 1.0171326572762884 \n",
      "iteration = 108 13.274297507857831\n",
      "0.8615691917762526 1.0417868117756985 1.6108848710276082 1.291651147201932 1.4616781490429316 3.073979522471566 0.8653208249973791 1.1896577308606828 0.9745093979027104 1.0171326572762884 \n",
      "iteration = 109 13.274297507857831\n",
      "0.8615691917762526 1.0417868117756985 1.6108848710276082 1.291651147201932 1.4616781490429316 3.073979522471566 0.8653208249973791 1.1896577308606828 0.9745093979027104 1.0171326572762884 \n",
      "iteration = 110 13.274297507857831\n",
      "0.8593888727701742 1.0554331853003012 1.6237510365811716 1.2677386488826834 1.4660940620475833 3.060189415969546 0.8585867440951186 1.215230156177706 0.9823389847496476 1.018276018887931 \n",
      "iteration = 111 13.29314966897838\n",
      "0.8593888727701742 1.0554331853003012 1.6237510365811716 1.2677386488826834 1.4660940620475833 3.060189415969546 0.8585867440951186 1.215230156177706 0.9823389847496476 1.018276018887931 \n",
      "iteration = 112 13.29314966897838\n",
      "0.8593888727701742 1.0554331853003012 1.6237510365811716 1.2677386488826834 1.4660940620475833 3.060189415969546 0.8585867440951186 1.215230156177706 0.9823389847496476 1.018276018887931 \n",
      "iteration = 113 13.29314966897838\n",
      "0.8762737684096057 1.0371660229190476 1.6075382184655354 1.1816425088589317 1.465241398130891 3.1346550581524872 0.8488976133664713 1.305744569856657 1.0101827468415987 1.031269638411447 \n",
      "iteration = 114 13.38234662764092\n",
      "0.8782148208965346 0.9626234309838559 1.6174065139956733 1.1973398713134489 1.5069154631086306 3.1300304812727107 0.8546949251070759 1.3067502271068034 1.0180245647914075 1.0273632884950776 \n",
      "iteration = 115 13.384530890071431\n",
      "0.8782148208965346 0.9626234309838559 1.6174065139956733 1.1973398713134489 1.5069154631086306 3.1300304812727107 0.8546949251070759 1.3067502271068034 1.0180245647914075 1.0273632884950776 \n",
      "iteration = 116 13.384530890071431\n",
      "0.8782148208965346 0.9626234309838559 1.6174065139956733 1.1973398713134489 1.5069154631086306 3.1300304812727107 0.8546949251070759 1.3067502271068034 1.0180245647914075 1.0273632884950776 \n",
      "iteration = 117 13.384530890071431\n",
      "0.8782148208965346 0.9626234309838559 1.6174065139956733 1.1973398713134489 1.5069154631086306 3.1300304812727107 0.8546949251070759 1.3067502271068034 1.0180245647914075 1.0273632884950776 \n",
      "iteration = 118 13.384530890071431\n",
      "0.8793718842738233 0.9603871334644465 1.6169030718864394 1.2117332893242294 1.5062166715938259 3.147824264714786 0.8547134545152908 1.3016173845046444 1.0068534274757763 1.028709581166263 \n",
      "iteration = 119 13.400040941609408\n",
      "0.879336944194729 0.958513526977004 1.6135985513058022 1.221340593611534 1.5063917818840755 3.1681579491597076 0.8568665270628177 1.2953794129116125 1.0018944957458282 1.0282237712632019 \n",
      "iteration = 120 13.415619164623259\n",
      "0.879336944194729 0.958513526977004 1.6135985513058022 1.221340593611534 1.5063917818840755 3.1681579491597076 0.8568665270628177 1.2953794129116125 1.0018944957458282 1.0282237712632019 \n",
      "iteration = 121 13.415619164623259\n",
      "0.8804765985791537 0.9646848318496303 1.6140888293414029 1.2059724969550158 1.5028243144353939 3.161647695228774 0.8536834489797279 1.3100101157445645 1.0064601656795762 1.0302892138242956 \n",
      "iteration = 122 13.415645207183276\n",
      "0.8788003714588314 0.9575812159976613 1.6111099250885712 1.1966505849479234 1.5090419897892606 3.1903734219491695 0.871240339565311 1.2978425571074563 1.0105183851710444 1.0275294913682809 \n",
      "iteration = 123 13.436899705130015\n",
      "0.8788003714588314 0.9575812159976613 1.6111099250885712 1.1966505849479234 1.5090419897892606 3.1903734219491695 0.871240339565311 1.2978425571074563 1.0105183851710444 1.0275294913682809 \n",
      "iteration = 124 13.436899705130015\n",
      "0.8788003714588314 0.9575812159976613 1.6111099250885712 1.1966505849479234 1.5090419897892606 3.1903734219491695 0.871240339565311 1.2978425571074563 1.0105183851710444 1.0275294913682809 \n",
      "iteration = 125 13.436899705130015\n",
      "0.8788003714588314 0.9575812159976613 1.6111099250885712 1.1966505849479234 1.5090419897892606 3.1903734219491695 0.871240339565311 1.2978425571074563 1.0105183851710444 1.0275294913682809 \n",
      "iteration = 126 13.436899705130015\n",
      "1.068870060487357 0.9780759729725115 1.2860198903172932 1.2117835135620005 1.5312790796907736 3.2396270007326344 0.9118277466152269 1.2869940585556008 0.9833496905258688 1.150365031785077 \n",
      "iteration = 127 13.53448563369719\n",
      "1.068870060487357 0.9780759729725115 1.2860198903172932 1.2117835135620005 1.5312790796907736 3.2396270007326344 0.9118277466152269 1.2869940585556008 0.9833496905258688 1.150365031785077 \n",
      "iteration = 128 13.53448563369719\n",
      "1.068870060487357 0.9780759729725115 1.2860198903172932 1.2117835135620005 1.5312790796907736 3.2396270007326344 0.9118277466152269 1.2869940585556008 0.9833496905258688 1.150365031785077 \n",
      "iteration = 129 13.53448563369719\n",
      "1.068870060487357 0.9780759729725115 1.2860198903172932 1.2117835135620005 1.5312790796907736 3.2396270007326344 0.9118277466152269 1.2869940585556008 0.9833496905258688 1.150365031785077 \n",
      "iteration = 130 13.53448563369719\n",
      "1.068870060487357 0.9780759729725115 1.2860198903172932 1.2117835135620005 1.5312790796907736 3.2396270007326344 0.9118277466152269 1.2869940585556008 0.9833496905258688 1.150365031785077 \n",
      "iteration = 131 13.53448563369719\n",
      "1.068870060487357 0.9780759729725115 1.2860198903172932 1.2117835135620005 1.5312790796907736 3.2396270007326344 0.9118277466152269 1.2869940585556008 0.9833496905258688 1.150365031785077 \n",
      "iteration = 132 13.53448563369719\n",
      "1.068870060487357 0.9780759729725115 1.2860198903172932 1.2117835135620005 1.5312790796907736 3.2396270007326344 0.9118277466152269 1.2869940585556008 0.9833496905258688 1.150365031785077 \n",
      "iteration = 133 13.53448563369719\n",
      "1.068870060487357 0.9780759729725115 1.2860198903172932 1.2117835135620005 1.5312790796907736 3.2396270007326344 0.9118277466152269 1.2869940585556008 0.9833496905258688 1.150365031785077 \n",
      "iteration = 134 13.53448563369719\n",
      "1.004089318425994 0.9756056265626577 1.4032590381842975 1.2179946138723707 1.530602827534152 3.2193973101966487 0.8984105570957354 1.288377432996345 0.9935040008398285 1.1171526053473348 \n",
      "iteration = 135 13.534659738489477\n",
      "1.0112467017151103 0.9755195066992584 1.39130264871751 1.2180834698009353 1.5312644724313211 3.222870366503815 0.8995499140837497 1.2891505137306294 0.9922447305897467 1.1213846348600813 \n",
      "iteration = 136 13.538891876939395\n",
      "1.0112467017151103 0.9755195066992584 1.39130264871751 1.2180834698009353 1.5312644724313211 3.222870366503815 0.8995499140837497 1.2891505137306294 0.9922447305897467 1.1213846348600813 \n",
      "iteration = 137 13.538891876939395\n",
      "1.0112467017151103 0.9755195066992584 1.39130264871751 1.2180834698009353 1.5312644724313211 3.222870366503815 0.8995499140837497 1.2891505137306294 0.9922447305897467 1.1213846348600813 \n",
      "iteration = 138 13.538891876939395\n",
      "1.0112467017151103 0.9755195066992584 1.39130264871751 1.2180834698009353 1.5312644724313211 3.222870366503815 0.8995499140837497 1.2891505137306294 0.9922447305897467 1.1213846348600813 \n",
      "iteration = 139 13.538891876939395\n",
      "1.0112467017151103 0.9755195066992584 1.39130264871751 1.2180834698009353 1.5312644724313211 3.222870366503815 0.8995499140837497 1.2891505137306294 0.9922447305897467 1.1213846348600813 \n",
      "iteration = 140 13.538891876939395\n",
      "1.0292342514553239 0.9764244812350003 1.3597368185570204 1.2168489061554875 1.5322525098261708 3.229883548181915 0.9038139830395717 1.2886944052896638 0.989695284477108 1.1313351853361822 \n",
      "iteration = 141 13.544218126617402\n",
      "1.0371941462606564 0.9786744833446968 1.2350875595209452 1.2169293604317064 1.5429870836685433 3.399110635526013 0.9057027316619105 1.3025828746336758 0.9766566048695164 1.1277442982291723 \n",
      "iteration = 142 13.607536420114682\n",
      "1.0184825890362224 0.9789879681985632 1.3288959245147023 1.2264188763399873 1.5372406286500953 3.363242404559746 0.9023168178899824 1.2969032425118294 0.9871384741641052 1.1185198938906626 \n",
      "iteration = 143 13.643710984224757\n",
      "1.0221829628777344 0.979198238924162 1.308653610749469 1.2261571286623811 1.538832859919879 3.3845571551895146 0.9029385265143741 1.2986862644098807 0.9848060587018198 1.1195481922593653 \n",
      "iteration = 144 13.650948996097675\n",
      "1.0221829628777344 0.979198238924162 1.308653610749469 1.2261571286623811 1.538832859919879 3.3845571551895146 0.9029385265143741 1.2986862644098807 0.9848060587018198 1.1195481922593653 \n",
      "iteration = 145 13.650948996097675\n",
      "1.0221829628777344 0.979198238924162 1.308653610749469 1.2261571286623811 1.538832859919879 3.3845571551895146 0.9029385265143741 1.2986862644098807 0.9848060587018198 1.1195481922593653 \n",
      "iteration = 146 13.650948996097675\n",
      "1.0221829628777344 0.979198238924162 1.308653610749469 1.2261571286623811 1.538832859919879 3.3845571551895146 0.9029385265143741 1.2986862644098807 0.9848060587018198 1.1195481922593653 \n",
      "iteration = 147 13.650948996097675\n",
      "1.0221829628777344 0.979198238924162 1.308653610749469 1.2261571286623811 1.538832859919879 3.3845571551895146 0.9029385265143741 1.2986862644098807 0.9848060587018198 1.1195481922593653 \n",
      "iteration = 148 13.650948996097675\n",
      "1.0315702276175729 0.9766227042021216 1.353144774330219 1.2190438301037307 1.4724169374196416 3.4525520950434743 0.9305622974129715 1.2973044113299204 0.991700252085141 1.0460138933927783 \n",
      "iteration = 149 13.657202866527685\n",
      "1.0315702276175729 0.9766227042021216 1.353144774330219 1.2190438301037307 1.4724169374196416 3.4525520950434743 0.9305622974129715 1.2973044113299204 0.991700252085141 1.0460138933927783 \n",
      "iteration = 150 13.657202866527685\n",
      "1.037266503426877 0.9770396346893898 1.3334222636557476 1.219801552440441 1.4738791790409491 3.4829585028689096 0.9318939500703339 1.2993069751775517 0.9899739999890568 1.047930285436173 \n",
      "iteration = 151 13.67960715105363\n",
      "1.0348396907140511 0.9783482973149826 1.3086627132870186 1.2235437891386223 1.508001200834133 3.458000348414816 0.9188685492040282 1.3002797505852315 0.9866061720310217 1.0841821241496015 \n",
      "iteration = 152 13.687484188580017\n",
      "1.0424470059423552 0.9775028914612237 1.3150367372943452 1.2200675724406231 1.475051705383624 3.5053681005324617 0.9331041716415778 1.3005965219559306 0.9882309672329804 1.0498988407709586 \n",
      "iteration = 153 13.693318096524195\n",
      "1.0424470059423552 0.9775028914612237 1.3150367372943452 1.2200675724406231 1.475051705383624 3.5053681005324617 0.9331041716415778 1.3005965219559306 0.9882309672329804 1.0498988407709586 \n",
      "iteration = 154 13.693318096524195\n",
      "1.0424470059423552 0.9775028914612237 1.3150367372943452 1.2200675724406231 1.475051705383624 3.5053681005324617 0.9331041716415778 1.3005965219559306 0.9882309672329804 1.0498988407709586 \n",
      "iteration = 155 13.693318096524195\n",
      "1.0424470059423552 0.9775028914612237 1.3150367372943452 1.2200675724406231 1.475051705383624 3.5053681005324617 0.9331041716415778 1.3005965219559306 0.9882309672329804 1.0498988407709586 \n",
      "iteration = 156 13.693318096524195\n",
      "1.0424470059423552 0.9775028914612237 1.3150367372943452 1.2200675724406231 1.475051705383624 3.5053681005324617 0.9331041716415778 1.3005965219559306 0.9882309672329804 1.0498988407709586 \n",
      "iteration = 157 13.693318096524195\n",
      "0.9887719957745551 1.0704452389127599 1.3341497475780622 1.1263361721341005 1.3630227746046237 3.708476408117944 0.9222244419662209 1.326640137482382 0.9115906839899506 1.0693455201603954 \n",
      "iteration = 158 13.703230270162543\n",
      "1.011261417864095 1.043403028203818 1.3349703230420538 1.173137448687654 1.4514322776187496 3.5992741215283015 0.9234029862440051 1.338032629005116 0.9557982212402537 1.070358881212695 \n",
      "iteration = 159 13.785373300329349\n",
      "1.0121786963336004 1.0438089222700881 1.3229522233721953 1.1737694875256586 1.458212574741311 3.600689485636539 0.9210063610284025 1.3387969586561046 0.954518938910541 1.078580122760148 \n",
      "iteration = 160 13.788763997235126\n",
      "1.0551876772798046 0.9939666566608533 1.3350740664264897 1.1831450307715334 1.4880846677969968 3.6049200900657423 0.9325535676906545 1.3623221317418779 1.0666350410891807 0.9454705719138694 \n",
      "iteration = 161 13.850162388250077\n",
      "1.0406879503399447 1.0071875422776082 1.3363746741183455 1.19291267686345 1.4915415096611773 3.5978576695690685 0.9279302483712016 1.353863260452177 1.0238986418304903 0.9964102922952611 \n",
      "iteration = 162 13.852794685322138\n",
      "1.0414473491392353 1.0314105619066476 1.343062342275508 1.1618178762661193 1.481217253761161 3.6939114208681354 0.9266604188396846 1.3903710773912739 1.0496072533605314 0.9496548258375166 \n",
      "iteration = 163 13.951111144286047\n",
      "1.0414473491392353 1.0314105619066476 1.343062342275508 1.1618178762661193 1.481217253761161 3.6939114208681354 0.9266604188396846 1.3903710773912739 1.0496072533605314 0.9496548258375166 \n",
      "iteration = 164 13.951111144286047\n",
      "1.0414473491392353 1.0314105619066476 1.343062342275508 1.1618178762661193 1.481217253761161 3.6939114208681354 0.9266604188396846 1.3903710773912739 1.0496072533605314 0.9496548258375166 \n",
      "iteration = 165 13.951111144286047\n",
      "1.0414473491392353 1.0314105619066476 1.343062342275508 1.1618178762661193 1.481217253761161 3.6939114208681354 0.9266604188396846 1.3903710773912739 1.0496072533605314 0.9496548258375166 \n",
      "iteration = 166 13.951111144286047\n",
      "1.0414473491392353 1.0314105619066476 1.343062342275508 1.1618178762661193 1.481217253761161 3.6939114208681354 0.9266604188396846 1.3903710773912739 1.0496072533605314 0.9496548258375166 \n",
      "iteration = 167 13.951111144286047\n",
      "1.0414473491392353 1.0314105619066476 1.343062342275508 1.1618178762661193 1.481217253761161 3.6939114208681354 0.9266604188396846 1.3903710773912739 1.0496072533605314 0.9496548258375166 \n",
      "iteration = 168 13.951111144286047\n",
      "1.0414473491392353 1.0314105619066476 1.343062342275508 1.1618178762661193 1.481217253761161 3.6939114208681354 0.9266604188396846 1.3903710773912739 1.0496072533605314 0.9496548258375166 \n",
      "iteration = 169 13.951111144286047\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 170 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 171 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 172 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 173 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 174 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 175 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 176 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 177 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 178 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 179 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 180 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 181 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 182 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 183 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 184 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 185 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 186 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 187 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 188 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 189 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 190 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 191 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 192 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 193 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 194 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 195 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 196 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 197 14.130886348673506\n",
      "1.0227281956867909 1.0249597860881556 1.316109385619939 1.1686517926495246 1.6804041826418574 3.92136186058787 1.0079283115649744 1.2552516555553683 1.0485682557472864 0.8033450993666067 \n",
      "iteration = 198 14.130886348673506\n",
      "0.9377765301913132 1.0421090510325346 1.7622028939467964 1.1890578290755385 1.6748006088736493 3.73902405843729 0.9347493326002446 1.2303776889028784 0.956821270156488 0.8343088341258911 \n",
      "iteration = 199 14.180152926427661\n",
      "0.9903719764688833 1.0408804188948937 1.5936257221670296 1.190216346692209 1.6494282126190538 3.796660448298806 0.9249405029332535 1.2974348803901288 1.019371601865949 0.840031246364288 \n",
      "Initial Secrecy Rate GA: 8.698405811598713\n",
      "[8.698405811598713, 10.24197660886312, 10.584381652068682, 10.816506909188888, 11.138319480378708, 11.338505444329597, 11.539022547932266, 11.539022547932266, 11.539022547932266, 11.539022547932266, 11.633094919177644, 11.633094919177644, 11.774052815468863, 11.774052815468863, 11.774052815468863, 11.774052815468863, 11.774052815468863, 11.849998127739932, 11.894948353618828, 11.894948353618828, 11.944937995038137, 11.973390283908248, 11.973390283908248, 11.989029811870116, 11.989029811870116, 11.989029811870116, 11.989029811870116, 12.285444459112885, 12.285444459112885, 12.295943051594392, 12.295943051594392, 12.295943051594392, 12.33689706026468, 12.438875333776199, 12.438875333776199, 12.438875333776199, 12.438875333776199, 12.438875333776199, 12.438875333776199, 12.438875333776199, 12.438875333776199, 12.438875333776199, 12.438875333776199, 12.438875333776199, 12.438875333776199, 12.47516988876878, 12.545978347231008, 12.545978347231008, 12.545978347231008, 12.545978347231008, 12.545978347231008, 12.545978347231008, 12.571274591059773, 12.571274591059773, 12.571274591059773, 12.571274591059773, 12.574790485505046, 12.591918284221801, 12.591918284221801, 12.591918284221801, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.77985443096356, 12.781862151096895, 12.781862151096895, 12.790557049519759, 12.790557049519759, 12.790557049519759, 12.790557049519759, 12.795668662958965, 12.795668662958965, 12.795668662958965, 12.795668662958965, 12.795668662958965, 12.795668662958965, 12.909171122572102, 12.909171122572102, 12.909171122572102, 12.909171122572102, 12.909171122572102, 12.909171122572102, 12.917092921520217, 12.917092921520217, 12.982100084827499, 13.20205578741819, 13.20205578741819, 13.20205578741819, 13.208599417006528, 13.216852912214243, 13.216852912214243, 13.274297507857831, 13.274297507857831, 13.274297507857831, 13.274297507857831, 13.274297507857831, 13.274297507857831, 13.29314966897838, 13.29314966897838, 13.29314966897838, 13.38234662764092, 13.384530890071431, 13.384530890071431, 13.384530890071431, 13.384530890071431, 13.400040941609408, 13.415619164623259, 13.415619164623259, 13.415645207183276, 13.436899705130015, 13.436899705130015, 13.436899705130015, 13.436899705130015, 13.53448563369719, 13.53448563369719, 13.53448563369719, 13.53448563369719, 13.53448563369719, 13.53448563369719, 13.53448563369719, 13.53448563369719, 13.534659738489477, 13.538891876939395, 13.538891876939395, 13.538891876939395, 13.538891876939395, 13.538891876939395, 13.544218126617402, 13.607536420114682, 13.643710984224757, 13.650948996097675, 13.650948996097675, 13.650948996097675, 13.650948996097675, 13.650948996097675, 13.657202866527685, 13.657202866527685, 13.67960715105363, 13.687484188580017, 13.693318096524195, 13.693318096524195, 13.693318096524195, 13.693318096524195, 13.693318096524195, 13.703230270162543, 13.785373300329349, 13.788763997235126, 13.850162388250077, 13.852794685322138, 13.951111144286047, 13.951111144286047, 13.951111144286047, 13.951111144286047, 13.951111144286047, 13.951111144286047, 13.951111144286047, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.130886348673506, 14.180152926427661, 14.226884446922785]\n",
      "Final Secrecy Rate GA: 14.226884446922785\n"
     ]
    }
   ],
   "source": [
    "population_size = 100\n",
    "num_generations = 200\n",
    "crossover_rate = 0.9\n",
    "mutation_rate = 0.3\n",
    "\n",
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# GA Algorithm\n",
    "GA_results = GA_optimize_w_theta(population_size, num_generations, crossover_rate, mutation_rate)\n",
    "print(\"Initial Secrecy Rate GA:\", GA_results[0])\n",
    "print(GA_results)\n",
    "print(\"Final Secrecy Rate GA:\", GA_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_update_w_only(w, theta, learning_rate):\n",
    "    grad_w = compute_gradient_w(theta, w)\n",
    "    w_new = [w[i] - learning_rate * grad_w[i] for i in range (number_of_users)]\n",
    "    w_new = normalise_beamforming_vectors(w_new)\n",
    "    theta_new = theta\n",
    "\n",
    "    return w_new, theta_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of PSO and GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_GD(max_pso_iter, max_gd_iter, number_of_particles, learning_rate, w_max, w_min, c1, c2):\n",
    "    particles = [PSOParticle() for _ in range(number_of_particles)]\n",
    "    global_best_secrecy_rate = -np.inf\n",
    "    global_best_theta = np.zeros((1, Nris))\n",
    "    global_best_w = [np.zeros((N, 1)) for i in range(number_of_users)]\n",
    "\n",
    "    results_secrecy_rate = []\n",
    "\n",
    "    for particle in particles:\n",
    "        if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "            global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "            global_best_theta = deepcopy(particle.best_theta)\n",
    "            global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "    results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "    \n",
    "    for iteration in range(max_pso_iter):\n",
    "        print(\"iteration =\", iteration, \"Global Best Secrecy Rate:\", global_best_secrecy_rate)\n",
    "        inertia = dynamic_inertia(iteration, max_iter, w_max, w_min)\n",
    "\n",
    "        \"\"\"\n",
    "            Update particles theta by velocity\n",
    "        \"\"\"\n",
    "        for particle in particles:\n",
    "            particle.update_velocity(inertia, c1, c2, global_best_theta, global_best_w)\n",
    "            particle.update_position()\n",
    "            particle.update_best()\n",
    "            \n",
    "            if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "                global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "                global_best_theta = deepcopy(particle.best_theta)\n",
    "                global_best_w = deepcopy(particle.best_w)\n",
    "        \n",
    "        # GD\n",
    "        for particle in particles:\n",
    "            for _ in range (max_gd_iter):\n",
    "                new_w, new_theta = gradient_descent_update(particle.w, theta_angles_to_theta_vector(particle.theta), learning_rate)\n",
    "                new_secrecy_rate = secrecy_rate_objective_function(new_theta, new_w)\n",
    "                if (new_secrecy_rate - particle.current_secrecy_rate) < 1e-9:\n",
    "                    break\n",
    "                \n",
    "                particle.w = new_w\n",
    "                particle.theta = theta_vector_to_theta_angles(new_theta)\n",
    "                particle.current_secrecy_rate = new_secrecy_rate\n",
    "\n",
    "            particle.update_best()\n",
    "            \n",
    "            if particle.best_secrecy_rate > global_best_secrecy_rate: \n",
    "                # No need to check validity as we already checked it in the inner loop\n",
    "                global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "                global_best_theta = deepcopy(particle.best_theta)\n",
    "                global_best_w = deepcopy(particle.best_w)\n",
    "       \n",
    "        results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "    return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0 Global Best Secrecy Rate: 8.698405811598713\n",
      "iteration = 1 Global Best Secrecy Rate: 12.067198824966304\n",
      "iteration = 2 Global Best Secrecy Rate: 12.190076725703847\n",
      "iteration = 3 Global Best Secrecy Rate: 12.497654529290656\n",
      "iteration = 4 Global Best Secrecy Rate: 12.627340993186552\n",
      "iteration = 5 Global Best Secrecy Rate: 12.627340993186552\n",
      "iteration = 6 Global Best Secrecy Rate: 12.627340993186552\n",
      "iteration = 7 Global Best Secrecy Rate: 12.627340993186552\n",
      "iteration = 8 Global Best Secrecy Rate: 12.725231632204217\n",
      "iteration = 9 Global Best Secrecy Rate: 12.784422023846759\n",
      "iteration = 10 Global Best Secrecy Rate: 13.241490627175448\n",
      "iteration = 11 Global Best Secrecy Rate: 13.241490627175448\n",
      "iteration = 12 Global Best Secrecy Rate: 13.241490627175448\n",
      "iteration = 13 Global Best Secrecy Rate: 13.371067175479775\n",
      "iteration = 14 Global Best Secrecy Rate: 13.70089504128547\n",
      "iteration = 15 Global Best Secrecy Rate: 13.956900854872414\n",
      "iteration = 16 Global Best Secrecy Rate: 14.006841256755926\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m c1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.5\u001b[39m\n\u001b[1;32m     10\u001b[0m c2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.5\u001b[39m\n\u001b[0;32m---> 12\u001b[0m PSO_GD_results \u001b[38;5;241m=\u001b[39m \u001b[43mPSO_GD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_pso_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_gd_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_particles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial Secrecy Rate PSO-GD:\u001b[39m\u001b[38;5;124m\"\u001b[39m, PSO_GD_results[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Secrecy Rate PSO-GD:\u001b[39m\u001b[38;5;124m\"\u001b[39m, PSO_GD_results[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[19], line 37\u001b[0m, in \u001b[0;36mPSO_GD\u001b[0;34m(max_pso_iter, max_gd_iter, number_of_particles, learning_rate, w_max, w_min, c1, c2)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m particle \u001b[38;5;129;01min\u001b[39;00m particles:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (max_gd_iter):\n\u001b[0;32m---> 37\u001b[0m         new_w, new_theta \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparticle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_angles_to_theta_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparticle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m         new_secrecy_rate \u001b[38;5;241m=\u001b[39m secrecy_rate_objective_function(new_theta, new_w)\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (new_secrecy_rate \u001b[38;5;241m-\u001b[39m particle\u001b[38;5;241m.\u001b[39mcurrent_secrecy_rate) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-9\u001b[39m:\n",
      "Cell \u001b[0;32mIn[10], line 160\u001b[0m, in \u001b[0;36mgradient_descent_update\u001b[0;34m(w, theta, learning_rate, original_secrecy_rate)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient_descent_update\u001b[39m(w, theta, learning_rate, original_secrecy_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 160\u001b[0m     grad_w \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_gradient_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m     grad_theta \u001b[38;5;241m=\u001b[39m compute_gradient_theta(theta, w)\n\u001b[1;32m    162\u001b[0m     w_new \u001b[38;5;241m=\u001b[39m [w[i] \u001b[38;5;241m-\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m grad_w[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (number_of_users)]\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mcompute_gradient_w\u001b[0;34m(theta, w)\u001b[0m\n\u001b[1;32m     21\u001b[0m Z_e \u001b[38;5;241m=\u001b[39m hie[index_e_max] \u001b[38;5;241m@\u001b[39m np\u001b[38;5;241m.\u001b[39mdiag(theta\u001b[38;5;241m.\u001b[39mflatten()) \u001b[38;5;241m@\u001b[39m Hai \u001b[38;5;241m+\u001b[39m hae[index_e_max]\n\u001b[1;32m     22\u001b[0m Z_e_max\u001b[38;5;241m.\u001b[39mappend(Z_e)\n\u001b[0;32m---> 24\u001b[0m Z_bk \u001b[38;5;241m=\u001b[39m hib[k] \u001b[38;5;241m@\u001b[39m np\u001b[38;5;241m.\u001b[39mdiag(theta\u001b[38;5;241m.\u001b[39mflatten()) \u001b[38;5;241m@\u001b[39m Hai \u001b[38;5;241m+\u001b[39m hab[k]\n\u001b[1;32m     25\u001b[0m numGamma_bk \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(Z_bk \u001b[38;5;241m@\u001b[39m w[k])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     26\u001b[0m denGamma_bk \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39msum([np\u001b[38;5;241m.\u001b[39mabs(Z_bk \u001b[38;5;241m@\u001b[39m w[i])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_of_users) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m k])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "max_pso_iter = 200\n",
    "max_gd_iter = 50\n",
    "number_of_particles = 50\n",
    "w_max = 0.9\n",
    "w_min = 0.5\n",
    "c1 = 1.5\n",
    "c2 = 1.5\n",
    "\n",
    "PSO_GD_results = PSO_GD(max_pso_iter, max_gd_iter, number_of_particles, learning_rate, w_max, w_min, c1, c2)\n",
    "print(\"Initial Secrecy Rate PSO-GD:\", PSO_GD_results[0])\n",
    "print(\"Final Secrecy Rate PSO-GD:\", PSO_GD_results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of GA and GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_GD_optimize_w_theta(population_size: int, max_iter: int, max_iter_gd: int, crossover_rate: float = 0.85, mutation_rate: float = 0.85):\n",
    "  population = GAPopulation(population_size, crossover_rate, mutation_rate)\n",
    "  population.sort_population()\n",
    "  results_secrecy_rate = []\n",
    "  results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "\n",
    "  for iteration in range(max_iter):\n",
    "    print(\"iteration =\", iteration)\n",
    "    print(\"Best secrecy rate:\", population.individuals[0].fitness)\n",
    "    # Crossover\n",
    "    for _ in range(population_size):\n",
    "      if np.random.rand() < population.crossover_rate:\n",
    "        parent1, parent2 = population.select_parents()\n",
    "        child = population.crossover(parent1, parent2)\n",
    "    #Mutate \n",
    "        population.mutate(child)\n",
    "        population.add_individual(child)\n",
    "\n",
    "\n",
    "    # GD\n",
    "    for individual in population.individuals:\n",
    "      for _ in range(max_iter_gd):\n",
    "        new_w, new_theta = gradient_descent_update(individual.w, theta_angles_to_theta_vector(individual.theta), learning_rate)\n",
    "        new_secrecy_rate = secrecy_rate_objective_function(new_theta, new_w)\n",
    "        if (new_secrecy_rate - individual.fitness) < 1e-9:\n",
    "          break\n",
    "        \n",
    "        individual.w = new_w\n",
    "        individual.theta = theta_vector_to_theta_angles(new_theta)\n",
    "        individual.update_fitness()\n",
    "\n",
    "      individual.theta, individual.w = repair(theta_angles_to_theta_vector(individual.theta), individual.w)\n",
    "      individual.theta = theta_vector_to_theta_angles(individual.theta)\n",
    "      individual.update_fitness()\n",
    "\n",
    "    # Filter\n",
    "    population.filter_population() \n",
    "\n",
    "    # Sort\n",
    "    population.sort_population()\n",
    "    \n",
    "    #print(f\"[Generation {iteration + 1}] Population before GD: {list(map(lambda x: x.fitness, population.individuals))}\")\n",
    "\n",
    "    print(\"Best secrecy rate:\", population.individuals[0].fitness)\n",
    "    results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "\n",
    "  return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0\n",
      "Best secrecy rate: 8.760058732423133\n",
      "Best secrecy rate: 12.193339136327316\n",
      "iteration = 1\n",
      "Best secrecy rate: 12.193339136327316\n",
      "Best secrecy rate: 12.760571565882191\n",
      "iteration = 2\n",
      "Best secrecy rate: 12.760571565882191\n",
      "Best secrecy rate: 12.951624154876127\n",
      "iteration = 3\n",
      "Best secrecy rate: 12.951624154876127\n",
      "Best secrecy rate: 12.951624154876127\n",
      "iteration = 4\n",
      "Best secrecy rate: 12.951624154876127\n",
      "Best secrecy rate: 13.113608419686262\n",
      "iteration = 5\n",
      "Best secrecy rate: 13.113608419686262\n",
      "Best secrecy rate: 13.112029129245368\n",
      "iteration = 6\n",
      "Best secrecy rate: 13.112029129245368\n",
      "Best secrecy rate: 13.550520084824718\n",
      "iteration = 7\n",
      "Best secrecy rate: 13.550520084824718\n",
      "Best secrecy rate: 13.630467973278321\n",
      "iteration = 8\n",
      "Best secrecy rate: 13.630467973278321\n",
      "Best secrecy rate: 13.672665621099366\n",
      "iteration = 9\n",
      "Best secrecy rate: 13.672665621099366\n",
      "Best secrecy rate: 13.780882136012421\n",
      "iteration = 10\n",
      "Best secrecy rate: 13.780882136012421\n",
      "Best secrecy rate: 13.901953834319016\n",
      "iteration = 11\n",
      "Best secrecy rate: 13.901953834319016\n",
      "Best secrecy rate: 13.922835510774162\n",
      "iteration = 12\n",
      "Best secrecy rate: 13.922835510774162\n",
      "Best secrecy rate: 14.21151598258529\n",
      "iteration = 13\n",
      "Best secrecy rate: 14.21151598258529\n",
      "Best secrecy rate: 14.21151598258529\n",
      "iteration = 14\n",
      "Best secrecy rate: 14.21151598258529\n",
      "Best secrecy rate: 14.21151598258529\n",
      "iteration = 15\n",
      "Best secrecy rate: 14.21151598258529\n",
      "Best secrecy rate: 14.21151598258529\n",
      "iteration = 16\n",
      "Best secrecy rate: 14.21151598258529\n",
      "Best secrecy rate: 14.259055455032328\n",
      "iteration = 17\n",
      "Best secrecy rate: 14.259055455032328\n",
      "Best secrecy rate: 14.280737883235041\n",
      "iteration = 18\n",
      "Best secrecy rate: 14.280737883235041\n",
      "Best secrecy rate: 14.351076880724047\n",
      "iteration = 19\n",
      "Best secrecy rate: 14.351076880724047\n",
      "Best secrecy rate: 14.351076880724047\n",
      "iteration = 20\n",
      "Best secrecy rate: 14.351076880724047\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 21\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 22\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 23\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 24\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 25\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 26\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 27\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 28\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 29\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.406291024286727\n",
      "iteration = 30\n",
      "Best secrecy rate: 14.406291024286727\n",
      "Best secrecy rate: 14.509286831247767\n",
      "iteration = 31\n",
      "Best secrecy rate: 14.509286831247767\n",
      "Best secrecy rate: 14.52644998159139\n",
      "iteration = 32\n",
      "Best secrecy rate: 14.52644998159139\n",
      "Best secrecy rate: 14.52644998159139\n",
      "iteration = 33\n",
      "Best secrecy rate: 14.52644998159139\n",
      "Best secrecy rate: 14.52644998159139\n",
      "iteration = 34\n",
      "Best secrecy rate: 14.52644998159139\n",
      "Best secrecy rate: 14.52644998159139\n",
      "iteration = 35\n",
      "Best secrecy rate: 14.52644998159139\n",
      "Best secrecy rate: 14.52644998159139\n",
      "iteration = 36\n",
      "Best secrecy rate: 14.52644998159139\n",
      "Best secrecy rate: 14.54170324686021\n",
      "iteration = 37\n",
      "Best secrecy rate: 14.54170324686021\n",
      "Best secrecy rate: 14.54170324686021\n",
      "iteration = 38\n",
      "Best secrecy rate: 14.54170324686021\n",
      "Best secrecy rate: 14.54170324686021\n",
      "iteration = 39\n",
      "Best secrecy rate: 14.54170324686021\n",
      "Best secrecy rate: 14.54170324686021\n",
      "iteration = 40\n",
      "Best secrecy rate: 14.54170324686021\n",
      "Best secrecy rate: 14.54170324686021\n",
      "iteration = 41\n",
      "Best secrecy rate: 14.54170324686021\n",
      "Best secrecy rate: 14.54170324686021\n",
      "iteration = 42\n",
      "Best secrecy rate: 14.54170324686021\n",
      "Best secrecy rate: 14.54170324686021\n",
      "iteration = 43\n",
      "Best secrecy rate: 14.54170324686021\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 44\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 45\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 46\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 47\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 48\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 49\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 50\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543250251556712\n",
      "iteration = 51\n",
      "Best secrecy rate: 14.543250251556712\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 52\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 53\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 54\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 55\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 56\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 57\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 58\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 59\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 60\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 61\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 62\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 63\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 64\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 65\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 66\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 67\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 68\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 69\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 70\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543351816313471\n",
      "iteration = 71\n",
      "Best secrecy rate: 14.543351816313471\n",
      "Best secrecy rate: 14.543360149509038\n",
      "iteration = 72\n",
      "Best secrecy rate: 14.543360149509038\n",
      "Best secrecy rate: 14.543365894306342\n",
      "iteration = 73\n",
      "Best secrecy rate: 14.543365894306342\n",
      "Best secrecy rate: 14.543365894306342\n",
      "iteration = 74\n",
      "Best secrecy rate: 14.543365894306342\n",
      "Best secrecy rate: 14.543365894306342\n",
      "iteration = 75\n",
      "Best secrecy rate: 14.543365894306342\n",
      "Best secrecy rate: 14.543365894306342\n",
      "iteration = 76\n",
      "Best secrecy rate: 14.543365894306342\n",
      "Best secrecy rate: 14.555928639822836\n",
      "iteration = 77\n",
      "Best secrecy rate: 14.555928639822836\n",
      "Best secrecy rate: 14.56454361237972\n",
      "iteration = 78\n",
      "Best secrecy rate: 14.56454361237972\n",
      "Best secrecy rate: 14.56454361237972\n",
      "iteration = 79\n",
      "Best secrecy rate: 14.56454361237972\n",
      "Best secrecy rate: 14.56454361237972\n",
      "iteration = 80\n",
      "Best secrecy rate: 14.56454361237972\n",
      "Best secrecy rate: 14.56454361237972\n",
      "iteration = 81\n",
      "Best secrecy rate: 14.56454361237972\n",
      "Best secrecy rate: 14.56454361237972\n",
      "iteration = 82\n",
      "Best secrecy rate: 14.56454361237972\n",
      "Best secrecy rate: 14.56454361237972\n",
      "iteration = 83\n",
      "Best secrecy rate: 14.56454361237972\n",
      "Best secrecy rate: 14.56454361237972\n",
      "iteration = 84\n",
      "Best secrecy rate: 14.56454361237972\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 85\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 86\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 87\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 88\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 89\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 90\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 91\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 92\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 93\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 94\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 95\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 96\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 97\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 98\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 99\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 100\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 101\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 102\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 103\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 104\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 105\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 106\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 107\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 108\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 109\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 110\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 111\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 112\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 113\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 114\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 115\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 116\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 117\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 118\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 119\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 120\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.567547255778061\n",
      "iteration = 121\n",
      "Best secrecy rate: 14.567547255778061\n",
      "Best secrecy rate: 14.579511856248596\n",
      "iteration = 122\n",
      "Best secrecy rate: 14.579511856248596\n",
      "Best secrecy rate: 14.579511856248596\n",
      "iteration = 123\n",
      "Best secrecy rate: 14.579511856248596\n",
      "Best secrecy rate: 14.579511856248596\n",
      "iteration = 124\n",
      "Best secrecy rate: 14.579511856248596\n",
      "Best secrecy rate: 14.579511856248596\n",
      "iteration = 125\n",
      "Best secrecy rate: 14.579511856248596\n",
      "Best secrecy rate: 14.585549079909352\n",
      "iteration = 126\n",
      "Best secrecy rate: 14.585549079909352\n",
      "Best secrecy rate: 14.585549079909352\n",
      "iteration = 127\n",
      "Best secrecy rate: 14.585549079909352\n",
      "Best secrecy rate: 14.585549079909352\n",
      "iteration = 128\n",
      "Best secrecy rate: 14.585549079909352\n",
      "Best secrecy rate: 14.585549079909352\n",
      "iteration = 129\n",
      "Best secrecy rate: 14.585549079909352\n",
      "Best secrecy rate: 14.590103859691594\n",
      "iteration = 130\n",
      "Best secrecy rate: 14.590103859691594\n",
      "Best secrecy rate: 14.591941713079597\n",
      "iteration = 131\n",
      "Best secrecy rate: 14.591941713079597\n",
      "Best secrecy rate: 14.594699454653522\n",
      "iteration = 132\n",
      "Best secrecy rate: 14.594699454653522\n",
      "Best secrecy rate: 14.59699156115945\n",
      "iteration = 133\n",
      "Best secrecy rate: 14.59699156115945\n",
      "Best secrecy rate: 14.658014401484959\n",
      "iteration = 134\n",
      "Best secrecy rate: 14.658014401484959\n",
      "Best secrecy rate: 14.723495216108446\n",
      "iteration = 135\n",
      "Best secrecy rate: 14.723495216108446\n",
      "Best secrecy rate: 14.723495216108446\n",
      "iteration = 136\n",
      "Best secrecy rate: 14.723495216108446\n",
      "Best secrecy rate: 14.73045372708136\n",
      "iteration = 137\n",
      "Best secrecy rate: 14.73045372708136\n",
      "Best secrecy rate: 14.73045372708136\n",
      "iteration = 138\n",
      "Best secrecy rate: 14.73045372708136\n",
      "Best secrecy rate: 14.73045372708136\n",
      "iteration = 139\n",
      "Best secrecy rate: 14.73045372708136\n",
      "Best secrecy rate: 14.73045372708136\n",
      "iteration = 140\n",
      "Best secrecy rate: 14.73045372708136\n",
      "Best secrecy rate: 14.73045372708136\n",
      "iteration = 141\n",
      "Best secrecy rate: 14.73045372708136\n",
      "Best secrecy rate: 14.73045372708136\n",
      "iteration = 142\n",
      "Best secrecy rate: 14.73045372708136\n",
      "Best secrecy rate: 14.73045372708136\n",
      "iteration = 143\n",
      "Best secrecy rate: 14.73045372708136\n",
      "Best secrecy rate: 14.746496812430445\n",
      "iteration = 144\n",
      "Best secrecy rate: 14.746496812430445\n",
      "Best secrecy rate: 14.746496812430445\n",
      "iteration = 145\n",
      "Best secrecy rate: 14.746496812430445\n",
      "Best secrecy rate: 14.746496812430445\n",
      "iteration = 146\n",
      "Best secrecy rate: 14.746496812430445\n",
      "Best secrecy rate: 14.746496812430445\n",
      "iteration = 147\n",
      "Best secrecy rate: 14.746496812430445\n",
      "Best secrecy rate: 14.74657164975042\n",
      "iteration = 148\n",
      "Best secrecy rate: 14.74657164975042\n",
      "Best secrecy rate: 14.758101835928588\n",
      "iteration = 149\n",
      "Best secrecy rate: 14.758101835928588\n",
      "Best secrecy rate: 14.758101835928588\n",
      "iteration = 150\n",
      "Best secrecy rate: 14.758101835928588\n",
      "Best secrecy rate: 14.792449283691997\n",
      "iteration = 151\n",
      "Best secrecy rate: 14.792449283691997\n",
      "Best secrecy rate: 14.792449283691997\n",
      "iteration = 152\n",
      "Best secrecy rate: 14.792449283691997\n",
      "Best secrecy rate: 14.794353974078724\n",
      "iteration = 153\n",
      "Best secrecy rate: 14.794353974078724\n",
      "Best secrecy rate: 14.794353974078724\n",
      "iteration = 154\n",
      "Best secrecy rate: 14.794353974078724\n",
      "Best secrecy rate: 14.794353974078724\n",
      "iteration = 155\n",
      "Best secrecy rate: 14.794353974078724\n",
      "Best secrecy rate: 14.794353974078724\n",
      "iteration = 156\n",
      "Best secrecy rate: 14.794353974078724\n",
      "Best secrecy rate: 14.794854765429585\n",
      "iteration = 157\n",
      "Best secrecy rate: 14.794854765429585\n",
      "Best secrecy rate: 14.794854765429585\n",
      "iteration = 158\n",
      "Best secrecy rate: 14.794854765429585\n",
      "Best secrecy rate: 14.794854765429585\n",
      "iteration = 159\n",
      "Best secrecy rate: 14.794854765429585\n",
      "Best secrecy rate: 14.799809566672467\n",
      "iteration = 160\n",
      "Best secrecy rate: 14.799809566672467\n",
      "Best secrecy rate: 14.80774126528311\n",
      "iteration = 161\n",
      "Best secrecy rate: 14.80774126528311\n",
      "Best secrecy rate: 14.80774126528311\n",
      "iteration = 162\n",
      "Best secrecy rate: 14.80774126528311\n",
      "Best secrecy rate: 14.809102385038518\n",
      "iteration = 163\n",
      "Best secrecy rate: 14.809102385038518\n",
      "Best secrecy rate: 14.946236927728707\n",
      "iteration = 164\n",
      "Best secrecy rate: 14.946236927728707\n",
      "Best secrecy rate: 14.976620495536064\n",
      "iteration = 165\n",
      "Best secrecy rate: 14.976620495536064\n",
      "Best secrecy rate: 14.988135941574829\n",
      "iteration = 166\n",
      "Best secrecy rate: 14.988135941574829\n",
      "Best secrecy rate: 14.988135941574829\n",
      "iteration = 167\n",
      "Best secrecy rate: 14.988135941574829\n",
      "Best secrecy rate: 14.988135941574829\n",
      "iteration = 168\n",
      "Best secrecy rate: 14.988135941574829\n",
      "Best secrecy rate: 14.988923831949428\n",
      "iteration = 169\n",
      "Best secrecy rate: 14.988923831949428\n",
      "Best secrecy rate: 14.989225323200388\n",
      "iteration = 170\n",
      "Best secrecy rate: 14.989225323200388\n",
      "Best secrecy rate: 14.989225323200388\n",
      "iteration = 171\n",
      "Best secrecy rate: 14.989225323200388\n",
      "Best secrecy rate: 14.989225323200388\n",
      "iteration = 172\n",
      "Best secrecy rate: 14.989225323200388\n",
      "Best secrecy rate: 14.989225323200388\n",
      "iteration = 173\n",
      "Best secrecy rate: 14.989225323200388\n",
      "Best secrecy rate: 14.999204428290211\n",
      "iteration = 174\n",
      "Best secrecy rate: 14.999204428290211\n",
      "Best secrecy rate: 14.999204428290211\n",
      "iteration = 175\n",
      "Best secrecy rate: 14.999204428290211\n",
      "Best secrecy rate: 14.999204428290211\n",
      "iteration = 176\n",
      "Best secrecy rate: 14.999204428290211\n",
      "Best secrecy rate: 15.036894372056059\n",
      "iteration = 177\n",
      "Best secrecy rate: 15.036894372056059\n",
      "Best secrecy rate: 15.036894372056059\n",
      "iteration = 178\n",
      "Best secrecy rate: 15.036894372056059\n",
      "Best secrecy rate: 15.043468674015703\n",
      "iteration = 179\n",
      "Best secrecy rate: 15.043468674015703\n",
      "Best secrecy rate: 15.043468674015703\n",
      "iteration = 180\n",
      "Best secrecy rate: 15.043468674015703\n",
      "Best secrecy rate: 15.043468674015703\n",
      "iteration = 181\n",
      "Best secrecy rate: 15.043468674015703\n",
      "Best secrecy rate: 15.059597653425225\n",
      "iteration = 182\n",
      "Best secrecy rate: 15.059597653425225\n",
      "Best secrecy rate: 15.059597653425225\n",
      "iteration = 183\n",
      "Best secrecy rate: 15.059597653425225\n",
      "Best secrecy rate: 15.059597653425225\n",
      "iteration = 184\n",
      "Best secrecy rate: 15.059597653425225\n",
      "Best secrecy rate: 15.059597653425225\n",
      "iteration = 185\n",
      "Best secrecy rate: 15.059597653425225\n",
      "Best secrecy rate: 15.063148394205433\n",
      "iteration = 186\n",
      "Best secrecy rate: 15.063148394205433\n",
      "Best secrecy rate: 15.063148394205433\n",
      "iteration = 187\n",
      "Best secrecy rate: 15.063148394205433\n",
      "Best secrecy rate: 15.065328334946605\n",
      "iteration = 188\n",
      "Best secrecy rate: 15.065328334946605\n",
      "Best secrecy rate: 15.067520512465904\n",
      "iteration = 189\n",
      "Best secrecy rate: 15.067520512465904\n",
      "Best secrecy rate: 15.067520512465904\n",
      "iteration = 190\n",
      "Best secrecy rate: 15.067520512465904\n",
      "Best secrecy rate: 15.067520512465904\n",
      "iteration = 191\n",
      "Best secrecy rate: 15.067520512465904\n",
      "Best secrecy rate: 15.067520512465904\n",
      "iteration = 192\n",
      "Best secrecy rate: 15.067520512465904\n",
      "Best secrecy rate: 15.067520512465904\n",
      "iteration = 193\n",
      "Best secrecy rate: 15.067520512465904\n",
      "Best secrecy rate: 15.067520512465904\n",
      "iteration = 194\n",
      "Best secrecy rate: 15.067520512465904\n",
      "Best secrecy rate: 15.06788089888\n",
      "iteration = 195\n",
      "Best secrecy rate: 15.06788089888\n",
      "Best secrecy rate: 15.06788089888\n",
      "iteration = 196\n",
      "Best secrecy rate: 15.06788089888\n",
      "Best secrecy rate: 15.06788089888\n",
      "iteration = 197\n",
      "Best secrecy rate: 15.06788089888\n",
      "Best secrecy rate: 15.068181708696923\n",
      "iteration = 198\n",
      "Best secrecy rate: 15.068181708696923\n",
      "Best secrecy rate: 15.068444638401472\n",
      "iteration = 199\n",
      "Best secrecy rate: 15.068444638401472\n",
      "Best secrecy rate: 15.06870984347262\n",
      "Initial Secrecy Rate GA-GD: 8.760058732423133\n",
      "[np.float64(8.760058732423133), np.float64(12.193339136327316), np.float64(12.760571565882191), np.float64(12.951624154876127), np.float64(12.951624154876127), np.float64(13.113608419686262), np.float64(13.112029129245368), np.float64(13.550520084824718), np.float64(13.630467973278321), np.float64(13.672665621099366), np.float64(13.780882136012421), np.float64(13.901953834319016), np.float64(13.922835510774162), np.float64(14.21151598258529), np.float64(14.21151598258529), np.float64(14.21151598258529), np.float64(14.21151598258529), np.float64(14.259055455032328), np.float64(14.280737883235041), np.float64(14.351076880724047), np.float64(14.351076880724047), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.406291024286727), np.float64(14.509286831247767), np.float64(14.52644998159139), np.float64(14.52644998159139), np.float64(14.52644998159139), np.float64(14.52644998159139), np.float64(14.52644998159139), np.float64(14.54170324686021), np.float64(14.54170324686021), np.float64(14.54170324686021), np.float64(14.54170324686021), np.float64(14.54170324686021), np.float64(14.54170324686021), np.float64(14.54170324686021), np.float64(14.543250251556712), np.float64(14.543250251556712), np.float64(14.543250251556712), np.float64(14.543250251556712), np.float64(14.543250251556712), np.float64(14.543250251556712), np.float64(14.543250251556712), np.float64(14.543250251556712), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543351816313471), np.float64(14.543360149509038), np.float64(14.543365894306342), np.float64(14.543365894306342), np.float64(14.543365894306342), np.float64(14.543365894306342), np.float64(14.555928639822836), np.float64(14.56454361237972), np.float64(14.56454361237972), np.float64(14.56454361237972), np.float64(14.56454361237972), np.float64(14.56454361237972), np.float64(14.56454361237972), np.float64(14.56454361237972), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.567547255778061), np.float64(14.579511856248596), np.float64(14.579511856248596), np.float64(14.579511856248596), np.float64(14.579511856248596), np.float64(14.585549079909352), np.float64(14.585549079909352), np.float64(14.585549079909352), np.float64(14.585549079909352), np.float64(14.590103859691594), np.float64(14.591941713079597), np.float64(14.594699454653522), np.float64(14.59699156115945), np.float64(14.658014401484959), np.float64(14.723495216108446), np.float64(14.723495216108446), np.float64(14.73045372708136), np.float64(14.73045372708136), np.float64(14.73045372708136), np.float64(14.73045372708136), np.float64(14.73045372708136), np.float64(14.73045372708136), np.float64(14.73045372708136), np.float64(14.746496812430445), np.float64(14.746496812430445), np.float64(14.746496812430445), np.float64(14.746496812430445), np.float64(14.74657164975042), np.float64(14.758101835928588), np.float64(14.758101835928588), np.float64(14.792449283691997), np.float64(14.792449283691997), np.float64(14.794353974078724), np.float64(14.794353974078724), np.float64(14.794353974078724), np.float64(14.794353974078724), np.float64(14.794854765429585), np.float64(14.794854765429585), np.float64(14.794854765429585), np.float64(14.799809566672467), np.float64(14.80774126528311), np.float64(14.80774126528311), np.float64(14.809102385038518), np.float64(14.946236927728707), np.float64(14.976620495536064), np.float64(14.988135941574829), np.float64(14.988135941574829), np.float64(14.988135941574829), np.float64(14.988923831949428), np.float64(14.989225323200388), np.float64(14.989225323200388), np.float64(14.989225323200388), np.float64(14.989225323200388), np.float64(14.999204428290211), np.float64(14.999204428290211), np.float64(14.999204428290211), np.float64(15.036894372056059), np.float64(15.036894372056059), np.float64(15.043468674015703), np.float64(15.043468674015703), np.float64(15.043468674015703), np.float64(15.059597653425225), np.float64(15.059597653425225), np.float64(15.059597653425225), np.float64(15.059597653425225), np.float64(15.063148394205433), np.float64(15.063148394205433), np.float64(15.065328334946605), np.float64(15.067520512465904), np.float64(15.067520512465904), np.float64(15.067520512465904), np.float64(15.067520512465904), np.float64(15.067520512465904), np.float64(15.067520512465904), np.float64(15.06788089888), np.float64(15.06788089888), np.float64(15.06788089888), np.float64(15.068181708696923), np.float64(15.068444638401472), np.float64(15.06870984347262)]\n",
      "Final Secrecy Rate GA-GD: 15.06870984347262\n"
     ]
    }
   ],
   "source": [
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# GA-GD\n",
    "population_size = 50\n",
    "num_generations = 200\n",
    "num_iter_gd = 50\n",
    "crossover_rate = 0.9\n",
    "mutation_rate = 0.3\n",
    "learning_rate = 0.01\n",
    "\n",
    "GA_GD_results = GA_GD_optimize_w_theta(population_size, num_generations, num_iter_gd, crossover_rate, mutation_rate)\n",
    "print(\"Initial Secrecy Rate GA-GD:\", GA_GD_results[0])\n",
    "print(GA_GD_results)\n",
    "print(\"Final Secrecy Rate GA-GD:\", GA_GD_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(8.760058732423133),\n",
       " np.float64(12.193339136327316),\n",
       " np.float64(12.760571565882191),\n",
       " np.float64(12.951624154876127),\n",
       " np.float64(12.951624154876127),\n",
       " np.float64(13.113608419686262),\n",
       " np.float64(13.112029129245368),\n",
       " np.float64(13.550520084824718),\n",
       " np.float64(13.630467973278321),\n",
       " np.float64(13.672665621099366),\n",
       " np.float64(13.780882136012421),\n",
       " np.float64(13.901953834319016),\n",
       " np.float64(13.922835510774162),\n",
       " np.float64(14.21151598258529),\n",
       " np.float64(14.21151598258529),\n",
       " np.float64(14.21151598258529),\n",
       " np.float64(14.21151598258529),\n",
       " np.float64(14.259055455032328),\n",
       " np.float64(14.280737883235041),\n",
       " np.float64(14.351076880724047),\n",
       " np.float64(14.351076880724047),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.406291024286727),\n",
       " np.float64(14.509286831247767),\n",
       " np.float64(14.52644998159139),\n",
       " np.float64(14.52644998159139),\n",
       " np.float64(14.52644998159139),\n",
       " np.float64(14.52644998159139),\n",
       " np.float64(14.52644998159139),\n",
       " np.float64(14.54170324686021),\n",
       " np.float64(14.54170324686021),\n",
       " np.float64(14.54170324686021),\n",
       " np.float64(14.54170324686021),\n",
       " np.float64(14.54170324686021),\n",
       " np.float64(14.54170324686021),\n",
       " np.float64(14.54170324686021),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543250251556712),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543351816313471),\n",
       " np.float64(14.543360149509038),\n",
       " np.float64(14.543365894306342),\n",
       " np.float64(14.543365894306342),\n",
       " np.float64(14.543365894306342),\n",
       " np.float64(14.543365894306342),\n",
       " np.float64(14.555928639822836),\n",
       " np.float64(14.56454361237972),\n",
       " np.float64(14.56454361237972),\n",
       " np.float64(14.56454361237972),\n",
       " np.float64(14.56454361237972),\n",
       " np.float64(14.56454361237972),\n",
       " np.float64(14.56454361237972),\n",
       " np.float64(14.56454361237972),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.567547255778061),\n",
       " np.float64(14.579511856248596),\n",
       " np.float64(14.579511856248596),\n",
       " np.float64(14.579511856248596),\n",
       " np.float64(14.579511856248596),\n",
       " np.float64(14.585549079909352),\n",
       " np.float64(14.585549079909352),\n",
       " np.float64(14.585549079909352),\n",
       " np.float64(14.585549079909352),\n",
       " np.float64(14.590103859691594),\n",
       " np.float64(14.591941713079597),\n",
       " np.float64(14.594699454653522),\n",
       " np.float64(14.59699156115945),\n",
       " np.float64(14.658014401484959),\n",
       " np.float64(14.723495216108446),\n",
       " np.float64(14.723495216108446),\n",
       " np.float64(14.73045372708136),\n",
       " np.float64(14.73045372708136),\n",
       " np.float64(14.73045372708136),\n",
       " np.float64(14.73045372708136),\n",
       " np.float64(14.73045372708136),\n",
       " np.float64(14.73045372708136),\n",
       " np.float64(14.73045372708136),\n",
       " np.float64(14.746496812430445),\n",
       " np.float64(14.746496812430445),\n",
       " np.float64(14.746496812430445),\n",
       " np.float64(14.746496812430445),\n",
       " np.float64(14.74657164975042),\n",
       " np.float64(14.758101835928588),\n",
       " np.float64(14.758101835928588),\n",
       " np.float64(14.792449283691997),\n",
       " np.float64(14.792449283691997),\n",
       " np.float64(14.794353974078724),\n",
       " np.float64(14.794353974078724),\n",
       " np.float64(14.794353974078724),\n",
       " np.float64(14.794353974078724),\n",
       " np.float64(14.794854765429585),\n",
       " np.float64(14.794854765429585),\n",
       " np.float64(14.794854765429585),\n",
       " np.float64(14.799809566672467),\n",
       " np.float64(14.80774126528311),\n",
       " np.float64(14.80774126528311),\n",
       " np.float64(14.809102385038518),\n",
       " np.float64(14.946236927728707),\n",
       " np.float64(14.976620495536064),\n",
       " np.float64(14.988135941574829),\n",
       " np.float64(14.988135941574829),\n",
       " np.float64(14.988135941574829),\n",
       " np.float64(14.988923831949428),\n",
       " np.float64(14.989225323200388),\n",
       " np.float64(14.989225323200388),\n",
       " np.float64(14.989225323200388),\n",
       " np.float64(14.989225323200388),\n",
       " np.float64(14.999204428290211),\n",
       " np.float64(14.999204428290211),\n",
       " np.float64(14.999204428290211),\n",
       " np.float64(15.036894372056059),\n",
       " np.float64(15.036894372056059),\n",
       " np.float64(15.043468674015703),\n",
       " np.float64(15.043468674015703),\n",
       " np.float64(15.043468674015703),\n",
       " np.float64(15.059597653425225),\n",
       " np.float64(15.059597653425225),\n",
       " np.float64(15.059597653425225),\n",
       " np.float64(15.059597653425225),\n",
       " np.float64(15.063148394205433),\n",
       " np.float64(15.063148394205433),\n",
       " np.float64(15.065328334946605),\n",
       " np.float64(15.067520512465904),\n",
       " np.float64(15.067520512465904),\n",
       " np.float64(15.067520512465904),\n",
       " np.float64(15.067520512465904),\n",
       " np.float64(15.067520512465904),\n",
       " np.float64(15.067520512465904),\n",
       " np.float64(15.06788089888),\n",
       " np.float64(15.06788089888),\n",
       " np.float64(15.06788089888),\n",
       " np.float64(15.068181708696923),\n",
       " np.float64(15.068444638401472),\n",
       " np.float64(15.06870984347262)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GA_GD_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# iterations = range(0, num_cycles+10, 10)\n",
    "\n",
    "iterations = range(0, 100)\n",
    "# Extend the results to the same length\n",
    "GD_results_draw = GD_results[:100]\n",
    "PSO_results_draw = PSO_results[:100]\n",
    "GA_results_draw = GA_results[:100]\n",
    "PSO_GD_results_draw = PSO_GD_results[:100]\n",
    "GA_GD_results_draw = GA_GD_results[:100]\n",
    "\n",
    "\n",
    "#plt.plot(iterations, GD_results_draw, label='Gradient Descent')\n",
    "plt.plot(iterations, PSO_results_draw, label='PSO')\n",
    "plt.plot(iterations, GA_results_draw, label='Genetic Algorithm')\n",
    "plt.plot(iterations, PSO_GD_results_draw, label='PSO-GD')\n",
    "plt.plot(iterations, GA_GD_results_draw, label='GA-GD')\n",
    "\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Secrecy rate (bps/Hz)')\n",
    "plt.title('gamma =', gamma)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Secrecy Rate GD: 14.55176659777728\n",
      "Best Secrecy Rate PSO: 12.476866173861348\n",
      "Best Secrecy Rate GA: 13.457714097721054\n",
      "Best Secrecy Rate PSO-GD: 19.42312619148822\n",
      "Best Secrecy Rate GA-GD: 15.06870984347262\n"
     ]
    }
   ],
   "source": [
    "# Best results of each methods\n",
    "print(\"Best Secrecy Rate GD:\", max(GD_results))\n",
    "print(\"Best Secrecy Rate PSO:\", max(PSO_results))\n",
    "print(\"Best Secrecy Rate GA:\", max(GA_results))\n",
    "print(\"Best Secrecy Rate PSO-GD:\", max(PSO_GD_results))\n",
    "print(\"Best Secrecy Rate GA-GD:\", max(GA_GD_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

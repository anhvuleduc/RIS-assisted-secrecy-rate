{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy, copy\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 99\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transfer from dBW to W (power)\n",
    "def db2pow(db: float) -> float:\n",
    "    return 10**(db/10)\n",
    "\n",
    "# Function to transfer from W to dBW (power)\n",
    "def pow2db(pow: float) -> float:\n",
    "    return 10*np.log10(pow)\n",
    "\n",
    "# Hermitian transpose of a matrix\n",
    "def HermTranspose(x: np.ndarray) -> np.ndarray:\n",
    "    return x.conj().T\n",
    "\n",
    "def chanGen(zeta: float, d: float, dim1: int, dim2: int) -> np.ndarray:\n",
    "    \"\"\"Function to generate Rayleigh fading channel coefficients\n",
    "\n",
    "    Args:\n",
    "        zeta: Î¾ is the path loss exponent\n",
    "        d: the distance between the transmitter and the receiver\n",
    "        dim1: the number of rows in the channel matrix\n",
    "        dim2: the number of columns in the channel matrix\n",
    "    \"\"\"\n",
    "    pl_ref: float = -30                                    # pathloss (dBW) at reference distance\n",
    "    pl: float = db2pow(pl_ref - 10*zeta*np.log10(d))       # pathloss model at distance d\n",
    "    y: np.ndarray = np.sqrt(0.5*pl)*(np.random.randn(dim1,dim2)\\\n",
    "        + 1j*np.random.randn(dim1,dim2))            # Rayleigh distribution\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = db2pow(-75)                                                                 # noise power\n",
    "N = 8                                                                               # number of transmit antennas\n",
    "Nris = 32                                                                           # number of RIS elements\n",
    "number_of_users = 4                                                                 # number of users\n",
    "number_of_eavesdroppers = 2                                                         # number of eavesdroppers\n",
    "zetaAI = 2.2                                                                        # Path loss exponent of the channel between the Alice and the RIS\n",
    "zetaIB = 2.5                                                                        # Path loss exponent of the channel between the legitimate receivers and the RIS\n",
    "zetaIE = 2.5                                                                        # Path loss exponent of the channel between the eavesdroppers and the RIS\n",
    "zetaAB = 3.5                                                                        # Path loss exponent of the channel between the Alice and the legitimate receivers\n",
    "zetaAE = 3.5                                                                        # Path loss exponent of the channel between the Alice and the eavesdroppers\n",
    "\n",
    "dAI = 50                                                                            # distance between Alice and the RIS\n",
    "dv = 2                                                                              # Vertical distance between the Alice and the Eve and Bob\n",
    "dABh = np.random.uniform(5, 10, size=number_of_users)                               # Horizontal distance between Alice and the legitimate receivers\n",
    "dAEh = np.random.uniform(50, 150, size=number_of_eavesdroppers)                     # Horizontal distance between Alice and the eavesdroppers\n",
    "dAB = [np.sqrt(dABh[i]**2 + dv**2) for i in range(number_of_users)]                 # Distance between Alice and the legitimate receivers\n",
    "dAE = [np.sqrt(dAEh[i]**2 + dv**2) for i in range(number_of_eavesdroppers)]         # Distance between Alice and the eavesdroppers\n",
    "dIB = [np.sqrt((dABh[i]-dAI)**2 + dv**2) for i in range(number_of_users)]           # Distance between the legitimate receivers and the RIS\n",
    "dIE = [np.sqrt((dAEh[i]-dAI)**2 + dv**2) for i in range(number_of_eavesdroppers)]   # Distance between the eavesdroppers and the RIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_beamforming_vectors(w: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Function to normalise the beamforming vectors\n",
    "\n",
    "    Args:\n",
    "        w: the beamforming vectors\n",
    "    \"\"\"\n",
    "    total_norm = 0\n",
    "    for i in range(number_of_users):\n",
    "        total_norm += np.linalg.norm(w[i])\n",
    "    for i in range(number_of_users):\n",
    "        w[i] = w[i] / total_norm\n",
    "    return w\n",
    "\n",
    "def generate_random_beamforming_vector():\n",
    "  '''\n",
    "  Generate one random beamforming vector\n",
    "  '''\n",
    "  return np.random.uniform(-1, 1, (N, 1)) + 1j * np.random.uniform(-1, 1, (N, 1))\n",
    "\n",
    "def generate_random_beamforming_vectors():\n",
    "    # Generate random complex numbers for each element of the beamforming vector\n",
    "    beamforming_vectors = [generate_random_beamforming_vector() for _ in range (number_of_users)]\n",
    "    \n",
    "    # Normalize the vectors\n",
    "    beamforming_vectors = normalise_beamforming_vectors(beamforming_vectors)\n",
    "    return beamforming_vectors\n",
    "    #w: list of beamforming vectors, length = number of users, elements are N x 1\n",
    "\n",
    "def generate_random_theta():\n",
    "    theta = np.random.uniform(-np.pi, np.pi, (1, Nris))\n",
    "    theta = np.exp(1j * theta)\n",
    "    return theta\n",
    "    #theta: phase shift of RIS, size 1 x Nris\n",
    "\n",
    "def generate_random_theta_angles(size: int):\n",
    "  \"\"\"\n",
    "    Generate a random vector of angles from -pi to pi\n",
    "  \"\"\"\n",
    "  return np.random.uniform(-np.pi, np.pi, size=(1, size))\n",
    "\n",
    "def theta_angles_to_theta_vector(angles: np.ndarray[np.float64]) -> np.ndarray[np.complex128]:\n",
    "  \"\"\"\n",
    "    Convert a vector of angles to a vector of complex numbers on the unit circle\n",
    "  \"\"\"\n",
    "  return np.exp(1j * angles)\n",
    "\n",
    "def theta_vector_to_theta_angles(theta: np.ndarray[np.complex128]) -> np.ndarray[np.float64]:\n",
    "  \"\"\"\n",
    "    Convert a vector of complex numbers on the unit circle to a vector of angles\n",
    "  \"\"\"\n",
    "  return np.angle(theta)\n",
    "\n",
    "def generateChannel():\n",
    "    normFact = 1/np.sqrt(sigma)\n",
    "    Hai = chanGen(zetaAI, dAI, Nris, N)                                                         # Alice to RIS channel\n",
    "    hib = [normFact*chanGen(zetaIB, dIB[i], 1, Nris) for i in range(number_of_users)]           # Channel between the RIS and the legitimate receivers\n",
    "    hie = [normFact*chanGen(zetaIE, dIE[i], 1, Nris) for i in range(number_of_eavesdroppers)]   # Channel between the RIS and the eavesdroppers\n",
    "    hab = [normFact*chanGen(zetaAB, dAB[i], 1, N) for i in range(number_of_users)]              # Channel between Alice and the legitimate receivers\n",
    "    hae = [normFact*chanGen(zetaAE, dAE[i], 1, N) for i in range(number_of_eavesdroppers)]      # Channel between Alice and the eavesdroppers\n",
    "    return Hai, hib, hie, hab, hae\n",
    "\n",
    "    #Hai: Channel between Alice and RIS: Nris x N  \n",
    "    #hib: Channel between RIS and users: List of length number_of_users, elements are 1 x Nris\n",
    "    #hab: Channel between Alice and users: List of length number_of_users, elements are 1 x N\n",
    "    #hie: Channel between RIS and eavesdroppers: List of length number_of_eavesdroppers, elements are 1 x Nris\n",
    "    #hae: Channel between Alice and eavesdroppers: List of length number_of_eavesdroppers, elements are 1 x N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseed\n",
    "# np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Channel generation\n",
    "Hai, hib, hie, hab, hae = generateChannel()\n",
    "\n",
    "# Generate random theta and w\n",
    "theta_init = generate_random_theta()\n",
    "w_init = generate_random_beamforming_vectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secrecy_rate_objective_function(theta, w) -> float:\n",
    "    secrecy_rate: float = 0\n",
    "    for k in range(number_of_users):\n",
    "        R_bk = []\n",
    "        # Legitimate user k\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        C_bk = np.log2(1 + gamma_bk)\n",
    "        \n",
    "        for m in range(number_of_eavesdroppers):\n",
    "            # Eavesdropper i\n",
    "            Z_em = hie[m] @ np.diag(theta.flatten()) @ Hai + hae[m]\n",
    "            numGamma_em = np.abs(Z_em @ w[k])**2\n",
    "            denGamma_em = 1 + np.sum([np.abs(Z_em @ w[j])**2 for j in range(number_of_users) if j != k])\n",
    "            gamma_em = numGamma_em/denGamma_em\n",
    "            C_em = np.log2(1 + gamma_em)\n",
    "            R_bk.append(C_bk - C_em)\n",
    "        \n",
    "        secrecy_rate += max(min(R_bk),0)\n",
    "\n",
    "    # Return the only element in the matrix as it is currently a 1x1 np array\n",
    "    return secrecy_rate[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between Alice and the receivers:  [np.float64(8.597260577730964), np.float64(7.704507320858385), np.float64(9.344025672091696), np.float64(5.531459234567628)]\n",
      "distance between Alice and the eavesdroppers:  [np.float64(130.82028537878898), np.float64(106.58050877047856)]\n",
      "Secrecy Rate: 1.0304382881643281\n"
     ]
    }
   ],
   "source": [
    "# print(theta_init)\n",
    "print(\"distance between Alice and the receivers: \", dAB)\n",
    "print(\"distance between Alice and the eavesdroppers: \", dAE)\n",
    "print(\"Secrecy Rate:\", secrecy_rate_objective_function(theta_init, w_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent for Maximization (GD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_w(theta, w):\n",
    "    grad_w = []\n",
    "    Z_e_max = [] #Z_e_max[k] = Z_e_max for user k\n",
    "    gamma_e_max = [] #gamma_e_max[k] = gamma_e_max for user k\n",
    "    Z_b = [] #Z_b[k] = Z_bk\n",
    "    gamma_b = [] #gamma_b[k] = gamma_bk\n",
    "    counted = [] #counted[k] = true if gamma_k > gamma_e_max[k]\n",
    "    \n",
    "\n",
    "    #Precalculation \n",
    "    for k in range (number_of_users):\n",
    "        gamma_e = []\n",
    "        for m in range (number_of_eavesdroppers):\n",
    "            Z_em = hie[m] @ np.diag(theta.flatten()) @ Hai + hae[m]\n",
    "            numGamma_em = np.abs(Z_em @ w[k])**2\n",
    "            denGamma_em = 1 + np.sum([np.abs(Z_em @ w[j])**2 for j in range(number_of_users) if j != k])\n",
    "            gamma_em = numGamma_em/denGamma_em\n",
    "            gamma_e.append(gamma_em)\n",
    "        \n",
    "        gamma_e_max.append(max(gamma_e))\n",
    "        index_e_max = gamma_e.index(max(gamma_e))\n",
    "        Z_e = hie[index_e_max] @ np.diag(theta.flatten()) @ Hai + hae[index_e_max]\n",
    "        Z_e_max.append(Z_e)\n",
    "\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "\n",
    "        Z_b.append(Z_bk)\n",
    "        gamma_b.append(gamma_bk)\n",
    "\n",
    "        counted.append(gamma_bk > gamma_e[index_e_max])\n",
    "\n",
    "\n",
    "    #Calculating grad for i-th beamforming vector\n",
    "    for i in range(number_of_users):\n",
    "        grad = np.zeros((N, 1))\n",
    "        #print(\"grad_shape =\", grad.shape)\n",
    "        for k in range (number_of_users):\n",
    "            if (counted[k] == False):\n",
    "                continue\n",
    "            if (k == i):\n",
    "                num_grad_C_bk_to_w_k = 2 * (HermTranspose(Z_b[k]) @ Z_b[k] @ w[k])\n",
    "                den_grad_C_bk_to_w_k = (1 + gamma_b[k]) * np.log(2) * (1 + sum([abs(Z_b[k] @ w[j]) for j in range (number_of_users) if j != k]))\n",
    "                grad_C_bk_to_w_k = num_grad_C_bk_to_w_k / den_grad_C_bk_to_w_k\n",
    "\n",
    "                num_grad_C_e_max_to_w_k = 2 * (HermTranspose(Z_e_max[k]) @ Z_e_max[k] @ w[k])\n",
    "                den_grad_C_e_max_to_w_k = (1 + gamma_e_max[k]) * np.log(2) * (1 + sum([abs(Z_e_max[k] @ w[j]) for j in range (number_of_users) if j != k]))\n",
    "                grad_C_e_max_to_w_k = num_grad_C_e_max_to_w_k / den_grad_C_e_max_to_w_k\n",
    "                \n",
    "                #print(\"num_grad_C_e_max_to_w_k\", num_grad_C_e_max_to_w_k.shape)\n",
    "                #print(\"den_grad_C_e_max_to_w_k\", den_grad_C_e_max_to_w_k.shape)\n",
    "                grad = grad - (grad_C_bk_to_w_k - grad_C_e_max_to_w_k)\n",
    "            else:\n",
    "                num_grad_C_bk_to_w_i = -2 * abs(Z_b[k] @ w[k]) * (HermTranspose(Z_b[k]) @ Z_b[k] @ w[i])\n",
    "                den_grad_C_bk_to_w_i = (1 + gamma_b[k]) * np.log(2) * (1 + sum([abs(Z_b[k] @ w[j]) for j in range (number_of_users) if j != k])) ** 2\n",
    "                grad_C_bk_to_w_i = num_grad_C_bk_to_w_i / den_grad_C_bk_to_w_i\n",
    "\n",
    "                num_grad_C_e_max_to_w_i = -2 * abs(Z_e_max[k] @ w[k]) * (HermTranspose(Z_e_max[k]) @ Z_e_max[k] @ w[i])\n",
    "                den_grad_C_e_max_to_w_i = (1 + gamma_e_max[k]) * np.log(2) * (1 + sum([abs(Z_e_max[k] @ w[j]) for j in range (number_of_users) if j != k])) ** 2\n",
    "                grad_C_e_max_to_w_i = num_grad_C_e_max_to_w_i / den_grad_C_e_max_to_w_i\n",
    "\n",
    "                grad = grad - (grad_C_bk_to_w_i - grad_C_e_max_to_w_i)\n",
    "            \n",
    "        grad_w.append(grad)\n",
    "    return grad_w\n",
    "\n",
    "def compute_gradient_theta_central(theta, w, epsilon=1e-3):\n",
    "    perturbation = epsilon + epsilon * 1j\n",
    "    grad_theta = []\n",
    "    for i in range(Nris):\n",
    "        theta_plus = copy(theta)\n",
    "        theta_plus[0, i] += perturbation\n",
    "        theta_minus = copy(theta)\n",
    "        theta_minus[0, i] -= perturbation\n",
    "        grad_theta_i = (secrecy_rate_objective_function(theta_plus, w) - secrecy_rate_objective_function(theta_minus, w)) / (2*epsilon)\n",
    "        grad_theta.append(grad_theta_i)\n",
    "            \n",
    "    return np.array(grad_theta)\n",
    "\n",
    "def compute_gradient_theta(theta, w, original_secrecy_rate=None, epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Faster implementation of the gradient calculation\n",
    "\n",
    "    Improvements:\n",
    "    - Use forward difference instead of central difference\n",
    "    \"\"\"\n",
    "    perturbation = epsilon + epsilon * 1j\n",
    "    grad_theta = []\n",
    "    for i in range(Nris):\n",
    "        theta_plus = copy(theta)\n",
    "        theta_plus[0, i] += perturbation\n",
    "        grad_theta_i = (secrecy_rate_objective_function(theta_plus, w) - original_secrecy_rate) / epsilon\n",
    "        grad_theta.append(grad_theta_i)\n",
    "\n",
    "    return np.array(grad_theta)\n",
    "\n",
    "\n",
    "def gradient_descent_update(w, theta, learning_rate, original_secrecy_rate=None):\n",
    "    grad_w = compute_gradient_w(theta, w)\n",
    "    grad_theta = compute_gradient_theta(theta, w, original_secrecy_rate)\n",
    "    w_new = [w[i] - learning_rate * grad_w[i] for i in range (number_of_users)]\n",
    "    total_norm = 0\n",
    "    for i in range (number_of_users):\n",
    "        total_norm += np.linalg.norm(w_new[i])\n",
    "    for i in range (number_of_users):\n",
    "        w_new[i] = w_new[i] / total_norm\n",
    "        \n",
    "    theta_new = theta - learning_rate * grad_theta\n",
    "    theta_new = np.exp(1j * np.angle(theta_new))\n",
    "\n",
    "    return w_new, theta_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Secrecy Rate GD: 1.2080238931977207\n",
      "Converged\n",
      "[np.float64(1.0304382881643281), np.float64(6.118621974604992), np.float64(8.696606202668494), np.float64(9.870564541150003), np.float64(10.61565521623102), np.float64(11.15330742326103), np.float64(11.546885679836965), np.float64(11.837522217687441), np.float64(12.05529429707602), np.float64(12.220996986919342), np.float64(12.348792792227963), np.float64(12.448538028550828), np.float64(12.527439073336147), np.float64(12.590554409322387), np.float64(12.641663260789842), np.float64(12.683589694060256), np.float64(12.71845871611104), np.float64(12.747875257186632), np.float64(12.773054442246746), np.float64(12.794917614361935), np.float64(12.814164053465657), np.float64(12.831324987560528), np.float64(12.846804468800919), np.float64(12.86091037652741), np.float64(12.87387793929189), np.float64(12.885887565316043), np.float64(12.89707833758916), np.float64(12.907558208728522), np.float64(12.917411687801103), np.float64(12.926705625323532), np.float64(12.935493559530357), np.float64(12.943818976765595), np.float64(12.951717754096743), np.float64(12.959219987280473), np.float64(12.966351357578773), np.float64(12.973134153143619), np.float64(12.979588032022315), np.float64(12.985730592149135), np.float64(12.991577797325006), np.float64(12.997144295866953), np.float64(13.002443659351517), np.float64(13.007488561931488), np.float64(13.012290915502962), np.float64(13.016861972107161), np.float64(13.021212402042352), np.float64(13.025352353988918), np.float64(13.029291501829963), np.float64(13.033039081641611), np.float64(13.036603921427153), np.float64(13.03999446549918), np.float64(13.043218794915461), np.float64(13.046284645003905), np.float64(13.049199420736933), np.float64(13.051970210511655), np.float64(13.054603798741045), np.float64(13.057106677549811), np.float64(13.05948505778617), np.float64(13.06174487950018), np.float64(13.063891821995002), np.float64(13.065931313524928), np.float64(13.067868540690831), np.float64(13.069708457566637), np.float64(13.071455794578611), np.float64(13.073115067150859), np.float64(13.074690584124728), np.float64(13.076186455955941), np.float64(13.07760660269107), np.float64(13.078954761723292), np.float64(13.080234495326945), np.float64(13.081449197970016), np.float64(13.082602103403921), np.float64(13.083696291530263), np.float64(13.084734695044755), np.float64(13.085720105859004), np.float64(13.086655181301495), np.float64(13.087542450099704), np.float64(13.088384318145685), np.float64(13.089183074048215), np.float64(13.089940894474863), np.float64(13.090659849287896), np.float64(13.091341906478192), np.float64(13.091988936901743), np.float64(13.092602718823596), np.float64(13.093184942274181), np.float64(13.09373721322331), np.float64(13.094261057577114), np.float64(13.094757925003428), np.float64(13.09522919259102), np.float64(13.095676168348241), np.float64(13.096100094546625), np.float64(13.096502150914832), np.float64(13.096883457688508), np.float64(13.097245078521336), np.float64(13.097588023262649), np.float64(13.09791325060674), np.float64(13.098221670619068), np.float64(13.098514147144195), np.float64(13.098791500100486), np.float64(13.099054507666175), np.float64(13.09930390836141), np.float64(13.099540403030826), np.float64(13.099764656730839), np.float64(13.099977300525943), np.float64(13.100178933197949), np.float64(13.100370122872182), np.float64(13.100551408564248), np.float64(13.100723301651113), np.float64(13.100886287269862), np.float64(13.101040825647555), np.float64(13.101187353365367), np.float64(13.10132628456006), np.float64(13.101458012065777), np.float64(13.10158290849896), np.float64(13.101701327289126), np.float64(13.101813603658062), np.float64(13.101920055549947), np.float64(13.102020984514734), np.float64(13.102116676547137), np.float64(13.102207402883263), np.float64(13.102293420757057), np.float64(13.10237497411853), np.float64(13.10245229431554), np.float64(13.102525600741085), np.float64(13.102595101447672), np.float64(13.102660993730478), np.float64(13.102723464680825), np.float64(13.102782691711464), np.float64(13.10283884305505), np.float64(13.10289207823718), np.float64(13.102942548525238), np.float64(13.10299039735433), np.float64(13.103035760731338), np.float64(13.10307876761835), np.float64(13.103119540296376), np.float64(13.103158194710446), np.float64(13.103194840796931), np.float64(13.103229582794118), np.float64(13.103262519536774), np.float64(13.103293744735568), np.float64(13.103323347242123), np.float64(13.103351411300387), np.float64(13.103378016785129), np.float64(13.103403239428044), np.float64(13.103427151032271), np.float64(13.103449819675847), np.float64(13.103471309904586), np.float64(13.103491682915115), np.float64(13.10351099672835), np.float64(13.103529306354083), np.float64(13.103546663947043), np.float64(13.103563118954861), np.float64(13.103578718258442), np.float64(13.103593506305021), np.float64(13.103607525234374), np.float64(13.103620814998479), np.float64(13.103633413474991), np.float64(13.103645356574841), np.float64(13.103656678344269), np.float64(13.103667411061556), np.float64(13.10367758532877), np.float64(13.103687230158737), np.float64(13.103696373057527), np.float64(13.103705040102636), np.float64(13.103713256017159), np.float64(13.103721044240057), np.float64(13.103728426992854), np.float64(13.103735425342808), np.float64(13.10374205926286), np.float64(13.103748347688423), np.float64(13.103754308571279), np.float64(13.103759958930636), np.float64(13.103765314901567), np.float64(13.103770391780902), np.float64(13.103775204070779), np.float64(13.103779765519912), np.float64(13.103784089162708), np.float64(13.103788187356379), np.float64(13.103792071816105), np.float64(13.103795753648392), np.float64(13.103799243382682), np.float64(13.103802551001326), np.float64(13.103805685968004), np.float64(13.103808657254675), np.float64(13.10381147336711), np.float64(13.103814142369114), np.float64(13.103816671905498), np.float64(13.103819069223821), np.float64(13.103821341195054), np.float64(13.103823494333131), np.float64(13.1038255348135), np.float64(13.103827468490712), np.float64(13.103829300915098), np.float64(13.103831037348556), np.float64(13.103832682779565), np.float64(13.103834241937374), np.float64(13.103835719305462), np.float64(13.103837119134344), np.float64(13.103838445453633), np.float64(13.103839702083542), np.float64(13.103840892645774), np.float64(13.103842020573804), np.float64(13.103843089122698), np.float64(13.103844101378346), np.float64(13.103845060266291), np.float64(13.103845968560027), np.float64(13.103846828888926), np.float64(13.103847643745711), np.float64(13.103848415493562), np.float64(13.103849146372855), np.float64(13.103849838507529), np.float64(13.10385049391115), np.float64(13.103851114492635), np.float64(13.103851702061702), np.float64(13.103852258334019), np.float64(13.10385278493609), np.float64(13.103853283409897), np.float64(13.103853755217276), np.float64(13.103854201744095), np.float64(13.103854624304207), np.float64(13.103855024143176), np.float64(13.103855402441834), np.float64(13.103855760319645), np.float64(13.103856098837904), np.float64(13.10385641900274), np.float64(13.103856721767997), np.float64(13.103857008037949), np.float64(13.103857278669874), np.float64(13.103857534476493), np.float64(13.103857776228292), np.float64(13.10385800465572), np.float64(13.103858220451254), np.float64(13.10385842427139), np.float64(13.103858616738506), np.float64(13.103858798442626), np.float64(13.103858969943122), np.float64(13.103859131770289), np.float64(13.103859284426854), np.float64(13.103859428389438), np.float64(13.103859564109868), np.float64(13.103859692016503), np.float64(13.103859812515443), np.float64(13.103859925991669), np.float64(13.10386003281016), np.float64(13.103860133316937), np.float64(13.103860227840023), np.float64(13.103860316690405), np.float64(13.10386040016289), np.float64(13.103860478536989), np.float64(13.103860552077666), np.float64(13.103860621036127), np.float64(13.103860685650513), np.float64(13.103860746146594), np.float64(13.103860802738405), np.float64(13.10386085562886), np.float64(13.103860905010322), np.float64(13.103860951065162), np.float64(13.103860993966268), np.float64(13.10386103387755), np.float64(13.103861070954391), np.float64(13.103861105344102), np.float64(13.103861137186342), np.float64(13.103861166613505), np.float64(13.10386119375111), np.float64(13.103861218718148), np.float64(13.103861241627435), np.float64(13.103861262585902), np.float64(13.103861281694954), np.float64(13.103861299050699), np.float64(13.103861314744261), np.float64(13.103861328862035), np.float64(13.103861341485906), np.float64(13.103861352693533), np.float64(13.103861362558506), np.float64(13.103861371150618), np.float64(13.103861378536017), np.float64(13.10386138477742), np.float64(13.103861389934284), np.float64(13.103861394062974), np.float64(13.103861397216928), np.float64(13.103861399446814), np.float64(13.10386140080065)]\n",
      "Final Secrecy Rate GD: 13.10386140080065\n"
     ]
    }
   ],
   "source": [
    "# Reseed first\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Gradient Descent Algorithm\n",
    "num_cycles = 500\n",
    "learning_rate = 0.01\n",
    "theta_GD = generate_random_theta()\n",
    "w_GD = generate_random_beamforming_vectors()\n",
    "print(\"Initial Secrecy Rate GD:\", secrecy_rate_objective_function(theta_GD, w_GD))\n",
    "current_secrecy_rate = secrecy_rate_objective_function(theta_init, w_init)\n",
    "\n",
    "GD_results = []\n",
    "GD_results.append(current_secrecy_rate)\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    w_new, theta_new = gradient_descent_update(w_GD, theta_GD, learning_rate, original_secrecy_rate=current_secrecy_rate)\n",
    "    new_secrecy_rate = secrecy_rate_objective_function(theta_new, w_new)\n",
    "    # print(new_secrecy_rate)\n",
    "    if (new_secrecy_rate - current_secrecy_rate) < 1e-9:\n",
    "        print(\"Converged\")\n",
    "        break\n",
    "    w_GD = w_new\n",
    "    theta_GD = theta_new\n",
    "    GD_results.append(new_secrecy_rate)\n",
    "    current_secrecy_rate = new_secrecy_rate\n",
    "\n",
    "print(GD_results)\n",
    "print(\"Final Secrecy Rate GD:\", secrecy_rate_objective_function(theta_GD, w_GD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Swarm Optimization (PSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSOParticle:\n",
    "  def __init__(self) -> None:\n",
    "    self.theta = generate_random_theta_angles(Nris)\n",
    "    self.w = generate_random_beamforming_vectors()\n",
    "    self.best_theta = deepcopy(self.theta)\n",
    "    self.best_w = deepcopy(self.w)\n",
    "    self.best_secrecy_rate = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.best_theta), self.best_w)\n",
    "    self.velocity_theta = np.zeros((1, Nris))\n",
    "    self.velocity_w = [np.zeros((N, 1)) for i in range(number_of_users)]\n",
    "\n",
    "  def update_velocity(self, inertia, c1, c2, global_best_theta, global_best_w):\n",
    "    self.velocity_theta = inertia * self.velocity_theta + c1 * np.random.rand() * (self.best_theta - self.theta) + c2 * np.random.rand() * (global_best_theta - self.theta)\n",
    "    self.velocity_w = [inertia * self.velocity_w[i] + c1 * np.random.rand() * (self.best_w[i] - self.w[i]) + c2 * np.random.rand() * (global_best_w[i] - self.w[i]) for i in range(number_of_users)]\n",
    "\n",
    "  def update_position(self):\n",
    "    self.theta = self.theta + self.velocity_theta\n",
    "    self.w = [self.w[i] + self.velocity_w[i] for i in range(number_of_users)]\n",
    "    total_norm = 0\n",
    "    for i in range (number_of_users):\n",
    "        total_norm += np.linalg.norm(self.w[i])\n",
    "    for i in range(number_of_users):\n",
    "        self.w[i] = self.w[i] / total_norm\n",
    "\n",
    "\n",
    "  def update_best(self):\n",
    "    current_secrecy_rate = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.theta), self.w)\n",
    "    if current_secrecy_rate > self.best_secrecy_rate:\n",
    "      self.best_secrecy_rate = current_secrecy_rate\n",
    "      self.best_theta = deepcopy(self.theta)\n",
    "      self.best_w = deepcopy(self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_inertia(i: int, max_iter: int, inertia_max: float, inertia_min: float) -> float:\n",
    "  E_t = float((max_iter - i - 1)/max_iter)\n",
    "  inertia = inertia_min + (inertia_max - inertia_min) * (2 /(1 + (np.e ** (-5 * E_t))) - 1)\n",
    "  return inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_optimize_w_theta(max_iter: int, num_particles: int, w_min: float, w_max: float, c1: float, c2: float):\n",
    "  particles = [PSOParticle() for _ in range(num_particles)]\n",
    "  global_best_secrecy_rate = -np.inf\n",
    "  global_best_theta = np.zeros((1, Nris))\n",
    "  global_best_w = [np.zeros((N, 1)) for i in range(number_of_users)]\n",
    "\n",
    "  results_secrecy_rate = []\n",
    "\n",
    "  for particle in particles:\n",
    "    if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "      global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "      global_best_theta = deepcopy(particle.best_theta)\n",
    "      global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "  results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "\n",
    "  for iteration in range(max_iter):\n",
    "    inertia = dynamic_inertia(iteration, max_iter, w_max, w_min)\n",
    "\n",
    "    for particle in particles:\n",
    "      particle.update_velocity(inertia, c1, c2, global_best_theta, global_best_w)\n",
    "      particle.update_position()\n",
    "      particle.update_best()\n",
    "\n",
    "      if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "        global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "        global_best_theta = deepcopy(particle.best_theta)\n",
    "        global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "    results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "\n",
    "  return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Secrecy Rate PSO: 3.782669340293348\n",
      "[np.float64(3.782669340293348), np.float64(7.27015869702259), np.float64(7.458103555294634), np.float64(7.458103555294634), np.float64(7.561774537274905), np.float64(7.824292146645841), np.float64(7.935926466190117), np.float64(8.215962066273109), np.float64(8.267887698862815), np.float64(8.406958649099684), np.float64(8.4269065902722), np.float64(8.460557831699361), np.float64(8.471013569453259), np.float64(8.50658819637212), np.float64(8.548326629987855), np.float64(8.589094950964), np.float64(8.639798146361018), np.float64(8.672306724700572), np.float64(8.72814308249653), np.float64(8.964862038283663), np.float64(9.058763159365984), np.float64(9.068630107746985), np.float64(9.093669292425396), np.float64(9.147765930218814), np.float64(9.153988586948213), np.float64(9.153988586948213), np.float64(9.158739096211445), np.float64(9.172630526805452), np.float64(9.182309966850095), np.float64(9.188334850070417), np.float64(9.195817247124642), np.float64(9.195817247124642), np.float64(9.203621546076342), np.float64(9.205290789918777), np.float64(9.209571761157934), np.float64(9.21801835018918), np.float64(9.226072994456954), np.float64(9.226567834444147), np.float64(9.233047264399424), np.float64(9.233211881599935), np.float64(9.23732624212993), np.float64(9.237790205992846), np.float64(9.240846748355029), np.float64(9.242275851410238), np.float64(9.242275851410238), np.float64(9.243648843844928), np.float64(9.243718375223798), np.float64(9.244531629173636), np.float64(9.244531629173636), np.float64(9.244546771531752), np.float64(9.244546771531752), np.float64(9.244546771531752), np.float64(9.245334777475923), np.float64(9.245696492021704), np.float64(9.24722518908049), np.float64(9.24722518908049), np.float64(9.247873175580688), np.float64(9.24827345380785), np.float64(9.25021596991998), np.float64(9.250931441618677), np.float64(9.25653888542418), np.float64(9.259826305313643), np.float64(9.259865453110349), np.float64(9.260801205420423), np.float64(9.2637169831268), np.float64(9.265706239874936), np.float64(9.265706239874936), np.float64(9.265706239874936), np.float64(9.265706239874936), np.float64(9.268763404740886), np.float64(9.268763404740886), np.float64(9.26962873828503), np.float64(9.270677803728233), np.float64(9.271568384318117), np.float64(9.271568384318117), np.float64(9.271568384318117), np.float64(9.274038141617359), np.float64(9.274038141617359), np.float64(9.274038141617359), np.float64(9.27454555797573), np.float64(9.27454555797573), np.float64(9.27454555797573), np.float64(9.27454555797573), np.float64(9.27504511649627), np.float64(9.27504511649627), np.float64(9.27504511649627), np.float64(9.27504511649627), np.float64(9.276471946606483), np.float64(9.276471946606483), np.float64(9.276998344019429), np.float64(9.278717599610305), np.float64(9.278717599610305), np.float64(9.27961696398949), np.float64(9.280608504375754), np.float64(9.28157914049474), np.float64(9.283276547466361), np.float64(9.285009932900907), np.float64(9.285009932900907), np.float64(9.285009932900907), np.float64(9.285009932900907), np.float64(9.285289960154671), np.float64(9.285289960154671), np.float64(9.285289960154671), np.float64(9.285289960154671), np.float64(9.285306349277763), np.float64(9.285306349277763), np.float64(9.285306349277763), np.float64(9.285306349277763), np.float64(9.285306349277763), np.float64(9.285306349277763), np.float64(9.285306349277763), np.float64(9.285680646554415), np.float64(9.285680646554415), np.float64(9.285680646554415), np.float64(9.286143370098483), np.float64(9.286143370098483), np.float64(9.286143370098483), np.float64(9.286143370098483), np.float64(9.286744179461856), np.float64(9.286744179461856), np.float64(9.286744179461856), np.float64(9.286744179461856), np.float64(9.286744179461856), np.float64(9.286744179461856), np.float64(9.286744179461856), np.float64(9.286744179461856), np.float64(9.286744179461856), np.float64(9.286744179461856), np.float64(9.286744179461856), np.float64(9.286744179461856), np.float64(9.286744179461856), np.float64(9.286785442905742), np.float64(9.286785442905742), np.float64(9.286785442905742), np.float64(9.286785442905742), np.float64(9.288131207562984), np.float64(9.288131207562984), np.float64(9.288131207562984), np.float64(9.288131207562984), np.float64(9.288131207562984), np.float64(9.288131207562984), np.float64(9.288131207562984), np.float64(9.289906717360207), np.float64(9.289906717360207), np.float64(9.289906717360207), np.float64(9.290013515118835), np.float64(9.290013515118835), np.float64(9.29079713773452), np.float64(9.291147765948086), np.float64(9.291147765948086), np.float64(9.291147765948086), np.float64(9.292478998422812), np.float64(9.292478998422812), np.float64(9.29299057036056), np.float64(9.293441530707176), np.float64(9.293441530707176), np.float64(9.293485534555474), np.float64(9.293485534555474), np.float64(9.293485534555474), np.float64(9.293485534555474), np.float64(9.293485534555474), np.float64(9.293855861858859), np.float64(9.293855861858859), np.float64(9.293855861858859), np.float64(9.295077677110598), np.float64(9.295077677110598), np.float64(9.296073116411662), np.float64(9.299143473513535), np.float64(9.299143473513535), np.float64(9.299307093949738), np.float64(9.299551617715464), np.float64(9.299551617715464), np.float64(9.299551617715464), np.float64(9.299551617715464), np.float64(9.299590410697132), np.float64(9.300169330459285), np.float64(9.300169330459285), np.float64(9.300169330459285), np.float64(9.300751626408017), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302298961492099), np.float64(9.302462873937468), np.float64(9.302462873937468), np.float64(9.302486350884463), np.float64(9.302486350884463), np.float64(9.30287202794934), np.float64(9.30287202794934), np.float64(9.30321559007915), np.float64(9.303443999239713), np.float64(9.303443999239713), np.float64(9.303579010774449), np.float64(9.303744438815539), np.float64(9.304278065628584), np.float64(9.304281226605433), np.float64(9.304650645016336), np.float64(9.304650645016336), np.float64(9.305674850899663), np.float64(9.305674850899663), np.float64(9.305674850899663), np.float64(9.305674850899663), np.float64(9.305717009315353), np.float64(9.306170337489712), np.float64(9.306170337489712), np.float64(9.306170337489712), np.float64(9.306170337489712), np.float64(9.306170337489712), np.float64(9.306401516635908), np.float64(9.306401516635908), np.float64(9.306401516635908), np.float64(9.30642737663775), np.float64(9.306439075403183), np.float64(9.306439075403183), np.float64(9.306439075403183), np.float64(9.306439075403183), np.float64(9.306439075403183), np.float64(9.306739731355636), np.float64(9.307458202716955), np.float64(9.307458202716955), np.float64(9.307458202716955), np.float64(9.307458202716955), np.float64(9.307458202716955), np.float64(9.307458202716955), np.float64(9.307458202716955), np.float64(9.307458202716955), np.float64(9.307458202716955), np.float64(9.307578522624105), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308249558956664), np.float64(9.308454891461142), np.float64(9.308454891461142), np.float64(9.308454891461142), np.float64(9.308454891461142), np.float64(9.308454891461142), np.float64(9.308454891461142), np.float64(9.308454891461142), np.float64(9.308454891461142), np.float64(9.308454891461142), np.float64(9.308454891461142), np.float64(9.308454891461142), np.float64(9.308477124623783), np.float64(9.308477124623783), np.float64(9.308477124623783), np.float64(9.308477124623783), np.float64(9.308477124623783), np.float64(9.308477124623783), np.float64(9.308578309613514), np.float64(9.308578309613514), np.float64(9.308578309613514), np.float64(9.308805978574652), np.float64(9.308805978574652), np.float64(9.308805978574652), np.float64(9.308805978574652), np.float64(9.308805978574652), np.float64(9.308805978574652), np.float64(9.308805978574652), np.float64(9.308805978574652), np.float64(9.308805978574652), np.float64(9.308805978574652), np.float64(9.308805978574652), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.30893216793975), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309081795886526), np.float64(9.309134056929738), np.float64(9.309134056929738), np.float64(9.309134056929738), np.float64(9.309134056929738), np.float64(9.309134056929738), np.float64(9.309134056929738), np.float64(9.309134056929738), np.float64(9.309134056929738), np.float64(9.309134056929738), np.float64(9.309134056929738), np.float64(9.309134056929738), np.float64(9.309134056929738), np.float64(9.309134056929738), np.float64(9.309134056929738), np.float64(9.309134056929738), np.float64(9.309134056929738), np.float64(9.309247616257496), np.float64(9.309247616257496), np.float64(9.309247616257496), np.float64(9.309247616257496), np.float64(9.309247616257496), np.float64(9.309247616257496), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.30932424270771), np.float64(9.309345478766508), np.float64(9.309345478766508), np.float64(9.309345478766508), np.float64(9.309345478766508), np.float64(9.309345478766508), np.float64(9.309345478766508), np.float64(9.309345478766508), np.float64(9.309345478766508), np.float64(9.309345478766508), np.float64(9.309345478766508), np.float64(9.309345478766508), np.float64(9.309345478766508), np.float64(9.309345478766508), np.float64(9.309345478766508), np.float64(9.309345478766508), np.float64(9.309345478766508), np.float64(9.309463922566332), np.float64(9.309463922566332), np.float64(9.309463922566332)]\n",
      "Final Secrecy Rate PSO: 9.309463922566332\n"
     ]
    }
   ],
   "source": [
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# PSO Algorithm\n",
    "max_iter = 500\n",
    "num_particles = 100\n",
    "w_min = 0.5\n",
    "w_max = 0.9\n",
    "c1 = 1.5\n",
    "c2 = 1.5\n",
    "\n",
    "PSO_results = PSO_optimize_w_theta(max_iter, num_particles, w_min, w_max, c1, c2)\n",
    "print(\"Initial Secrecy Rate PSO:\", PSO_results[0])\n",
    "print(PSO_results)\n",
    "print(\"Final Secrecy Rate PSO:\", PSO_results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm (GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAIndividual:\n",
    "  def __init__(self, theta: np.ndarray[np.float64] = None, w: np.ndarray[np.complex128] = None) -> None:\n",
    "    if theta is None:\n",
    "      self.theta = generate_random_theta_angles(Nris)\n",
    "    else:\n",
    "      self.theta = theta\n",
    "\n",
    "    if w is None:\n",
    "      self.w = generate_random_beamforming_vectors()\n",
    "    else:\n",
    "      self.w = w\n",
    "\n",
    "    self.update_fitness()\n",
    "\n",
    "  def update_fitness(self):\n",
    "    self.fitness = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.theta), self.w)\n",
    "\n",
    "\n",
    "class GAPopulation:\n",
    "  def __init__(self, population_size: int, crossover_rate: float = 0.85, mutation_rate: float = 0.3) -> None:\n",
    "    self.population_size = population_size\n",
    "    self.individuals = [GAIndividual() for _ in range(population_size)]\n",
    "    self.crossover_rate = crossover_rate\n",
    "    self.mutation_rate = mutation_rate\n",
    "\n",
    "  def sort_population(self):\n",
    "    self.individuals.sort(key=lambda x: x.fitness, reverse=True)\n",
    "\n",
    "  def filter_population(self):\n",
    "    self.sort_population()\n",
    "    self.individuals = self.individuals[:self.population_size]\n",
    "\n",
    "  def add_individual(self, individual: GAIndividual):\n",
    "    self.individuals.append(individual)\n",
    "\n",
    "  def select_parents(self) -> tuple[GAIndividual, GAIndividual]:\n",
    "    parents = np.random.choice(self.individuals, 2, replace=False)\n",
    "    return parents[0], parents[1]\n",
    "  \n",
    "  def crossover(self, parent1: GAIndividual, parent2: GAIndividual) -> GAIndividual:\n",
    "    theta1, w1 = parent1.theta, parent1.w\n",
    "    theta2, w2 = parent2.theta, parent2.w\n",
    "    theta_child = (theta1 + theta2) / 2\n",
    "    w_child = [(w1[i] + w2[i]) / 2 for i in range(number_of_users)]\n",
    "    return GAIndividual(theta_child, w_child)\n",
    "  \n",
    "  def mutate(self, individual: GAIndividual) -> GAIndividual:\n",
    "    if np.random.rand() < self.mutation_rate:\n",
    "      mutation_index = np.random.randint(0, Nris)\n",
    "      individual.theta[0, mutation_index] = np.random.uniform(-np.pi, np.pi)\n",
    "      mutation_index = np.random.randint(len(individual.w))\n",
    "      individual.w[mutation_index] = generate_random_beamforming_vector()\n",
    "      individual.update_fitness()\n",
    "\n",
    "    return individual\n",
    "  \n",
    "def GA_optimize_w_theta(population_size: int, max_iter: int, crossover_rate: float = 0.85, mutation_rate: float = 0.85):\n",
    "  population = GAPopulation(population_size, crossover_rate, mutation_rate)\n",
    "  population.sort_population()\n",
    "  results_secrecy_rate = []\n",
    "  results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "\n",
    "  for _ in range(max_iter):\n",
    "    # Crossover\n",
    "    for _ in range(population_size):\n",
    "      if np.random.rand() < population.crossover_rate:\n",
    "        parent1, parent2 = population.select_parents()\n",
    "        child = population.crossover(parent1, parent2)\n",
    "        population.add_individual(child)\n",
    "\n",
    "    # Mutation\n",
    "    for individual in population.individuals:\n",
    "      population.mutate(individual)\n",
    "\n",
    "    # Filter\n",
    "    population.filter_population()\n",
    "\n",
    "    results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "\n",
    "  return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Secrecy Rate GA: 3.782669340293348\n",
      "[np.float64(3.782669340293348), np.float64(7.579021276782638), np.float64(7.579021276782638), np.float64(7.1426282359163), np.float64(8.045095038583577), np.float64(8.045095038583577), np.float64(8.373352005253087), np.float64(8.373352005253087), np.float64(8.373352005253087), np.float64(8.373352005253087), np.float64(10.61018522535604), np.float64(8.290184339105886), np.float64(8.290184339105886), np.float64(8.652745368366757), np.float64(8.692335711597526), np.float64(9.121916305947643), np.float64(9.16578997555841), np.float64(9.16578997555841), np.float64(9.340788210206556), np.float64(9.927776039099278), np.float64(10.374700912755545), np.float64(10.319153485748146), np.float64(11.431140728809781), np.float64(11.431140728809781), np.float64(11.431140728809781), np.float64(11.431140728809781), np.float64(11.431140728809781), np.float64(10.757606356812504), np.float64(10.827179092310868), np.float64(10.827179092310868), np.float64(10.838254606423913), np.float64(10.827179092310868), np.float64(10.827179092310868), np.float64(12.720780375803521), np.float64(12.720780375803521), np.float64(12.720780375803521), np.float64(14.167619537679766), np.float64(12.442564234780788), np.float64(12.442564234780788), np.float64(12.540840838303298), np.float64(12.540840838303298), np.float64(12.540840838303298), np.float64(11.38730834400742), np.float64(11.292095272236061), np.float64(11.292095272236061), np.float64(11.609691737277588), np.float64(12.28056890980277), np.float64(12.28056890980277), np.float64(12.28056890980277), np.float64(12.28056890980277), np.float64(12.28056890980277), np.float64(12.28056890980277), np.float64(12.28056890980277), np.float64(12.28056890980277), np.float64(12.28056890980277), np.float64(12.259905877172539), np.float64(12.259905877172539), np.float64(12.259905877172539), np.float64(12.259905877172539), np.float64(12.552063620815263), np.float64(12.947516788629013), np.float64(12.26111007819442), np.float64(12.339819917710027), np.float64(12.364536270309456), np.float64(12.39189998499463), np.float64(13.912653818877562), np.float64(13.912653818877562), np.float64(13.423609932401654), np.float64(13.423609932401654), np.float64(12.354578925693389), np.float64(12.354578925693389), np.float64(12.354578925693389), np.float64(12.760140919615964), np.float64(13.533387555914576), np.float64(12.985546754423003), np.float64(12.985546754423003), np.float64(12.985546754423003), np.float64(12.985546754423003), np.float64(12.985546754423003), np.float64(12.985546754423003), np.float64(12.985546754423003), np.float64(12.985546754423003), np.float64(12.959199107294225), np.float64(13.303119676220277), np.float64(13.606720689855585), np.float64(14.05087773526142), np.float64(14.05087773526142), np.float64(14.05087773526142), np.float64(14.05087773526142), np.float64(14.05087773526142), np.float64(14.05087773526142), np.float64(14.706139058219279), np.float64(14.706139058219279), np.float64(14.706139058219279), np.float64(14.706139058219279), np.float64(14.706139058219279), np.float64(14.706139058219279), np.float64(14.706139058219279), np.float64(14.706139058219279), np.float64(14.706139058219279), np.float64(14.706139058219279), np.float64(14.706139058219279), np.float64(14.706139058219279), np.float64(14.706139058219279), np.float64(14.706139058219279), np.float64(14.706139058219279), np.float64(13.860226030700192), np.float64(13.798263502219458), np.float64(13.798263502219458), np.float64(14.533299630699984), np.float64(14.044962399091173), np.float64(14.042589158976178), np.float64(14.042589158976178), np.float64(14.030685331580221), np.float64(14.159146740651542), np.float64(14.159146740651542), np.float64(14.159146740651542), np.float64(13.759563849798873), np.float64(13.74474639185566), np.float64(13.74474639185566), np.float64(13.74474639185566), np.float64(13.74474639185566), np.float64(13.998361889424407), np.float64(13.998361889424407), np.float64(13.998361889424407), np.float64(13.998361889424407), np.float64(14.01531906057302), np.float64(14.01531906057302), np.float64(13.735050806685367), np.float64(13.735050806685367), np.float64(13.734321638082047), np.float64(13.734321638082047), np.float64(13.733593478033868), np.float64(13.733593478033868), np.float64(13.731984011339952), np.float64(13.731984011339952), np.float64(13.731984011339952), np.float64(13.731645802520752), np.float64(13.73148465614755), np.float64(14.97529372377219), np.float64(14.766126717043528), np.float64(14.334531373524522), np.float64(14.334531373524522), np.float64(13.731541771377948), np.float64(13.731541771377948), np.float64(13.731541771377948), np.float64(13.731483391806563), np.float64(13.731483391806563), np.float64(13.73143755472277), np.float64(13.73143755472277), np.float64(13.7928486334383), np.float64(13.7928486334383), np.float64(13.905397467129454), np.float64(13.907350617023623), np.float64(13.90448462746109), np.float64(13.90448462746109), np.float64(14.649629209840953), np.float64(14.649629209840953), np.float64(14.649629209840953), np.float64(14.649629209840953), np.float64(14.649629209840953), np.float64(14.649629209840953), np.float64(14.649629209840953), np.float64(14.649629209840953), np.float64(14.649629209840953), np.float64(13.731388856266898), np.float64(13.73138697582185), np.float64(13.731386748270792), np.float64(13.731386378622535), np.float64(13.731386352494493), np.float64(13.731386216799656), np.float64(13.731386216799656), np.float64(13.731386216799656), np.float64(13.731386216799656), np.float64(13.731385949456735), np.float64(13.731385949456735), np.float64(13.731385949456735), np.float64(13.731385949456735), np.float64(13.731385758559929), np.float64(13.731385749175326), np.float64(13.731385749175326), np.float64(13.731385723884438), np.float64(13.731385723884438), np.float64(13.731385686500655), np.float64(13.731385686500655), np.float64(13.731385686500655), np.float64(13.73138567025105), np.float64(13.73138567025105), np.float64(14.011739335297325), np.float64(14.670649435378284), np.float64(14.670649435378284), np.float64(14.670652715076878), np.float64(14.670652715076878), np.float64(14.670650130023303), np.float64(14.670649842500513), np.float64(14.670649842500513), np.float64(14.670649842500513), np.float64(14.670649842500513), np.float64(14.670649842500513), np.float64(15.274900835886822), np.float64(15.274900835886822), np.float64(14.893768976945992), np.float64(14.670649842500513), np.float64(14.670649842500513), np.float64(14.64810273198471), np.float64(14.64810273198471), np.float64(14.64810273198471), np.float64(14.64810273198471), np.float64(14.64810273198471), np.float64(14.64810273198471), np.float64(14.64810273198471), np.float64(14.64810273198471), np.float64(14.64810273198471), np.float64(14.64810273198471), np.float64(14.6480951121248), np.float64(14.639440244941378), np.float64(14.639440244941378), np.float64(14.637828013407184), np.float64(14.637828013407184), np.float64(14.637828013407184), np.float64(14.637828013407184), np.float64(14.637828013407184), np.float64(14.637828013407184), np.float64(14.637828013407184), np.float64(14.637828013407184), np.float64(14.637828013407184), np.float64(14.637828013407184), np.float64(14.631256382360696), np.float64(14.631256382360696), np.float64(14.631256382360696), np.float64(14.857241119704717), np.float64(15.58593255308028), np.float64(15.58593255308028), np.float64(15.58593255308028), np.float64(15.58593255308028), np.float64(15.419106465489536), np.float64(15.419106465489536), np.float64(15.418272523574784), np.float64(15.418272523574784), np.float64(15.418228967708892), np.float64(15.418228967708892), np.float64(15.418228967708892), np.float64(15.418228967708892), np.float64(15.145745270688831), np.float64(15.145745270688831), np.float64(15.138122933920542), np.float64(15.138122933920542), np.float64(15.138122933920542), np.float64(15.138122933920542), np.float64(15.138122933920542), np.float64(15.138122933920542), np.float64(15.138122933920542), np.float64(15.138122933920542), np.float64(15.102661492547968), np.float64(15.083120301424927), np.float64(15.083120301424927), np.float64(15.083120301424927), np.float64(15.08175846974774), np.float64(15.08175846974774), np.float64(15.08175846974774), np.float64(15.08175846974774), np.float64(15.08175846974774), np.float64(15.08175846974774), np.float64(15.08175846974774), np.float64(15.068637470372513), np.float64(15.068637470372513), np.float64(15.061704697863377), np.float64(15.06164959394448), np.float64(15.06164959394448), np.float64(15.06164959394448), np.float64(15.06164959394448), np.float64(15.06164959394448), np.float64(15.06164959394448), np.float64(15.06164959394448), np.float64(15.06164959394448), np.float64(15.06164959394448), np.float64(15.06164959394448), np.float64(15.129896553777805), np.float64(15.129896553777805), np.float64(15.129896553777805), np.float64(15.058817817544522), np.float64(15.058790807476612), np.float64(15.058790807476612), np.float64(15.058772564593013), np.float64(15.058772564593013), np.float64(15.058772564593013), np.float64(15.058772564593013), np.float64(15.058605616965021), np.float64(15.058597687257146), np.float64(15.05855919395541), np.float64(15.05855919395541), np.float64(15.05855919395541), np.float64(15.05855919395541), np.float64(15.05855919395541), np.float64(15.76349485471702), np.float64(15.058532077446298), np.float64(15.058532077446298), np.float64(15.058532077446298), np.float64(15.058531323934726), np.float64(15.058531323934726), np.float64(15.058524428780439), np.float64(15.058524428780439), np.float64(15.058521534887564), np.float64(15.058520931252032), np.float64(15.058520931252032), np.float64(15.058520931252032), np.float64(15.058520164938408), np.float64(15.058520164938408), np.float64(15.058520164938408), np.float64(15.058519747720922), np.float64(15.058519747720922), np.float64(15.058519747720922), np.float64(15.058519747720922), np.float64(15.744034034770985), np.float64(15.744034034770985), np.float64(15.744034034770985), np.float64(15.744034034770985), np.float64(15.744034034770985), np.float64(15.058519549623504), np.float64(15.058519549623504), np.float64(15.058519549623504), np.float64(15.456288959889804), np.float64(15.96955827645375), np.float64(15.96955827645375), np.float64(15.058519549623504), np.float64(15.058519549623504), np.float64(15.058519549623504), np.float64(15.05851949448832), np.float64(15.058519470257146), np.float64(15.058519465848313), np.float64(15.058519465848313), np.float64(15.058519465848313), np.float64(15.058519464679355), np.float64(15.058519464679355), np.float64(15.058519460432894), np.float64(15.058519460432894), np.float64(15.058519460432894), np.float64(15.058519460432894), np.float64(15.058519460432894), np.float64(15.058519460432894), np.float64(15.058519460432894), np.float64(15.058519459745487), np.float64(15.058519459745487), np.float64(15.058519459745487), np.float64(15.058519459745487), np.float64(15.058519459745487), np.float64(15.058519459745487), np.float64(15.058519459745487), np.float64(15.058519458310807), np.float64(15.058519458310807), np.float64(15.058519457927218), np.float64(15.058519457927218), np.float64(15.058519457927218), np.float64(15.058519457927218), np.float64(15.058519457774352), np.float64(15.058519457774352), np.float64(15.058519457774352), np.float64(15.058519457718251), np.float64(15.058519457680895), np.float64(15.058519457680895), np.float64(15.058519457680895), np.float64(15.058519457672805), np.float64(15.058519457670227), np.float64(15.058519457670227), np.float64(15.058519457668982), np.float64(15.058519457668982), np.float64(15.058519457668982), np.float64(15.058519457668982), np.float64(15.058519457668982), np.float64(15.05851945766631), np.float64(15.058519457664591), np.float64(15.058519457664591), np.float64(15.058519457664591), np.float64(15.058519457662634), np.float64(15.058519457662634), np.float64(15.058519457662634), np.float64(15.058519457662634), np.float64(15.058519457662634), np.float64(15.058519457662634), np.float64(15.058519457662257), np.float64(15.058519457662257), np.float64(15.058519457662257), np.float64(15.058519457661596), np.float64(15.058519457661596), np.float64(15.058519457661577), np.float64(15.058519457661577), np.float64(15.058519457661427), np.float64(15.058519457661427), np.float64(15.058519457661395), np.float64(15.058519457661395), np.float64(15.058519457661395), np.float64(15.058519457661395), np.float64(15.05851945766135), np.float64(15.05851945766135), np.float64(15.058519457661347), np.float64(15.058519457661347), np.float64(15.058519457661347), np.float64(15.058519457661347), np.float64(15.058519457661347), np.float64(15.058519457661347), np.float64(15.058519457661347), np.float64(15.058519457661347), np.float64(15.058519457661347), np.float64(15.058519457661319), np.float64(15.058519457661319), np.float64(15.058519457661319), np.float64(15.058519457661319), np.float64(15.05851945766131), np.float64(15.058519457661307), np.float64(15.058519457661307), np.float64(15.058519457661307), np.float64(15.058519457661307), np.float64(15.058519457661307), np.float64(15.058519457661307), np.float64(15.058519457661307), np.float64(15.280657900255338), np.float64(15.280657900255338), np.float64(15.058519457661307), np.float64(15.058519457661307), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661307), np.float64(15.058519457661307), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.058519457661305), np.float64(15.076673113043382), np.float64(15.076673113043382), np.float64(15.258532615355538), np.float64(15.668245111166993), np.float64(15.60929104922602), np.float64(15.60929104922602), np.float64(15.668245111166993), np.float64(15.668245111166993), np.float64(15.696531753569621), np.float64(15.696531753569621), np.float64(15.697341845793131), np.float64(15.697886588018061), np.float64(15.697886588018061), np.float64(15.697886588018061), np.float64(15.697886588018061), np.float64(15.697059502707091), np.float64(15.698002303383674), np.float64(15.698035233819496), np.float64(15.698035233819496), np.float64(15.698035233819496), np.float64(15.698035233819496), np.float64(15.698035233819496), np.float64(15.698024024959725), np.float64(15.697958427067498), np.float64(15.69803872108647), np.float64(15.697958427067498), np.float64(15.698025792342293), np.float64(15.698025792342293), np.float64(15.698031450179595), np.float64(15.698036616150908), np.float64(15.698036616150908), np.float64(15.698036616150908), np.float64(15.697883887879094), np.float64(15.697883887879094), np.float64(15.697883887879094), np.float64(15.697883887879094), np.float64(16.819940444453753), np.float64(16.819940444453753), np.float64(16.375123507743748), np.float64(16.375123507743748), np.float64(16.375123507743748), np.float64(15.69760220371427)]\n",
      "Final Secrecy Rate GA: 15.69760220371427\n"
     ]
    }
   ],
   "source": [
    "population_size = 100\n",
    "num_generations = 500\n",
    "crossover_rate = 0.85\n",
    "mutation_rate = 0.3\n",
    "\n",
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# GA Algorithm\n",
    "GA_results = GA_optimize_w_theta(population_size, num_generations, crossover_rate, mutation_rate)\n",
    "print(\"Initial Secrecy Rate GA:\", GA_results[0])\n",
    "print(GA_results)\n",
    "print(\"Final Secrecy Rate GA:\", GA_results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of PSO and GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_GD(max_pso_iter, max_gd_iter, number_of_particles, learning_rate, w_max, w_min, c1, c2):\n",
    "    particles = [PSOParticle() for _ in range(number_of_particles)]\n",
    "    global_best_secrecy_rate = -np.inf\n",
    "    global_best_theta = np.zeros((1, Nris))\n",
    "    global_best_w = [np.zeros((N, 1)) for i in range(number_of_users)]\n",
    "\n",
    "    results_secrecy_rate = []\n",
    "\n",
    "    for particle in particles:\n",
    "        if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "            global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "            global_best_theta = deepcopy(particle.best_theta)\n",
    "            global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "    results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "    \n",
    "    for iteration in range(max_pso_iter):\n",
    "        inertia = dynamic_inertia(iteration, max_iter, w_max, w_min)\n",
    "\n",
    "        \"\"\"\n",
    "            Gradient descent for every particles\n",
    "        \"\"\"\n",
    "        for particle in particles:\n",
    "            for _ in range (max_gd_iter):\n",
    "                new_w, new_theta = gradient_descent_update(particle.w, theta_angles_to_theta_vector(particle.theta), learning_rate, original_secrecy_rate=particle.best_secrecy_rate)\n",
    "                particle.w = new_w\n",
    "                particle.theta = theta_vector_to_theta_angles(new_theta)\n",
    "                particle.update_best()\n",
    "\n",
    "            if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "                global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "                global_best_theta = deepcopy(particle.best_theta)\n",
    "                global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "        \"\"\"\n",
    "            Update particles by velocity\n",
    "        \"\"\"\n",
    "        \n",
    "        for particle in particles:\n",
    "            particle.update_velocity(inertia, c1, c2, global_best_theta, global_best_w)\n",
    "            particle.update_position()\n",
    "            particle.update_best()\n",
    "\n",
    "            if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "                global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "                global_best_theta = deepcopy(particle.best_theta)\n",
    "                global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "        results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "\n",
    "    return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "max_pso_iter = 10\n",
    "max_gd_iter = 10\n",
    "number_of_particles = 100\n",
    "w_max = 0.9\n",
    "w_min = 0.5\n",
    "c1 = 1.5\n",
    "c2 = 1.5\n",
    "\n",
    "PSO_GD_results = PSO_GD(max_pso_iter, max_gd_iter, number_of_particles, learning_rate, w_max, w_min, c1, c2)\n",
    "print(\"Initial Secrecy Rate PSO-GD:\", PSO_GD_results[0])\n",
    "print(\"Final Secrecy Rate PSO-GD:\", PSO_GD_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         77062470 function calls (77049422 primitive calls) in 194.620 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   331100   70.494    0.000  174.558    0.001 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\4206688599.py:1(secrecy_rate_objective_function)\n",
      "  2648800   24.073    0.000   24.073    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\4206688599.py:16(<listcomp>)\n",
      "  4093200   18.726    0.000   18.726    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "  4133200   12.941    0.000   18.655    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_twodim_base_impl.py:242(diag)\n",
      "  1324400   12.090    0.000   12.090    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\4206688599.py:8(<listcomp>)\n",
      "  4093200    8.988    0.000   34.863    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:69(_wrapreduction)\n",
      "    10000    8.373    0.001   15.857    0.002 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\703710569.py:1(compute_gradient_w)\n",
      "  4093200    5.291    0.000   40.935    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:2255(sum)\n",
      "  4133200    4.584    0.000    4.584    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "  4173705    4.070    0.000    4.070    0.000 {built-in method numpy.zeros}\n",
      "  4429510    3.914    0.000    3.914    0.000 {built-in method builtins.getattr}\n",
      "  4093200    2.756    0.000    2.756    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:70(<dictcomp>)\n",
      "  1404400    2.210    0.000    2.210    0.000 {built-in method builtins.max}\n",
      "  1324400    1.963    0.000    1.963    0.000 {built-in method builtins.min}\n",
      "    10000    1.300    0.000  170.870    0.017 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\703710569.py:82(compute_gradient_theta)\n",
      "  5333110    1.251    0.000    1.251    0.000 {built-in method builtins.abs}\n",
      "   319976    0.843    0.000    0.843    0.000 {built-in method builtins.sum}\n",
      "  4093202    0.781    0.000    0.781    0.000 {built-in method builtins.isinstance}\n",
      "    80000    0.739    0.000    0.739    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\703710569.py:16(<listcomp>)\n",
      "   119991    0.709    0.000    0.957    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\703710569.py:57(<listcomp>)\n",
      "   119991    0.705    0.000    0.951    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\703710569.py:61(<listcomp>)\n",
      "  4093200    0.689    0.000    0.689    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:2250(_sum_dispatcher)\n",
      "  4153200    0.640    0.000    0.640    0.000 {built-in method numpy.asanyarray}\n",
      "  4133200    0.640    0.000    0.640    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_twodim_base_impl.py:238(_diag_dispatcher)\n",
      "  4133200    0.616    0.000    0.616    0.000 {built-in method builtins.len}\n",
      "   320000    0.556    0.000    1.055    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:66(copy)\n",
      "  4093200    0.553    0.000    0.553    0.000 {method 'items' of 'dict' objects}\n",
      "  3314907    0.541    0.000    0.541    0.000 {method 'append' of 'list' objects}\n",
      "    10000    0.509    0.000  187.857    0.019 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\703710569.py:94(gradient_descent_update)\n",
      "    40000    0.375    0.000    0.375    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\703710569.py:27(<listcomp>)\n",
      "   320000    0.310    0.000    0.310    0.000 {method '__copy__' of 'numpy.ndarray' objects}\n",
      "   319976    0.265    0.000    0.265    0.000 {method 'conj' of 'numpy.ndarray' objects}\n",
      "    44400    0.246    0.000    0.410    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2566(norm)\n",
      "    39997    0.245    0.000    0.333    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\703710569.py:45(<listcomp>)\n",
      "    39997    0.236    0.000    0.319    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\703710569.py:49(<listcomp>)\n",
      "   319976    0.191    0.000    0.455    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\4261464760.py:10(HermTranspose)\n",
      "    21100    0.164    0.000    0.164    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\61964049.py:41(theta_angles_to_theta_vector)\n",
      "    10000    0.137    0.000    0.137    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\703710569.py:97(<listcomp>)\n",
      "    20000    0.132    0.000    0.137    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:1606(angle)\n",
      "    88800    0.105    0.000    0.105    0.000 {method 'dot' of 'numpy.ndarray' objects}\n",
      "        1    0.097    0.097  194.620  194.620 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\2616247581.py:1(PSO_GD)\n",
      "   445110    0.076    0.000    0.076    0.000 {built-in method builtins.issubclass}\n",
      "   359144    0.069    0.000    0.069    0.000 {method 'get' of 'dict' objects}\n",
      "    11000    0.063    0.000    6.270    0.001 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\2974727148.py:25(update_best)\n",
      "19572/6524    0.060    0.000    0.136    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:128(deepcopy)\n",
      "    40000    0.051    0.000    0.051    0.000 {method 'index' of 'list' objects}\n",
      "    10000    0.044    0.000    0.044    0.000 {built-in method numpy.array}\n",
      "     1000    0.035    0.000    0.035    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\2974727148.py:13(<listcomp>)\n",
      "    19572    0.025    0.000    0.030    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:243(_keep_alive)\n",
      "    44400    0.022    0.000    0.022    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "    44400    0.017    0.000    0.022    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:128(isComplexType)\n",
      "     1000    0.015    0.000    0.045    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\2974727148.py:15(update_position)\n",
      "    16310    0.015    0.000    0.015    0.000 {method '__deepcopy__' of 'numpy.ndarray' objects}\n",
      "    10000    0.013    0.000    0.055    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\61964049.py:47(theta_vector_to_theta_angles)\n",
      "     1000    0.013    0.000    0.047    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\2974727148.py:11(update_velocity)\n",
      "     3262    0.011    0.000    0.075    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\copy.py:201(_deepcopy_list)\n",
      "    48930    0.008    0.000    0.008    0.000 {built-in method builtins.id}\n",
      "      400    0.008    0.000    0.008    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\61964049.py:14(generate_random_beamforming_vector)\n",
      "    44400    0.006    0.000    0.006    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2562(_norm_dispatcher)\n",
      "    44400    0.006    0.000    0.006    0.000 {built-in method numpy.asarray}\n",
      "    20000    0.004    0.000    0.004    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:1602(_angle_dispatcher)\n",
      "     1000    0.003    0.000    0.003    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\2974727148.py:17(<listcomp>)\n",
      "      100    0.002    0.000    0.008    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\61964049.py:1(normalise_beamforming_vectors)\n",
      "      100    0.001    0.000    0.156    0.002 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\2974727148.py:2(__init__)\n",
      "      100    0.001    0.000    0.001    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\61964049.py:35(generate_random_theta_angles)\n",
      "      100    0.000    0.000    0.008    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\61964049.py:22(<listcomp>)\n",
      "      100    0.000    0.000    0.016    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\61964049.py:20(generate_random_beamforming_vectors)\n",
      "      100    0.000    0.000    0.001    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\2974727148.py:9(<listcomp>)\n",
      "        1    0.000    0.000    0.157    0.157 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\2616247581.py:2(<listcomp>)\n",
      "       10    0.000    0.000    0.000    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\1667300957.py:1(dynamic_inertia)\n",
      "        2    0.000    0.000    0.000    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py:775(_clean_thread_parent_frames)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:1501(enumerate)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py:790(<setcomp>)\n",
      "        6    0.000    0.000    0.000    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:1168(ident)\n",
      "        1    0.000    0.000    0.000    0.000 c:\\Users\\Long\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\cProfile.py:118(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\Long\\AppData\\Local\\Temp\\ipykernel_44676\\2616247581.py:5(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "max_pso_iter = 10\n",
    "max_gd_iter = 10\n",
    "number_of_particles = 100\n",
    "w_max = 0.9\n",
    "w_min = 0.5\n",
    "c1 = 1.5\n",
    "c2 = 1.5\n",
    "\n",
    "with cProfile.Profile() as pr:\n",
    "  PSO_GD_results = PSO_GD(max_pso_iter, max_gd_iter, number_of_particles, learning_rate, w_max, w_min, c1, c2)\n",
    "\n",
    "stats = pstats.Stats(pr)\n",
    "stats.sort_stats(pstats.SortKey.TIME)\n",
    "stats.print_stats()\n",
    "stats.dump_stats(\"./PSO_GD_new.prof\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, num_cycles\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Plotting the data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# plt.plot(iterations, GD_results, label='Gradient Descent')\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(iterations, \u001b[43mGD_results\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGradient Descent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(iterations, PSO_results, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPSO\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(iterations, GA_results, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenetic Algorithm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "iterations = range(0, num_cycles+10, 10)\n",
    "\n",
    "# Plotting the data\n",
    "# plt.plot(iterations, GD_results, label='Gradient Descent')\n",
    "plt.plot(iterations, GD_results[:, 0], label='Gradient Descent')\n",
    "plt.plot(iterations, PSO_results, label='PSO')\n",
    "plt.plot(iterations, GA_results, label='Genetic Algorithm')\n",
    "plt.plot(iterations, PSO_GD_results, label='PSO-GD')\n",
    "\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Secrecy rate (bps/Hz)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Secrecy Rate GD: [24.6548294]\n",
      "Best Secrecy Rate PSO: [11.27448635]\n",
      "Best Secrecy Rate GA: [17.00556469]\n",
      "Best Secrecy Rate PSO-GD: [25.62364522]\n"
     ]
    }
   ],
   "source": [
    "# Best results of each methods\n",
    "print(\"Best Secrecy Rate GD:\", max(GD_results))\n",
    "print(\"Best Secrecy Rate PSO:\", max(PSO_results))\n",
    "print(\"Best Secrecy Rate GA:\", max(GA_results))\n",
    "print(\"Best Secrecy Rate PSO-GD:\", max(PSO_GD_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy, copy\n",
    "import functools\n",
    "import os\n",
    "import cProfile\n",
    "import pstats\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 4\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transfer from dBW to W (power)\n",
    "def db2pow(db: float) -> float:\n",
    "    return 10**(db/10)\n",
    "\n",
    "# Function to transfer from W to dBW (power)\n",
    "def pow2db(pow: float) -> float:\n",
    "    return 10*np.log10(pow)\n",
    "\n",
    "# Hermitian transpose of a matrix\n",
    "def HermTranspose(x: np.ndarray) -> np.ndarray:\n",
    "    return x.conj().T\n",
    "\n",
    "def chanGen(zeta: float, d: float, dim1: int, dim2: int) -> np.ndarray:\n",
    "    \"\"\"Function to generate Rayleigh fading channel coefficients\n",
    "\n",
    "    Args:\n",
    "        zeta: Î¾ is the path loss exponent\n",
    "        d: the distance between the transmitter and the receiver\n",
    "        dim1: the number of rows in the channel matrix\n",
    "        dim2: the number of columns in the channel matrix\n",
    "    \"\"\"\n",
    "    pl_ref: float = -30                                    # pathloss (dBW) at reference distance\n",
    "    pl: float = db2pow(pl_ref - 10*zeta*np.log10(d))       # pathloss model at distance d\n",
    "    y: np.ndarray = np.sqrt(0.5*pl)*(np.random.randn(dim1,dim2)\\\n",
    "        + 1j*np.random.randn(dim1,dim2))            # Rayleigh distribution\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input data & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = db2pow(-75)                                                                 # noise power\n",
    "N = 10                                                                              # number of transmit antennas\n",
    "gamma = 0.8 # Lower bound for user's link quality\n",
    "pmax = 1000  # Maximum transmit power of Alice\n",
    "\n",
    "# Channel generation\n",
    "def read_generate_channel() -> tuple:\n",
    "    filepath = './data/general/'\n",
    "    Hai = np.load(filepath + 'Hai.npy')\n",
    "    hib = np.load(filepath + 'hib.npy')\n",
    "    hab = np.load(filepath + 'hab.npy')\n",
    "    hie = np.load(filepath + 'hie.npy')\n",
    "    hae = np.load(filepath + 'hae.npy')\n",
    "    return Hai, hib, hie, hab, hae\n",
    "\n",
    "def read_fixed_eaves(num_of_users, num_of_eavesdroppers) -> tuple:\n",
    "    filepath = f'./data/fixed_eaves/data_{num_of_users}users_{num_of_eavesdroppers}eaves/'\n",
    "    Hai = np.load(filepath + 'Hai.npy')\n",
    "    hib = np.load(filepath + 'hib.npy')\n",
    "    hab = np.load(filepath + 'hab.npy')\n",
    "    hie = np.load(filepath + 'hie.npy')\n",
    "    hae = np.load(filepath + 'hae.npy')\n",
    "    return Hai, hib, hie, hab, hae\n",
    "\n",
    "def read_fixed_users(num_of_users, num_of_eavesdroppers) -> tuple:\n",
    "    filepath = f'./data/fixed_users/data_{num_of_users}users_{num_of_eavesdroppers}eaves/'\n",
    "    Hai = np.load(filepath + 'Hai.npy')\n",
    "    hib = np.load(filepath + 'hib.npy')\n",
    "    hab = np.load(filepath + 'hab.npy')\n",
    "    hie = np.load(filepath + 'hie.npy')\n",
    "    hae = np.load(filepath + 'hae.npy')\n",
    "    return Hai, hib, hie, hab, hae\n",
    "\n",
    "#Hai: Channel between Alice and RIS: Nris x N  \n",
    "#hib: Channel between RIS and users: List of length number_of_users, elements are 1 x Nris\n",
    "#hab: Channel between Alice and users: List of length number_of_users, elements are 1 x N\n",
    "#hie: Channel between RIS and eavesdroppers: List of length number_of_eavesdroppers, elements are 1 x Nris\n",
    "#hae: Channel between Alice and eavesdroppers: List of length number_of_eavesdroppers, elements are 1 x N\n",
    "\n",
    "Hai, hib, hie, hab, hae = read_generate_channel()\n",
    "\n",
    "Nris = Hai.shape[0]                                                                       \n",
    "number_of_users = len(hib)\n",
    "number_of_eavesdroppers = len(hie)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beamforming vectors and RIS functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_beamforming_vectors(w: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Function to normalise the beamforming vectors\n",
    "\n",
    "    Args:\n",
    "        w: the beamforming vectors\n",
    "    \"\"\"\n",
    "    total_norm_squared = 0\n",
    "    for i in range(number_of_users):\n",
    "        total_norm_squared += (np.linalg.norm(w[i]) ** 2)\n",
    "    if total_norm_squared <= pmax:\n",
    "        return w\n",
    "    for i in range(number_of_users):\n",
    "        w[i] = w[i] / (total_norm_squared ** 0.5) * np.sqrt(pmax)\n",
    "    return w\n",
    "\n",
    "def generate_random_beamforming_vector():\n",
    "  '''\n",
    "  Generate one random beamforming vector\n",
    "  '''\n",
    "  return np.random.uniform(-1, 1, (N, 1)) + 1j * np.random.uniform(-1, 1, (N, 1))\n",
    "\n",
    "def generate_random_beamforming_vectors():\n",
    "    # Generate random complex numbers for each element of the beamforming vector\n",
    "    beamforming_vectors = [generate_random_beamforming_vector() for _ in range (number_of_users)]\n",
    "    \n",
    "    # Normalize the vectors\n",
    "    beamforming_vectors = normalise_beamforming_vectors(beamforming_vectors)\n",
    "    return beamforming_vectors\n",
    "    #w: list of beamforming vectors, length = number of users, elements are N x 1\n",
    "\n",
    "def generate_random_theta():\n",
    "    theta = np.random.uniform(-np.pi, np.pi, (1, Nris))\n",
    "    theta = np.exp(1j * theta)\n",
    "    return theta\n",
    "    #theta: phase shift of RIS, size 1 x Nris\n",
    "\n",
    "def generate_random_theta_angles(size: int):\n",
    "  \"\"\"\n",
    "    Generate a random vector of angles from -pi to pi\n",
    "  \"\"\"\n",
    "  return np.random.uniform(-np.pi, np.pi, size=(1, size))\n",
    "\n",
    "def theta_angles_to_theta_vector(angles: np.ndarray[np.float64]) -> np.ndarray[np.complex128]:\n",
    "  \"\"\"\n",
    "    Convert a vector of angles to a vector of complex numbers on the unit circle\n",
    "  \"\"\"\n",
    "  return np.exp(1j * angles)\n",
    "\n",
    "def theta_vector_to_theta_angles(theta: np.ndarray[np.complex128]) -> np.ndarray[np.float64]:\n",
    "  \"\"\"\n",
    "    Convert a vector of complex numbers on the unit circle to a vector of angles\n",
    "  \"\"\"\n",
    "  return np.angle(theta)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secrecy_rate_objective_function(theta, w) -> float:\n",
    "    secrecy_rate: float = 0\n",
    "    for k in range(number_of_users):\n",
    "        R_bk = []\n",
    "        # Legitimate user k\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        C_bk = np.log2(1 + gamma_bk)\n",
    "        \n",
    "        for m in range(number_of_eavesdroppers):\n",
    "            # Eavesdropper i\n",
    "            Z_em = hie[m] @ np.diag(theta.flatten()) @ Hai + hae[m]\n",
    "            numGamma_em = np.abs(Z_em @ w[k])**2\n",
    "            denGamma_em = 1 + np.sum([np.abs(Z_em @ w[j])**2 for j in range(number_of_users) if j != k])\n",
    "            gamma_em = numGamma_em/denGamma_em\n",
    "            C_em = np.log2(1 + gamma_em)\n",
    "            R_bk.append(C_bk - C_em)\n",
    "        \n",
    "        secrecy_rate += max(min(R_bk),0)\n",
    "\n",
    "    # Return the only element in the matrix as it is currently a 1x1 np array\n",
    "    return secrecy_rate[0, 0]\n",
    "\n",
    "# Check if the current set up is valid (every users' C_bk >= gamma)\n",
    "# Returns the index of the invalid user whose C_bk is highest among the invalid or -1 if all users are valid\n",
    "def check_validity(theta, w) -> int:\n",
    "    user = -1\n",
    "    maxx = 0\n",
    "    for k in range(number_of_users):\n",
    "        # Legitimate user k\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        C_bk = np.log2(1 + gamma_bk)\n",
    "        \n",
    "        if (C_bk < gamma):\n",
    "            if C_bk > maxx:\n",
    "                maxx = C_bk\n",
    "                user = k\n",
    "    return user\n",
    "\n",
    "# Print the C_bk of each user\n",
    "def print_users_Cbk(theta, w) -> None:\n",
    "    for k in range(number_of_users):\n",
    "        # Legitimate user k\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        C_bk = np.log2(1 + gamma_bk)\n",
    "        print(float(C_bk), end = \" \")\n",
    "    print()\n",
    "\n",
    "# Calculate the C_bk of a user\n",
    "def calculate_user_Cbk(theta, w, user) -> float:\n",
    "    Z_bk = hib[user] @ np.diag(theta.flatten()) @ Hai + hab[user]\n",
    "    numGamma_bk = np.abs(Z_bk @ w[user])**2\n",
    "    denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != user])\n",
    "    gamma_bk = numGamma_bk/denGamma_bk\n",
    "    C_bk = np.log2(1 + gamma_bk)\n",
    "    return C_bk\n",
    "\n",
    "# Using gradient descent to repair the beamforming vector of a user\n",
    "# Try to make that user's C_bk >= gamma\n",
    "def repair_beamforming_vectors(theta, w, user, learning_rate = 0.01, max_iter = 500):\n",
    "    #print(\"Initial norm of user beamforming vector: \", np.linalg.norm(w[user]))\n",
    "    #print(\"Before update beamforming of user \", user, \": \")\n",
    "    #print_users_Cbk(theta, w)\n",
    "    while (calculate_user_Cbk(theta, w, user) < gamma + 0.2 and max_iter > 0):\n",
    "        Z_bk = hib[user] @ np.diag(theta.flatten()) @ Hai + hab[user]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[user])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != user])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "        \n",
    "        num_grad_C_bk_to_w_k = 2 * (HermTranspose(Z_bk) @ Z_bk @ w[user])\n",
    "        den_grad_C_bk_to_w_k = (1 + gamma_bk) * np.log(2) * (1 + sum([abs(Z_bk @ w[j]) for j in range (number_of_users) if j != user]))\n",
    "        grad_C_bk_to_w_k = num_grad_C_bk_to_w_k / den_grad_C_bk_to_w_k\n",
    "        w[user] = w[user] + learning_rate * grad_C_bk_to_w_k\n",
    "        #w[user] *= 2\n",
    "        max_iter -= 1\n",
    "\n",
    "        w = normalise_beamforming_vectors(w)\n",
    "    #print(\"New norm of user beamforming vector: \", np.linalg.norm(w[user]))\n",
    "    #print(\"After update beamforming of user \", user, \": \")\n",
    "    #print_users_Cbk(theta, w)\n",
    "    return w\n",
    "\n",
    "# Using gradient descent to repair the whole (theta, w) set up\n",
    "def repair(theta, w, iter = 100):\n",
    "    invalid_user = check_validity(theta, w)\n",
    "    while (invalid_user != -1 and iter > 0):\n",
    "        w = repair_beamforming_vectors(theta, w, invalid_user)\n",
    "        invalid_user = check_validity(theta, w)\n",
    "        iter -= 1\n",
    "    if (invalid_user != -1):\n",
    "        theta, w = generate_random_theta(), generate_random_beamforming_vectors()\n",
    "        return repair(theta, w)\n",
    "    return theta, w\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent for Maximization (GD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_w(theta, w):\n",
    "    grad_w = []\n",
    "    Z_e_max = [] #Z_e_max[k] = Z_e_max for user k\n",
    "    gamma_e_max = [] #gamma_e_max[k] = gamma_e_max for user k\n",
    "    Z_b = [] #Z_b[k] = Z_bk\n",
    "    gamma_b = [] #gamma_b[k] = gamma_bk\n",
    "    counted = [] #counted[k] = true if gamma_k > gamma_e_max[k]\n",
    "    \n",
    "    #Precalculation \n",
    "    for k in range(number_of_users):\n",
    "        gamma_e = []\n",
    "        for m in range (number_of_eavesdroppers):\n",
    "            Z_em = hie[m] @ np.diag(theta.flatten()) @ Hai + hae[m]\n",
    "            numGamma_em = np.abs(Z_em @ w[k])**2\n",
    "            denGamma_em = 1 + np.sum([np.abs(Z_em @ w[j])**2 for j in range(number_of_users) if j != k])\n",
    "            gamma_em = numGamma_em/denGamma_em\n",
    "            gamma_e.append(gamma_em)\n",
    "        \n",
    "        gamma_e_max.append(max(gamma_e))\n",
    "        index_e_max = gamma_e.index(max(gamma_e))\n",
    "        Z_e = hie[index_e_max] @ np.diag(theta.flatten()) @ Hai + hae[index_e_max]\n",
    "        Z_e_max.append(Z_e)\n",
    "\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "\n",
    "        Z_b.append(Z_bk)\n",
    "        gamma_b.append(gamma_bk)\n",
    "\n",
    "        counted.append(gamma_bk > gamma_e[index_e_max])\n",
    "\n",
    "\n",
    "    #Calculating grad for i-th beamforming vector\n",
    "    for i in range(number_of_users):\n",
    "        grad = np.zeros((N, 1))\n",
    "        for k in range (number_of_users):\n",
    "            if (counted[k] == False):\n",
    "                continue\n",
    "            if (k == i):\n",
    "                num_grad_C_bk_to_w_k = 2 * (HermTranspose(Z_b[k]) @ Z_b[k] @ w[k])\n",
    "                den_grad_C_bk_to_w_k = (1 + gamma_b[k]) * np.log(2) * (1 + sum([abs(Z_b[k] @ w[j]) for j in range (number_of_users) if j != k]))\n",
    "                grad_C_bk_to_w_k = num_grad_C_bk_to_w_k / den_grad_C_bk_to_w_k\n",
    "\n",
    "                num_grad_C_e_max_to_w_k = 2 * (HermTranspose(Z_e_max[k]) @ Z_e_max[k] @ w[k])\n",
    "                den_grad_C_e_max_to_w_k = (1 + gamma_e_max[k]) * np.log(2) * (1 + sum([abs(Z_e_max[k] @ w[j]) for j in range (number_of_users) if j != k]))\n",
    "                grad_C_e_max_to_w_k = num_grad_C_e_max_to_w_k / den_grad_C_e_max_to_w_k\n",
    "                \n",
    "                grad = grad - (grad_C_bk_to_w_k - grad_C_e_max_to_w_k)\n",
    "            else:\n",
    "                num_grad_C_bk_to_w_i = -2 * abs(Z_b[k] @ w[k]) * (HermTranspose(Z_b[k]) @ Z_b[k] @ w[i])\n",
    "                den_grad_C_bk_to_w_i = (1 + gamma_b[k]) * np.log(2) * (1 + sum([abs(Z_b[k] @ w[j]) for j in range (number_of_users) if j != k])) ** 2\n",
    "                grad_C_bk_to_w_i = num_grad_C_bk_to_w_i / den_grad_C_bk_to_w_i\n",
    "\n",
    "                num_grad_C_e_max_to_w_i = -2 * abs(Z_e_max[k] @ w[k]) * (HermTranspose(Z_e_max[k]) @ Z_e_max[k] @ w[i])\n",
    "                den_grad_C_e_max_to_w_i = (1 + gamma_e_max[k]) * np.log(2) * (1 + sum([abs(Z_e_max[k] @ w[j]) for j in range (number_of_users) if j != k])) ** 2\n",
    "                grad_C_e_max_to_w_i = num_grad_C_e_max_to_w_i / den_grad_C_e_max_to_w_i\n",
    "\n",
    "                grad = grad - (grad_C_bk_to_w_i - grad_C_e_max_to_w_i)\n",
    "            \n",
    "        grad_w.append(grad)\n",
    "    return grad_w\n",
    "\n",
    "def compute_gradient_theta_central(theta, w, epsilon=1e-3):\n",
    "    perturbation = epsilon #+ epsilon * 1j\n",
    "    grad_theta = []\n",
    "    for i in range(Nris):\n",
    "        theta_plus = copy(theta)\n",
    "        theta_plus[0, i] += perturbation\n",
    "        theta_minus = copy(theta)\n",
    "        theta_minus[0, i] -= perturbation\n",
    "        grad_theta_i = (secrecy_rate_objective_function(theta_plus, w) - secrecy_rate_objective_function(theta_minus, w)) / (2*epsilon)\n",
    "        grad_theta.append(grad_theta_i)\n",
    "            \n",
    "    return np.array(grad_theta)\n",
    "\n",
    "def compute_gradient_theta_forward(theta, w, original_secrecy_rate=None, epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Faster implementation of the gradient calculation\n",
    "\n",
    "    Improvements:\n",
    "    - Use forward difference instead of central difference\n",
    "    \"\"\"\n",
    "    perturbation = epsilon + epsilon * 1j\n",
    "    grad_theta = []\n",
    "    for i in range(Nris):\n",
    "        theta_plus = copy(theta)\n",
    "        theta_plus[0, i] += perturbation\n",
    "        grad_theta_i = (secrecy_rate_objective_function(theta_plus, w) - original_secrecy_rate) / epsilon\n",
    "        grad_theta.append(grad_theta_i)\n",
    "\n",
    "    return np.array(grad_theta)\n",
    "\n",
    "def compute_gradient_theta(theta, w):\n",
    "    Z_e_max = [] #Z_e_max[k] = Z_e_max for user k\n",
    "    gamma_e_max = [] #gamma_e_max[k] = gamma_e_max for user k\n",
    "    Z_b = [] #Z_b[k] = Z_bk\n",
    "    gamma_b = [] #gamma_b[k] = gamma_bk\n",
    "    counted = [] #counted[k] = true if gamma_k > gamma_e_max[k]\n",
    "    index_e_max_list = []\n",
    "    #Precalculation\n",
    "    for k in range(number_of_users):\n",
    "        gamma_e = []\n",
    "        for m in range (number_of_eavesdroppers):\n",
    "            Z_em = hie[m] @ np.diag(theta.flatten()) @ Hai + hae[m]\n",
    "            numGamma_em = np.abs(Z_em @ w[k])**2\n",
    "            denGamma_em = 1 + np.sum([np.abs(Z_em @ w[j])**2 for j in range(number_of_users) if j != k])\n",
    "            gamma_em = numGamma_em/denGamma_em\n",
    "            gamma_e.append(gamma_em)\n",
    "        \n",
    "        gamma_e_max.append(max(gamma_e))\n",
    "        index_e_max = gamma_e.index(max(gamma_e))\n",
    "        index_e_max_list.append(index_e_max)\n",
    "        Z_e = hie[index_e_max] @ np.diag(theta.flatten()) @ Hai + hae[index_e_max]\n",
    "        Z_e_max.append(Z_e)\n",
    "\n",
    "        Z_bk = hib[k] @ np.diag(theta.flatten()) @ Hai + hab[k]\n",
    "        numGamma_bk = np.abs(Z_bk @ w[k])**2\n",
    "        denGamma_bk = 1 + np.sum([np.abs(Z_bk @ w[i])**2 for i in range(number_of_users) if i != k])\n",
    "        gamma_bk = numGamma_bk/denGamma_bk\n",
    "\n",
    "        Z_b.append(Z_bk)\n",
    "        gamma_b.append(gamma_bk)\n",
    "\n",
    "        counted.append(gamma_bk > gamma_e[index_e_max])\n",
    "\n",
    "\n",
    "    grad_theta = 0\n",
    "\n",
    "\n",
    "    for k in range(number_of_users):\n",
    "        if (counted[k] == False):\n",
    "            continue\n",
    "\n",
    "        grad_Z_bk_wk_to_theta = (1/sigma) * np.diag(hib[k].flatten()) @ Hai @ w[k]\n",
    "        grad_gamma_bk_to_theta_first_term = (2 * (Z_b[k] @ w[k]) * grad_Z_bk_wk_to_theta) * (1 + sum([np.linalg.norm(Z_b[k] @ w[j])**2 for j in range (number_of_users) if j != k]))\n",
    "        grad_gamma_bk_to_theta_second_term = sum([2 * (Z_b[k] @ w[j]) * grad_Z_bk_wk_to_theta for j in range(number_of_users) if j != k]) * (np.linalg.norm(Z_b[k] @ w[k]) ** 2)\n",
    "        grad_gamma_bk_to_theta_third_term = (1 + sum([np.linalg.norm(Z_b[k] @ w[j]) for j in range (number_of_users) if j != k])**2) ** 2\n",
    "        grad_gamma_bk_to_theta = (grad_gamma_bk_to_theta_first_term - grad_gamma_bk_to_theta_second_term) / grad_gamma_bk_to_theta_third_term\n",
    "\n",
    "        grad_C_bk_to_theta = 1 / ((1 + gamma_b[k]) * np.log(2)) * grad_gamma_bk_to_theta\n",
    "\n",
    "        grad_Z_emax_wk_to_theta = (1/sigma) * np.diag(hie[index_e_max_list[k]].flatten()) @ Hai @ w[k]\n",
    "\n",
    "        grad_gamma_emax_to_theta_first_term = (2 * (Z_e_max[k] @ w[k]) * grad_Z_emax_wk_to_theta) * (1 + sum([np.linalg.norm(Z_e_max[k] @ w[j])**2 for j in range (number_of_users) if j != k]))\n",
    "        grad_gamma_emax_to_theta_second_term = sum([2 * (Z_e_max[k] @ w[j]) * grad_Z_emax_wk_to_theta for j in range(number_of_users) if j != k]) * (np.linalg.norm(Z_e_max[k] @ w[k]) ** 2)\n",
    "        grad_gamma_emax_to_theta_third_term = (1 + sum([np.linalg.norm(Z_e_max[k] @ w[j]) for j in range (number_of_users) if j != k])**2) ** 2\n",
    "        grad_gamma_emax_to_theta = (grad_gamma_emax_to_theta_first_term - grad_gamma_emax_to_theta_second_term) / grad_gamma_emax_to_theta_third_term\n",
    "\n",
    "        grad_C_emax_to_theta = 1 / ((1 + gamma_e_max[k]) * np.log(2)) * grad_gamma_emax_to_theta\n",
    "\n",
    "        grad_theta -= (grad_C_bk_to_theta - grad_C_emax_to_theta)\n",
    "    \n",
    "    return np.array(grad_theta).reshape((1, Nris))\n",
    "    \n",
    "\n",
    "\n",
    "def gradient_descent_update(w, theta, learning_rate, original_secrecy_rate=None):\n",
    "    grad_w = compute_gradient_w(theta, w)\n",
    "    grad_theta = compute_gradient_theta(theta, w)\n",
    "    w_new = [w[i] - learning_rate * grad_w[i] for i in range (number_of_users)]\n",
    "    w_new = normalise_beamforming_vectors(w_new)\n",
    "        \n",
    "    theta_new = theta - learning_rate * grad_theta\n",
    "    theta_new = np.exp(1j * np.angle(theta_new))\n",
    "\n",
    "    return w_new, theta_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Secrecy Rate GD: 8.462072947731604\n",
      "Iteration 0\n",
      "Secrecy Rate: 8.462072947731604\n",
      "Iteration 1\n",
      "Secrecy Rate: 8.573155494043856\n",
      "Iteration 2\n",
      "Secrecy Rate: 8.694068834790068\n",
      "Iteration 3\n",
      "Secrecy Rate: 8.791556180035123\n",
      "Iteration 4\n",
      "Secrecy Rate: 8.905042192946965\n",
      "Iteration 5\n",
      "Secrecy Rate: 8.997475071661812\n",
      "Iteration 6\n",
      "Secrecy Rate: 9.0957755040826\n",
      "Iteration 7\n",
      "Secrecy Rate: 9.190328517417903\n",
      "Iteration 8\n",
      "Secrecy Rate: 9.28392937108024\n",
      "Iteration 9\n",
      "Secrecy Rate: 9.372079536709194\n",
      "Iteration 10\n",
      "Secrecy Rate: 9.459092018993513\n",
      "Iteration 11\n",
      "Secrecy Rate: 9.54340326635763\n",
      "Iteration 12\n",
      "Secrecy Rate: 9.624937591616495\n",
      "Iteration 13\n",
      "Secrecy Rate: 9.703976377920773\n",
      "Iteration 14\n",
      "Secrecy Rate: 9.780723195137062\n",
      "Iteration 15\n",
      "Secrecy Rate: 9.855290442632903\n",
      "Iteration 16\n",
      "Secrecy Rate: 9.927762837012807\n",
      "Iteration 17\n",
      "Secrecy Rate: 9.998215537675014\n",
      "Iteration 18\n",
      "Secrecy Rate: 10.066719534138562\n",
      "Iteration 19\n",
      "Secrecy Rate: 10.133343197404578\n",
      "Iteration 20\n",
      "Secrecy Rate: 10.198152008777544\n",
      "Iteration 21\n",
      "Secrecy Rate: 10.261207951759477\n",
      "Iteration 22\n",
      "Secrecy Rate: 10.322569588714693\n",
      "Iteration 23\n",
      "Secrecy Rate: 10.382292788103442\n",
      "Iteration 24\n",
      "Secrecy Rate: 10.440432126957592\n",
      "Iteration 25\n",
      "Secrecy Rate: 10.497026367750102\n",
      "Iteration 26\n",
      "Secrecy Rate: 10.548204329929774\n",
      "Iteration 27\n",
      "Secrecy Rate: 10.602134135330445\n",
      "Iteration 28\n",
      "Secrecy Rate: 10.654261949946966\n",
      "Iteration 29\n",
      "Secrecy Rate: 10.705005609433112\n",
      "Iteration 30\n",
      "Secrecy Rate: 10.754440181713148\n",
      "Iteration 31\n",
      "Secrecy Rate: 10.802591729662478\n",
      "Iteration 32\n",
      "Secrecy Rate: 10.849498999025384\n",
      "Iteration 33\n",
      "Secrecy Rate: 10.895200510673435\n",
      "Iteration 34\n",
      "Secrecy Rate: 10.939733941712765\n",
      "Iteration 35\n",
      "Secrecy Rate: 10.9831359726541\n",
      "Iteration 36\n",
      "Secrecy Rate: 11.025442308099784\n",
      "Iteration 37\n",
      "Secrecy Rate: 11.066687759091023\n",
      "Iteration 38\n",
      "Secrecy Rate: 11.106906360917387\n",
      "Iteration 39\n",
      "Secrecy Rate: 11.146131522417678\n",
      "Iteration 40\n",
      "Secrecy Rate: 11.184396205469074\n",
      "Iteration 41\n",
      "Secrecy Rate: 11.221733132760741\n",
      "Iteration 42\n",
      "Secrecy Rate: 11.258175018540015\n",
      "Iteration 43\n",
      "Secrecy Rate: 11.2937548079945\n",
      "Iteration 44\n",
      "Secrecy Rate: 11.32850589144175\n",
      "Iteration 45\n",
      "Secrecy Rate: 11.362462222174122\n",
      "Iteration 46\n",
      "Secrecy Rate: 11.395658201890958\n",
      "Iteration 47\n",
      "Secrecy Rate: 11.428128096785802\n",
      "Iteration 48\n",
      "Secrecy Rate: 11.459784993357902\n",
      "Iteration 49\n",
      "Secrecy Rate: 11.493161344396894\n",
      "Iteration 50\n",
      "Secrecy Rate: 11.521397212092575\n",
      "Iteration 51\n",
      "Secrecy Rate: 11.551374224181114\n",
      "Iteration 52\n",
      "Secrecy Rate: 11.580591347730783\n",
      "Iteration 53\n",
      "Secrecy Rate: 11.608191729713255\n",
      "Iteration 54\n",
      "Secrecy Rate: 11.636009324072015\n",
      "Iteration 55\n",
      "Secrecy Rate: 11.661863940154499\n",
      "Iteration 56\n",
      "Secrecy Rate: 11.688871351452143\n",
      "Iteration 57\n",
      "Secrecy Rate: 11.714671799417133\n",
      "Iteration 58\n",
      "Secrecy Rate: 11.737567963260831\n",
      "Iteration 59\n",
      "Secrecy Rate: 11.763754284834292\n",
      "Iteration 60\n",
      "Secrecy Rate: 11.787781808421805\n",
      "Iteration 61\n",
      "Secrecy Rate: 11.808151158913931\n",
      "Iteration 62\n",
      "Secrecy Rate: 11.833298359640441\n",
      "Iteration 63\n",
      "Secrecy Rate: 11.855438585920625\n",
      "Iteration 64\n",
      "Secrecy Rate: 11.877152115752647\n",
      "Iteration 65\n",
      "Secrecy Rate: 11.898094936676063\n",
      "Iteration 66\n",
      "Secrecy Rate: 11.918530672193903\n",
      "Iteration 67\n",
      "Secrecy Rate: 11.93850674921721\n",
      "Iteration 68\n",
      "Secrecy Rate: 11.958031335014942\n",
      "Iteration 69\n",
      "Secrecy Rate: 11.977113599062553\n",
      "Iteration 70\n",
      "Secrecy Rate: 11.995765330348082\n",
      "Iteration 71\n",
      "Secrecy Rate: 12.01399843732378\n",
      "Iteration 72\n",
      "Secrecy Rate: 12.03182443954202\n",
      "Iteration 73\n",
      "Secrecy Rate: 12.049254475326032\n",
      "Iteration 74\n",
      "Secrecy Rate: 12.066299363601946\n",
      "Iteration 75\n",
      "Secrecy Rate: 12.082969656364426\n",
      "Iteration 76\n",
      "Secrecy Rate: 12.099275691268648\n",
      "Iteration 77\n",
      "Secrecy Rate: 12.115227653741732\n",
      "Iteration 78\n",
      "Secrecy Rate: 12.13083565742958\n",
      "Iteration 79\n",
      "Secrecy Rate: 12.146109855638418\n",
      "Iteration 80\n",
      "Secrecy Rate: 12.161060604580141\n",
      "Iteration 81\n",
      "Secrecy Rate: 12.175698714166241\n",
      "Iteration 82\n",
      "Secrecy Rate: 12.190035849908586\n",
      "Iteration 83\n",
      "Secrecy Rate: 12.204085202592138\n",
      "Iteration 84\n",
      "Secrecy Rate: 12.217862645886319\n",
      "Iteration 85\n",
      "Secrecy Rate: 12.231388805130209\n",
      "Iteration 86\n",
      "Secrecy Rate: 12.244692846430336\n",
      "Iteration 87\n",
      "Secrecy Rate: 12.257819421100482\n",
      "Iteration 88\n",
      "Secrecy Rate: 12.270840532378164\n",
      "Iteration 89\n",
      "Secrecy Rate: 12.283869814539488\n",
      "Iteration 90\n",
      "Secrecy Rate: 12.297048459610686\n",
      "Iteration 91\n",
      "Secrecy Rate: 12.310394110878454\n",
      "Iteration 92\n",
      "Secrecy Rate: 12.32349994454949\n",
      "Iteration 93\n",
      "Secrecy Rate: 12.335739658200163\n",
      "Iteration 94\n",
      "Secrecy Rate: 12.347046770928255\n",
      "Iteration 95\n",
      "Secrecy Rate: 12.357593343888531\n",
      "Iteration 96\n",
      "Secrecy Rate: 12.373951689660656\n",
      "Iteration 97\n",
      "Secrecy Rate: 12.384097526693145\n",
      "Iteration 98\n",
      "Secrecy Rate: 12.393061619172197\n",
      "Iteration 99\n",
      "Secrecy Rate: 12.401878115992313\n",
      "Iteration 100\n",
      "Secrecy Rate: 12.410503539867872\n",
      "Iteration 101\n",
      "Secrecy Rate: 12.418937435679709\n",
      "Iteration 102\n",
      "Secrecy Rate: 12.427184755737594\n",
      "Iteration 103\n",
      "Secrecy Rate: 12.435250045680785\n",
      "Iteration 104\n",
      "Secrecy Rate: 12.443137702328784\n",
      "Iteration 105\n",
      "Secrecy Rate: 12.4573428234075\n",
      "Iteration 106\n",
      "Secrecy Rate: 12.473077397793723\n",
      "Iteration 107\n",
      "Secrecy Rate: 12.488700179239586\n",
      "Iteration 108\n",
      "Secrecy Rate: 12.50420742339131\n",
      "Iteration 109\n",
      "Secrecy Rate: 12.519599943492928\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration\u001b[39m\u001b[38;5;124m\"\u001b[39m, i)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSecrecy Rate:\u001b[39m\u001b[38;5;124m\"\u001b[39m, current_secrecy_rate)\n\u001b[1;32m---> 19\u001b[0m w_new, theta_new \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw_GD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_GD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_secrecy_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_secrecy_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#if check_validity(theta_new, w_new) == False:\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#    print(\"Stop by invalidity\")\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#    break\u001b[39;00m\n\u001b[0;32m     23\u001b[0m new_secrecy_rate \u001b[38;5;241m=\u001b[39m secrecy_rate_objective_function(theta_new, w_new)\n",
      "Cell \u001b[1;32mIn[7], line 161\u001b[0m, in \u001b[0;36mgradient_descent_update\u001b[1;34m(w, theta, learning_rate, original_secrecy_rate)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient_descent_update\u001b[39m(w, theta, learning_rate, original_secrecy_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    160\u001b[0m     grad_w \u001b[38;5;241m=\u001b[39m compute_gradient_w(theta, w)\n\u001b[1;32m--> 161\u001b[0m     grad_theta \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_gradient_theta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m     w_new \u001b[38;5;241m=\u001b[39m [w[i] \u001b[38;5;241m-\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m grad_w[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (number_of_users)]\n\u001b[0;32m    163\u001b[0m     w_new \u001b[38;5;241m=\u001b[39m normalise_beamforming_vectors(w_new)\n",
      "Cell \u001b[1;32mIn[7], line 106\u001b[0m, in \u001b[0;36mcompute_gradient_theta\u001b[1;34m(theta, w)\u001b[0m\n\u001b[0;32m    104\u001b[0m gamma_e \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (number_of_eavesdroppers):\n\u001b[1;32m--> 106\u001b[0m     Z_em \u001b[38;5;241m=\u001b[39m hie[m] \u001b[38;5;241m@\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m@\u001b[39m Hai \u001b[38;5;241m+\u001b[39m hae[m]\n\u001b[0;32m    107\u001b[0m     numGamma_em \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(Z_em \u001b[38;5;241m@\u001b[39m w[k])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    108\u001b[0m     denGamma_em \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39msum([np\u001b[38;5;241m.\u001b[39mabs(Z_em \u001b[38;5;241m@\u001b[39m w[j])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_of_users) \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m!=\u001b[39m k])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\_twodim_base_impl.py:305\u001b[0m, in \u001b[0;36mdiag\u001b[1;34m(v, k)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    304\u001b[0m     n \u001b[38;5;241m=\u001b[39m s[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mabs\u001b[39m(k)\n\u001b[1;32m--> 305\u001b[0m     res \u001b[38;5;241m=\u001b[39m zeros((n, n), v\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    307\u001b[0m         i \u001b[38;5;241m=\u001b[39m k\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Reseed first\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Gradient Descent Algorithm\n",
    "num_cycles = 500\n",
    "learning_rate = 0.01\n",
    "theta_GD = generate_random_theta()\n",
    "w_GD = generate_random_beamforming_vectors()\n",
    "theta_GD, w_GD = repair(theta_GD, w_GD)\n",
    "print(\"Initial Secrecy Rate GD:\", secrecy_rate_objective_function(theta_GD, w_GD))\n",
    "current_secrecy_rate = secrecy_rate_objective_function(theta_GD, w_GD)\n",
    "\n",
    "GD_results = []\n",
    "GD_results.append(current_secrecy_rate)\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    print(\"Iteration\", i)\n",
    "    print(\"Secrecy Rate:\", current_secrecy_rate)\n",
    "    w_new, theta_new = gradient_descent_update(w_GD, theta_GD, learning_rate, original_secrecy_rate=current_secrecy_rate)\n",
    "    #if check_validity(theta_new, w_new) == False:\n",
    "    #    print(\"Stop by invalidity\")\n",
    "    #    break\n",
    "    new_secrecy_rate = secrecy_rate_objective_function(theta_new, w_new)\n",
    "    if (new_secrecy_rate - current_secrecy_rate) < 1e-9:\n",
    "        print(\"Converged\")\n",
    "        break\n",
    "    w_GD = w_new\n",
    "    theta_GD = theta_new\n",
    "    GD_results.append(new_secrecy_rate)\n",
    "    current_secrecy_rate = new_secrecy_rate\n",
    "\n",
    "theta_GD, w_GD = repair(theta_GD, w_GD)\n",
    "#print(GD_results)\n",
    "print(\"Final Secrecy Rate GD:\", secrecy_rate_objective_function(theta_GD, w_GD))\n",
    "print_users_Cbk(theta_GD, w_GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Swarm Optimization (PSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSOParticle:\n",
    "  def __init__(self) -> None:\n",
    "    self.theta = generate_random_theta_angles(Nris)\n",
    "    self.w = generate_random_beamforming_vectors()\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "    self.best_theta = deepcopy(self.theta)\n",
    "    self.best_w = deepcopy(self.w)\n",
    "    self.best_secrecy_rate = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.best_theta), self.best_w)\n",
    "    self.current_secrecy_rate = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.theta), self.w)\n",
    "    self.velocity_theta = np.zeros((1, Nris))\n",
    "    self.velocity_w = [np.zeros((N, 1)) for i in range(number_of_users)]\n",
    "\n",
    "  \n",
    "  def update_velocity(self, inertia, c1, c2, global_best_theta, global_best_w):\n",
    "    r1 = np.random.rand()\n",
    "    r2 = np.random.rand()\n",
    "    self.velocity_theta = inertia * self.velocity_theta + c1 * r1 * (self.best_theta - self.theta) + c2 * r2 * (global_best_theta - self.theta)\n",
    "    self.velocity_w = [inertia * self.velocity_w[i] + c1 * r1 * (self.best_w[i] - self.w[i]) + c2 * r2 * (global_best_w[i] - self.w[i]) for i in range(number_of_users)]\n",
    "\n",
    "  def update_position(self):\n",
    "    self.theta = self.theta + self.velocity_theta\n",
    "    self.w = [self.w[i] + self.velocity_w[i] for i in range(number_of_users)]\n",
    "    self.w = normalise_beamforming_vectors(self.w)\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "\n",
    "  def update_velocity_theta(self, inertia, c1, c2, global_best_theta): #Used for PSO_GD\n",
    "    self.velocity_theta = inertia * self.velocity_theta + c1 * np.random.rand() * (self.best_theta - self.theta) + c2 * np.random.rand() * (global_best_theta - self.theta)\n",
    "  \n",
    "  def update_position_theta(self): #Used for PSO_GD\n",
    "    self.theta = self.theta + self.velocity_theta\n",
    "\n",
    "  def update_best(self):\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "    self.current_secrecy_rate = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.theta), self.w)\n",
    "    if self.current_secrecy_rate > self.best_secrecy_rate:\n",
    "      self.best_secrecy_rate = self.current_secrecy_rate\n",
    "      self.best_theta = deepcopy(self.theta)\n",
    "      self.best_w = deepcopy(self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_inertia(i: int, max_iter: int, inertia_max: float, inertia_min: float) -> float:\n",
    "  E_t = float((max_iter - i - 1)/max_iter)\n",
    "  inertia = inertia_min + (inertia_max - inertia_min) * (2 /(1 + (np.e ** (-5 * E_t))) - 1)\n",
    "  return inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_optimize_w_theta(max_iter: int, num_particles: int, w_min: float, w_max: float, c1: float, c2: float):\n",
    "  particles = [PSOParticle() for _ in range(num_particles)]\n",
    "  global_best_secrecy_rate = -np.inf\n",
    "  global_best_theta = np.zeros((1, Nris))\n",
    "  global_best_w = [np.zeros((N, 1)) for i in range(number_of_users)]\n",
    "\n",
    "  results_secrecy_rate = []\n",
    "\n",
    "  for particle in particles:\n",
    "    if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "      global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "      global_best_theta = deepcopy(particle.best_theta)\n",
    "      global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "  results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "\n",
    "  for iteration in range(max_iter):\n",
    "    print(\"iteration =\", iteration, global_best_secrecy_rate)\n",
    "    inertia = dynamic_inertia(iteration, max_iter, w_max, w_min)\n",
    "\n",
    "    for particle in particles:\n",
    "      particle.update_velocity(inertia, c1, c2, global_best_theta, global_best_w)\n",
    "      particle.update_position()\n",
    "      particle.update_best()\n",
    "\n",
    "      if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "        global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "        global_best_theta = deepcopy(particle.best_theta)\n",
    "        global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "    results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "   \n",
    "\n",
    "  return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0 8.711394027055588\n",
      "iteration = 1 11.011073398347389\n",
      "iteration = 2 11.318363082019385\n",
      "iteration = 3 11.318363082019385\n",
      "iteration = 4 11.318363082019385\n",
      "iteration = 5 11.318363082019385\n",
      "iteration = 6 11.318363082019385\n",
      "iteration = 7 11.318363082019385\n",
      "iteration = 8 11.380514816724677\n",
      "iteration = 9 11.380514816724677\n",
      "iteration = 10 11.380514816724677\n",
      "iteration = 11 11.380514816724677\n",
      "iteration = 12 11.380514816724677\n",
      "iteration = 13 11.38528692250363\n",
      "iteration = 14 11.38528692250363\n",
      "iteration = 15 11.38528692250363\n",
      "iteration = 16 11.38528692250363\n",
      "iteration = 17 11.60923043440848\n",
      "iteration = 18 11.60923043440848\n",
      "iteration = 19 11.60923043440848\n",
      "iteration = 20 11.60923043440848\n",
      "iteration = 21 11.60923043440848\n",
      "iteration = 22 11.60923043440848\n",
      "iteration = 23 11.60923043440848\n",
      "iteration = 24 11.60923043440848\n",
      "iteration = 25 11.60923043440848\n",
      "iteration = 26 11.60923043440848\n",
      "iteration = 27 11.60923043440848\n",
      "iteration = 28 11.60923043440848\n",
      "iteration = 29 11.60923043440848\n",
      "iteration = 30 11.60923043440848\n",
      "iteration = 31 11.60923043440848\n",
      "iteration = 32 11.60923043440848\n",
      "iteration = 33 11.60923043440848\n",
      "iteration = 34 11.60923043440848\n",
      "iteration = 35 11.60923043440848\n",
      "iteration = 36 11.60923043440848\n",
      "iteration = 37 11.60923043440848\n",
      "iteration = 38 11.665509007491117\n",
      "iteration = 39 11.665509007491117\n",
      "iteration = 40 11.665509007491117\n",
      "iteration = 41 11.665509007491117\n",
      "iteration = 42 11.665509007491117\n",
      "iteration = 43 11.665509007491117\n",
      "iteration = 44 11.665509007491117\n",
      "iteration = 45 11.665509007491117\n",
      "iteration = 46 11.665509007491117\n",
      "iteration = 47 11.665509007491117\n",
      "iteration = 48 11.665509007491117\n",
      "iteration = 49 11.665509007491117\n",
      "iteration = 50 11.665509007491117\n",
      "iteration = 51 11.665509007491117\n",
      "iteration = 52 11.665509007491117\n",
      "iteration = 53 11.665509007491117\n",
      "iteration = 54 11.665509007491117\n",
      "iteration = 55 11.665509007491117\n",
      "iteration = 56 11.831713070783769\n",
      "iteration = 57 11.831713070783769\n",
      "iteration = 58 11.831713070783769\n",
      "iteration = 59 11.831713070783769\n",
      "iteration = 60 11.831713070783769\n",
      "iteration = 61 11.831713070783769\n",
      "iteration = 62 11.831713070783769\n",
      "iteration = 63 11.831713070783769\n",
      "iteration = 64 11.831713070783769\n",
      "iteration = 65 11.831713070783769\n",
      "iteration = 66 11.831713070783769\n",
      "iteration = 67 11.917049692127337\n",
      "iteration = 68 11.917049692127337\n",
      "iteration = 69 11.917049692127337\n",
      "iteration = 70 11.917049692127337\n",
      "iteration = 71 11.917049692127337\n",
      "iteration = 72 11.917049692127337\n",
      "iteration = 73 11.938527627600092\n",
      "iteration = 74 11.938527627600092\n",
      "iteration = 75 11.938527627600092\n",
      "iteration = 76 11.938527627600092\n",
      "iteration = 77 11.938527627600092\n",
      "iteration = 78 11.938527627600092\n",
      "iteration = 79 11.938527627600092\n",
      "iteration = 80 11.98926653702035\n",
      "iteration = 81 11.98926653702035\n",
      "iteration = 82 11.98926653702035\n",
      "iteration = 83 11.98926653702035\n",
      "iteration = 84 11.98926653702035\n",
      "iteration = 85 11.98926653702035\n",
      "iteration = 86 12.079268743076739\n",
      "iteration = 87 12.079268743076739\n",
      "iteration = 88 12.079268743076739\n",
      "iteration = 89 12.079268743076739\n",
      "iteration = 90 12.079268743076739\n",
      "iteration = 91 12.079268743076739\n",
      "iteration = 92 12.079268743076739\n",
      "iteration = 93 12.079268743076739\n",
      "iteration = 94 12.079268743076739\n",
      "iteration = 95 12.079268743076739\n",
      "iteration = 96 12.079268743076739\n",
      "iteration = 97 12.079268743076739\n",
      "iteration = 98 12.079268743076739\n",
      "iteration = 99 12.079268743076739\n",
      "iteration = 100 12.079268743076739\n",
      "iteration = 101 12.079268743076739\n",
      "iteration = 102 12.079268743076739\n",
      "iteration = 103 12.43209769574586\n",
      "iteration = 104 12.43209769574586\n",
      "iteration = 105 12.43209769574586\n",
      "iteration = 106 12.43209769574586\n",
      "iteration = 107 12.43209769574586\n",
      "iteration = 108 12.43209769574586\n",
      "iteration = 109 12.43209769574586\n",
      "iteration = 110 12.43209769574586\n",
      "iteration = 111 12.43209769574586\n",
      "iteration = 112 12.43209769574586\n",
      "iteration = 113 12.43209769574586\n",
      "iteration = 114 12.43209769574586\n",
      "iteration = 115 12.43209769574586\n",
      "iteration = 116 12.43209769574586\n",
      "iteration = 117 12.43209769574586\n",
      "iteration = 118 12.43209769574586\n",
      "iteration = 119 12.43209769574586\n",
      "iteration = 120 12.43209769574586\n",
      "iteration = 121 12.43209769574586\n",
      "iteration = 122 12.550100201913477\n",
      "iteration = 123 12.550100201913477\n",
      "iteration = 124 12.550100201913477\n",
      "iteration = 125 12.550100201913477\n",
      "iteration = 126 12.550100201913477\n",
      "iteration = 127 12.550100201913477\n",
      "iteration = 128 12.550100201913477\n",
      "iteration = 129 12.550100201913477\n",
      "iteration = 130 12.550100201913477\n",
      "iteration = 131 12.57628088650531\n",
      "iteration = 132 12.744075824287345\n",
      "iteration = 133 12.744075824287345\n",
      "iteration = 134 12.744075824287345\n",
      "iteration = 135 12.744075824287345\n",
      "iteration = 136 12.744075824287345\n",
      "iteration = 137 12.744075824287345\n",
      "iteration = 138 12.744075824287345\n",
      "iteration = 139 12.744075824287345\n",
      "iteration = 140 12.744075824287345\n",
      "iteration = 141 12.798839677861784\n",
      "iteration = 142 12.849972160927571\n",
      "iteration = 143 12.849972160927571\n",
      "iteration = 144 12.849972160927571\n",
      "iteration = 145 12.849972160927571\n",
      "iteration = 146 12.849972160927571\n",
      "iteration = 147 12.849972160927571\n",
      "iteration = 148 12.851662497142277\n",
      "iteration = 149 12.851662497142277\n",
      "iteration = 150 12.851662497142277\n",
      "iteration = 151 12.851662497142277\n",
      "iteration = 152 12.894461405305336\n",
      "iteration = 153 12.894461405305336\n",
      "iteration = 154 12.894461405305336\n",
      "iteration = 155 12.894461405305336\n",
      "iteration = 156 12.894461405305336\n",
      "iteration = 157 13.078815928510332\n",
      "iteration = 158 13.078815928510332\n",
      "iteration = 159 13.078815928510332\n",
      "iteration = 160 13.078815928510332\n",
      "iteration = 161 13.078815928510332\n",
      "iteration = 162 13.078815928510332\n",
      "iteration = 163 13.078815928510332\n",
      "iteration = 164 13.078815928510332\n",
      "iteration = 165 13.078815928510332\n",
      "iteration = 166 13.124221240558306\n",
      "iteration = 167 13.124221240558306\n",
      "iteration = 168 13.124221240558306\n",
      "iteration = 169 13.124221240558306\n",
      "iteration = 170 13.193982711544681\n",
      "iteration = 171 13.193982711544681\n",
      "iteration = 172 13.193982711544681\n",
      "iteration = 173 13.193982711544681\n",
      "iteration = 174 13.193982711544681\n",
      "iteration = 175 13.220548318914318\n",
      "iteration = 176 13.220548318914318\n",
      "iteration = 177 13.276125355905442\n",
      "iteration = 178 13.320864865463438\n",
      "iteration = 179 13.320864865463438\n",
      "iteration = 180 13.320864865463438\n",
      "iteration = 181 13.320864865463438\n",
      "iteration = 182 13.320864865463438\n",
      "iteration = 183 13.411944637262033\n",
      "iteration = 184 13.411944637262033\n",
      "iteration = 185 13.411944637262033\n",
      "iteration = 186 13.411944637262033\n",
      "iteration = 187 13.411944637262033\n",
      "iteration = 188 13.411944637262033\n",
      "iteration = 189 13.411944637262033\n",
      "iteration = 190 13.411944637262033\n",
      "iteration = 191 13.411944637262033\n",
      "iteration = 192 13.411944637262033\n",
      "iteration = 193 13.411944637262033\n",
      "iteration = 194 13.411944637262033\n",
      "iteration = 195 13.411944637262033\n",
      "iteration = 196 13.411944637262033\n",
      "iteration = 197 13.411944637262033\n",
      "iteration = 198 13.411944637262033\n",
      "iteration = 199 13.421806656003334\n",
      "Initial Secrecy Rate PSO: 8.711394027055588\n",
      "[np.float64(8.711394027055588), np.float64(11.011073398347389), np.float64(11.318363082019385), np.float64(11.318363082019385), np.float64(11.318363082019385), np.float64(11.318363082019385), np.float64(11.318363082019385), np.float64(11.318363082019385), np.float64(11.380514816724677), np.float64(11.380514816724677), np.float64(11.380514816724677), np.float64(11.380514816724677), np.float64(11.380514816724677), np.float64(11.38528692250363), np.float64(11.38528692250363), np.float64(11.38528692250363), np.float64(11.38528692250363), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.60923043440848), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.665509007491117), np.float64(11.831713070783769), np.float64(11.831713070783769), np.float64(11.831713070783769), np.float64(11.831713070783769), np.float64(11.831713070783769), np.float64(11.831713070783769), np.float64(11.831713070783769), np.float64(11.831713070783769), np.float64(11.831713070783769), np.float64(11.831713070783769), np.float64(11.831713070783769), np.float64(11.917049692127337), np.float64(11.917049692127337), np.float64(11.917049692127337), np.float64(11.917049692127337), np.float64(11.917049692127337), np.float64(11.917049692127337), np.float64(11.938527627600092), np.float64(11.938527627600092), np.float64(11.938527627600092), np.float64(11.938527627600092), np.float64(11.938527627600092), np.float64(11.938527627600092), np.float64(11.938527627600092), np.float64(11.98926653702035), np.float64(11.98926653702035), np.float64(11.98926653702035), np.float64(11.98926653702035), np.float64(11.98926653702035), np.float64(11.98926653702035), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.079268743076739), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.43209769574586), np.float64(12.550100201913477), np.float64(12.550100201913477), np.float64(12.550100201913477), np.float64(12.550100201913477), np.float64(12.550100201913477), np.float64(12.550100201913477), np.float64(12.550100201913477), np.float64(12.550100201913477), np.float64(12.550100201913477), np.float64(12.57628088650531), np.float64(12.744075824287345), np.float64(12.744075824287345), np.float64(12.744075824287345), np.float64(12.744075824287345), np.float64(12.744075824287345), np.float64(12.744075824287345), np.float64(12.744075824287345), np.float64(12.744075824287345), np.float64(12.744075824287345), np.float64(12.798839677861784), np.float64(12.849972160927571), np.float64(12.849972160927571), np.float64(12.849972160927571), np.float64(12.849972160927571), np.float64(12.849972160927571), np.float64(12.849972160927571), np.float64(12.851662497142277), np.float64(12.851662497142277), np.float64(12.851662497142277), np.float64(12.851662497142277), np.float64(12.894461405305336), np.float64(12.894461405305336), np.float64(12.894461405305336), np.float64(12.894461405305336), np.float64(12.894461405305336), np.float64(13.078815928510332), np.float64(13.078815928510332), np.float64(13.078815928510332), np.float64(13.078815928510332), np.float64(13.078815928510332), np.float64(13.078815928510332), np.float64(13.078815928510332), np.float64(13.078815928510332), np.float64(13.078815928510332), np.float64(13.124221240558306), np.float64(13.124221240558306), np.float64(13.124221240558306), np.float64(13.124221240558306), np.float64(13.193982711544681), np.float64(13.193982711544681), np.float64(13.193982711544681), np.float64(13.193982711544681), np.float64(13.193982711544681), np.float64(13.220548318914318), np.float64(13.220548318914318), np.float64(13.276125355905442), np.float64(13.320864865463438), np.float64(13.320864865463438), np.float64(13.320864865463438), np.float64(13.320864865463438), np.float64(13.320864865463438), np.float64(13.411944637262033), np.float64(13.411944637262033), np.float64(13.411944637262033), np.float64(13.411944637262033), np.float64(13.411944637262033), np.float64(13.411944637262033), np.float64(13.411944637262033), np.float64(13.411944637262033), np.float64(13.411944637262033), np.float64(13.411944637262033), np.float64(13.411944637262033), np.float64(13.411944637262033), np.float64(13.411944637262033), np.float64(13.411944637262033), np.float64(13.411944637262033), np.float64(13.411944637262033), np.float64(13.421806656003334), np.float64(13.421806656003334)]\n",
      "Final Secrecy Rate PSO: 13.421806656003334\n"
     ]
    }
   ],
   "source": [
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# PSO Algorithm\n",
    "max_iter = 200\n",
    "num_particles = 100\n",
    "w_min = 0.5\n",
    "w_max = 0.9\n",
    "c1 = 1.5\n",
    "c2 = 1.5\n",
    "\n",
    "PSO_results = PSO_optimize_w_theta(max_iter, num_particles, w_min, w_max, c1, c2)\n",
    "print(\"Initial Secrecy Rate PSO:\", PSO_results[0])\n",
    "print(PSO_results)\n",
    "print(\"Final Secrecy Rate PSO:\", PSO_results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm (GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAIndividual:\n",
    "  def __init__(self, theta: np.ndarray[np.float64] = None, w: np.ndarray[np.complex128] = None) -> None:\n",
    "    if theta is None or w is None:\n",
    "      self.theta = generate_random_theta_angles(Nris)\n",
    "      self.w = generate_random_beamforming_vectors()\n",
    "    else:\n",
    "      self.theta = theta\n",
    "      self.w = w\n",
    "    self.theta, self.w = repair(self.theta, self.w)\n",
    "    self.update_fitness()\n",
    "  \n",
    "  def update_fitness(self):\n",
    "    self.fitness = secrecy_rate_objective_function(theta_angles_to_theta_vector(self.theta), self.w)\n",
    "\n",
    "\n",
    "class GAPopulation:\n",
    "  def __init__(self, population_size: int, crossover_rate: float = 0.85, mutation_rate: float = 0.3) -> None:\n",
    "    self.population_size = population_size\n",
    "    self.individuals = [GAIndividual() for _ in range(population_size)]\n",
    "    self.crossover_rate = crossover_rate\n",
    "    self.mutation_rate = mutation_rate\n",
    "\n",
    "  def sort_population(self):\n",
    "    self.individuals.sort(key=lambda x: x.fitness, reverse=True)\n",
    "\n",
    "  def filter_population(self):\n",
    "    self.sort_population()\n",
    "    self.individuals = self.individuals[:self.population_size]\n",
    "\n",
    "  def add_individual(self, individual: GAIndividual):\n",
    "    self.individuals.append(individual)\n",
    "\n",
    "  def select_parents(self) -> tuple[GAIndividual, GAIndividual]:\n",
    "    parents = np.random.choice(self.individuals, 2, replace=False)\n",
    "    return parents[0], parents[1]\n",
    "  \n",
    "  def crossover(self, parent1: GAIndividual, parent2: GAIndividual) -> GAIndividual:\n",
    "    theta1, w1 = parent1.theta, parent1.w\n",
    "    theta2, w2 = parent2.theta, parent2.w\n",
    "    theta_child = (theta1 + theta2) / 2\n",
    "    w_child = [(w1[i] + w2[i]) / 2 for i in range(number_of_users)]\n",
    "    w_child = normalise_beamforming_vectors(w_child)\n",
    "    theta_child, w_child = repair(theta_child, w_child)\n",
    "    return GAIndividual(theta_child, w_child)\n",
    "  \n",
    "  def mutate(self, individual: GAIndividual) -> GAIndividual:\n",
    "    if np.random.rand() < self.mutation_rate:\n",
    "      mutation_index = np.random.randint(0, Nris)\n",
    "      individual.theta[0, mutation_index] = np.random.uniform(-np.pi, np.pi)\n",
    "      mutation_index = np.random.randint(len(individual.w))\n",
    "      individual.w[mutation_index] = generate_random_beamforming_vector()\n",
    "      individual.w = normalise_beamforming_vectors(individual.w)\n",
    "      individual.theta, individual.w = repair(individual.theta, individual.w)\n",
    "      individual.update_fitness()\n",
    "\n",
    "    return individual\n",
    "  \n",
    "def GA_optimize_w_theta(population_size: int, max_iter: int, crossover_rate: float = 0.85, mutation_rate: float = 0.85):\n",
    "  population = GAPopulation(population_size, crossover_rate, mutation_rate)\n",
    "  population.sort_population()\n",
    "  results_secrecy_rate = []\n",
    "  results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "\n",
    "  for iteration in range(max_iter):\n",
    "    print(\"iteration =\", iteration, population.individuals[0].fitness)\n",
    "    # Crossover and mutate\n",
    "    for _ in range(population_size):\n",
    "      if np.random.rand() < population.crossover_rate:\n",
    "        parent1, parent2 = population.select_parents()\n",
    "        child = population.crossover(parent1, parent2)\n",
    "        population.mutate(child)\n",
    "        population.add_individual(child)\n",
    "    # Filter\n",
    "    population.filter_population()\n",
    "    \n",
    "    results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "    print_users_Cbk(theta_angles_to_theta_vector(population.individuals[0].theta), population.individuals[0].w)\n",
    "  return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0 8.711394027055588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11\\AppData\\Local\\Temp\\ipykernel_9636\\3202772336.py:54: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(float(C_bk), end = \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0096485574684622 0.8718345705772377 1.392729908557463 0.9519600758486615 1.2458210207340612 1.3577845324518516 0.9815672643352481 0.9804513555396681 1.1371593704217071 0.9228336719598024 \n",
      "iteration = 1 10.449327113062685\n",
      "0.889130899957525 1.2685130675834375 0.9796328079636565 1.3778490711737268 1.3752595387219892 1.2025680291635594 0.9765254424022117 1.018556990055146 0.8568300958198054 1.166287570151521 \n",
      "iteration = 2 10.73247287090803\n",
      "0.935583573364569 1.0247884551792008 1.383402140578051 1.0058325223643985 1.5199275387136109 1.6225995028711049 0.8524496735129997 0.8976843275982967 0.9461012001517316 0.8223038708118452 \n",
      "iteration = 3 10.776926157469974\n",
      "1.0176874190879055 0.9437687097156418 1.3943829038127975 1.0508085706033066 1.773458896202298 0.8346312052320835 0.80642812953957 1.2288888747726658 1.132400988885898 1.1590869110544528 \n",
      "iteration = 4 11.140555598703731\n",
      "0.9037234137889181 0.9846179872648325 0.8725873761652597 0.9662189023019141 1.3866400303917479 1.609440904705831 0.8246086444184335 1.5792263600558867 1.0588396209269895 1.3820161122191272 \n",
      "iteration = 5 11.455838132666749\n",
      "0.9037234137889181 0.9846179872648325 0.8725873761652597 0.9662189023019141 1.3866400303917479 1.609440904705831 0.8246086444184335 1.5792263600558867 1.0588396209269895 1.3820161122191272 \n",
      "iteration = 6 11.455838132666749\n",
      "1.006617312615442 1.2671354290206864 1.0256353360108088 0.867885419839189 1.4650477901377283 1.2963481541520632 1.017454861232585 1.2367373669176878 1.6412331013611796 0.868118770171766 \n",
      "iteration = 7 11.571991199909178\n",
      "0.9532169817592206 1.0837720002296185 1.7277612761797159 0.902329013517461 2.0259733855250333 1.0190339356561453 0.9207393807112403 1.0602883250784911 1.0649191547500698 0.9308474128391248 \n",
      "iteration = 8 11.575023584553582\n",
      "0.8983385260688225 1.4111778426605703 1.4168331518439816 1.1104867672189396 1.7818817145085948 0.9952798819133423 0.9524780616837555 1.0043898923590702 1.167889053196721 0.9468128108221535 \n",
      "iteration = 9 11.5781696474601\n",
      "0.82912361833678 1.5300706631972207 1.0963839110709148 1.0818389213545219 1.9721235967654662 1.5054598934288272 0.8400119822571367 0.9949585159233632 0.9654626059469457 1.1212425344605301 \n",
      "iteration = 10 11.811674698626\n",
      "0.82912361833678 1.5300706631972207 1.0963839110709148 1.0818389213545219 1.9721235967654662 1.5054598934288272 0.8400119822571367 0.9949585159233632 0.9654626059469457 1.1212425344605301 \n",
      "iteration = 11 11.811674698626\n",
      "0.82912361833678 1.5300706631972207 1.0963839110709148 1.0818389213545219 1.9721235967654662 1.5054598934288272 0.8400119822571367 0.9949585159233632 0.9654626059469457 1.1212425344605301 \n",
      "iteration = 12 11.811674698626\n",
      "0.82912361833678 1.5300706631972207 1.0963839110709148 1.0818389213545219 1.9721235967654662 1.5054598934288272 0.8400119822571367 0.9949585159233632 0.9654626059469457 1.1212425344605301 \n",
      "iteration = 13 11.811674698626\n",
      "0.8877126012256453 1.1085905044473832 1.5774287773440892 0.9450100709473263 2.1599893306873965 1.0596443592461857 0.9547076506077267 1.2402389118234198 1.0107886922853777 1.064550243794372 \n",
      "iteration = 14 11.907056561082273\n",
      "1.0732446362964025 1.267474048800235 1.3400439920071485 1.0355149747934866 2.5702521805308387 1.072514234829513 0.9950224594765186 1.1115809033047717 0.8882264540110512 0.9467506976358592 \n",
      "iteration = 15 12.169041955349943\n",
      "1.0732446362964025 1.267474048800235 1.3400439920071485 1.0355149747934866 2.5702521805308387 1.072514234829513 0.9950224594765186 1.1115809033047717 0.8882264540110512 0.9467506976358592 \n",
      "iteration = 16 12.169041955349943\n",
      "1.0732446362964025 1.267474048800235 1.3400439920071485 1.0355149747934866 2.5702521805308387 1.072514234829513 0.9950224594765186 1.1115809033047717 0.8882264540110512 0.9467506976358592 \n",
      "iteration = 17 12.169041955349943\n",
      "1.0732446362964025 1.267474048800235 1.3400439920071485 1.0355149747934866 2.5702521805308387 1.072514234829513 0.9950224594765186 1.1115809033047717 0.8882264540110512 0.9467506976358592 \n",
      "iteration = 18 12.169041955349943\n",
      "1.0732446362964025 1.267474048800235 1.3400439920071485 1.0355149747934866 2.5702521805308387 1.072514234829513 0.9950224594765186 1.1115809033047717 0.8882264540110512 0.9467506976358592 \n",
      "iteration = 19 12.169041955349943\n",
      "1.0732446362964025 1.267474048800235 1.3400439920071485 1.0355149747934866 2.5702521805308387 1.072514234829513 0.9950224594765186 1.1115809033047717 0.8882264540110512 0.9467506976358592 \n",
      "iteration = 20 12.169041955349943\n",
      "1.0239160019581757 1.255221772234785 1.3726187722810175 0.9115517090565689 2.419936033812395 1.1226939630557264 1.025698315378437 1.1463055842935967 1.0551523581961453 0.9500908695708189 \n",
      "iteration = 21 12.173689046249592\n",
      "1.0239160019581757 1.255221772234785 1.3726187722810175 0.9115517090565689 2.419936033812395 1.1226939630557264 1.025698315378437 1.1463055842935967 1.0551523581961453 0.9500908695708189 \n",
      "iteration = 22 12.173689046249592\n",
      "0.9789727212206212 1.2652566734242054 1.3733409532695893 1.020010377037667 2.346389715099851 1.1223350284262927 1.0146599007332002 1.191779498847946 1.0259915290833168 0.9841849035124056 \n",
      "iteration = 23 12.21557564471722\n",
      "0.8760695083409278 1.192961942295904 1.4643930585091827 0.9212279749950224 2.438446986535218 1.1037265933848024 1.0540982974701596 1.26333827505764 1.0309491977575123 1.0512877782365178 \n",
      "iteration = 24 12.29655841820717\n",
      "0.8760695083409278 1.192961942295904 1.4643930585091827 0.9212279749950224 2.438446986535218 1.1037265933848024 1.0540982974701596 1.26333827505764 1.0309491977575123 1.0512877782365178 \n",
      "iteration = 25 12.29655841820717\n",
      "0.8760695083409278 1.192961942295904 1.4643930585091827 0.9212279749950224 2.438446986535218 1.1037265933848024 1.0540982974701596 1.26333827505764 1.0309491977575123 1.0512877782365178 \n",
      "iteration = 26 12.29655841820717\n",
      "0.8760695083409278 1.192961942295904 1.4643930585091827 0.9212279749950224 2.438446986535218 1.1037265933848024 1.0540982974701596 1.26333827505764 1.0309491977575123 1.0512877782365178 \n",
      "iteration = 27 12.29655841820717\n",
      "0.8760695083409278 1.192961942295904 1.4643930585091827 0.9212279749950224 2.438446986535218 1.1037265933848024 1.0540982974701596 1.26333827505764 1.0309491977575123 1.0512877782365178 \n",
      "iteration = 28 12.29655841820717\n",
      "0.8760695083409278 1.192961942295904 1.4643930585091827 0.9212279749950224 2.438446986535218 1.1037265933848024 1.0540982974701596 1.26333827505764 1.0309491977575123 1.0512877782365178 \n",
      "iteration = 29 12.29655841820717\n",
      "0.8760695083409278 1.192961942295904 1.4643930585091827 0.9212279749950224 2.438446986535218 1.1037265933848024 1.0540982974701596 1.26333827505764 1.0309491977575123 1.0512877782365178 \n",
      "iteration = 30 12.29655841820717\n",
      "0.8565052723248123 1.4394885523797851 1.5336077796751044 0.936068102129878 2.2470042745822907 1.095576083990629 1.051619060487595 1.1908636924351437 1.0793222623820802 1.0442543150769181 \n",
      "iteration = 31 12.367936356478793\n",
      "0.8326585408828505 1.4292767724723416 1.5567996638066364 0.9199454738764928 2.258175520332631 1.100788412827874 1.0506792475717146 1.1929274604655935 1.0948054767374342 1.0513690339089072 \n",
      "iteration = 32 12.382512796407125\n",
      "0.8245851793801795 1.4254773840557142 1.5608878073135928 0.9563654728347504 2.259498975336501 1.1005450354061916 1.0359193529117035 1.1795620380074823 1.0944761725044243 1.0533345460077754 \n",
      "iteration = 33 12.38577684410212\n",
      "0.8298123137849496 1.340398314002344 1.5202897817719743 0.9158275675270481 2.3668492940551626 1.1158979224033554 1.0495726785827861 1.226053338326909 1.0869355577980646 1.0465126533335076 \n",
      "iteration = 34 12.397068595753748\n",
      "0.8438296570500775 1.430765150853289 1.5342609936656402 0.9362399504116674 2.2584423912850804 1.1013467325637456 1.05413840192615 1.2107657779769891 1.086164632512606 1.0543618051824368 \n",
      "iteration = 35 12.404798016859479\n",
      "1.0404549002476697 1.2168501681802844 1.3978252017645327 0.9055286453026227 2.6203570168489287 1.1111881357350875 1.0769442797043836 1.0076818421018332 1.1123258577021524 1.0216788507756995 \n",
      "iteration = 36 12.40982373367344\n",
      "0.8458666051166126 1.3149369563152693 1.4769256983265144 0.9169097734458869 2.529917046601352 1.1248685772046527 1.0695575524534877 1.1174634282882512 1.1083091448694782 1.0534312716310834 \n",
      "iteration = 37 12.458815324937584\n",
      "0.8458666051166126 1.3149369563152693 1.4769256983265144 0.9169097734458869 2.529917046601352 1.1248685772046527 1.0695575524534877 1.1174634282882512 1.1083091448694782 1.0534312716310834 \n",
      "iteration = 38 12.458815324937584\n",
      "0.8458666051166126 1.3149369563152693 1.4769256983265144 0.9169097734458869 2.529917046601352 1.1248685772046527 1.0695575524534877 1.1174634282882512 1.1083091448694782 1.0534312716310834 \n",
      "iteration = 39 12.458815324937584\n",
      "0.8636788776477156 1.295823051823813 1.4784111192965548 0.9186828892731442 2.58204832199132 1.1294547621841649 1.072977938679229 1.1071507151998552 1.097015067112293 1.031790847567145 \n",
      "iteration = 40 12.477379627165712\n",
      "0.8636788776477156 1.295823051823813 1.4784111192965548 0.9186828892731442 2.58204832199132 1.1294547621841649 1.072977938679229 1.1071507151998552 1.097015067112293 1.031790847567145 \n",
      "iteration = 41 12.477379627165712\n",
      "0.8636788776477156 1.295823051823813 1.4784111192965548 0.9186828892731442 2.58204832199132 1.1294547621841649 1.072977938679229 1.1071507151998552 1.097015067112293 1.031790847567145 \n",
      "iteration = 42 12.477379627165712\n",
      "0.8636788776477156 1.295823051823813 1.4784111192965548 0.9186828892731442 2.58204832199132 1.1294547621841649 1.072977938679229 1.1071507151998552 1.097015067112293 1.031790847567145 \n",
      "iteration = 43 12.477379627165712\n",
      "0.8636788776477156 1.295823051823813 1.4784111192965548 0.9186828892731442 2.58204832199132 1.1294547621841649 1.072977938679229 1.1071507151998552 1.097015067112293 1.031790847567145 \n",
      "iteration = 44 12.477379627165712\n",
      "0.9194556324419789 1.3918209623351676 1.4735063712103877 0.9487301664055232 2.470165600419566 1.1024155077819635 1.059780002212412 1.116364420754574 1.088224733256991 1.0478247063119615 \n",
      "iteration = 45 12.514235187744276\n",
      "0.9194556324419789 1.3918209623351676 1.4735063712103877 0.9487301664055232 2.470165600419566 1.1024155077819635 1.059780002212412 1.116364420754574 1.088224733256991 1.0478247063119615 \n",
      "iteration = 46 12.514235187744276\n",
      "0.9195260293656748 1.385700422812554 1.471141728094783 0.9472031042103993 2.480096915825219 1.1029930882807075 1.060892853795609 1.1088672668980273 1.0926036359799456 1.048993443547723 \n",
      "iteration = 47 12.514399682277206\n",
      "0.8498556259137091 1.3221065289973997 1.4647027130527497 0.8836781859716131 2.681132518493436 1.1264477945563882 0.9859499143030812 1.1664001615133919 1.0993500852437463 1.11555321717257 \n",
      "iteration = 48 12.599636109227276\n",
      "0.8498556259137091 1.3221065289973997 1.4647027130527497 0.8836781859716131 2.681132518493436 1.1264477945563882 0.9859499143030812 1.1664001615133919 1.0993500852437463 1.11555321717257 \n",
      "iteration = 49 12.599636109227276\n",
      "0.8498556259137091 1.3221065289973997 1.4647027130527497 0.8836781859716131 2.681132518493436 1.1264477945563882 0.9859499143030812 1.1664001615133919 1.0993500852437463 1.11555321717257 \n",
      "iteration = 50 12.599636109227276\n",
      "0.8498556259137091 1.3221065289973997 1.4647027130527497 0.8836781859716131 2.681132518493436 1.1264477945563882 0.9859499143030812 1.1664001615133919 1.0993500852437463 1.11555321717257 \n",
      "iteration = 51 12.599636109227276\n",
      "0.8498556259137091 1.3221065289973997 1.4647027130527497 0.8836781859716131 2.681132518493436 1.1264477945563882 0.9859499143030812 1.1664001615133919 1.0993500852437463 1.11555321717257 \n",
      "iteration = 52 12.599636109227276\n",
      "0.8767591215779831 1.3491232063866911 1.477202593217313 0.910981620848108 2.611086493730049 1.1194589628773068 1.0259410706037424 1.1477422153752388 1.1186111524631432 1.081608038586201 \n",
      "iteration = 53 12.619785039772445\n",
      "0.9017750305399495 1.3736456767110834 1.4735118029951368 0.9226175892601807 2.5867599667319747 1.1102599588767847 1.0224662734464873 1.1477504141867307 1.112289668042643 1.082998857458862 \n",
      "iteration = 54 12.633893713506321\n",
      "0.9017750305399495 1.3736456767110834 1.4735118029951368 0.9226175892601807 2.5867599667319747 1.1102599588767847 1.0224662734464873 1.1477504141867307 1.112289668042643 1.082998857458862 \n",
      "iteration = 55 12.633893713506321\n",
      "0.9017750305399495 1.3736456767110834 1.4735118029951368 0.9226175892601807 2.5867599667319747 1.1102599588767847 1.0224662734464873 1.1477504141867307 1.112289668042643 1.082998857458862 \n",
      "iteration = 56 12.633893713506321\n",
      "0.9017750305399495 1.3736456767110834 1.4735118029951368 0.9226175892601807 2.5867599667319747 1.1102599588767847 1.0224662734464873 1.1477504141867307 1.112289668042643 1.082998857458862 \n",
      "iteration = 57 12.633893713506321\n",
      "0.878315340066553 1.349053613788724 1.4736393623655668 0.9071068734212774 2.630622384938168 1.119072232326009 1.0156119935273804 1.1525610799440311 1.1159969312149605 1.090336447070821 \n",
      "iteration = 58 12.63406159993222\n",
      "0.878315340066553 1.349053613788724 1.4736393623655668 0.9071068734212774 2.630622384938168 1.119072232326009 1.0156119935273804 1.1525610799440311 1.1159969312149605 1.090336447070821 \n",
      "iteration = 59 12.63406159993222\n",
      "0.878315340066553 1.349053613788724 1.4736393623655668 0.9071068734212774 2.630622384938168 1.119072232326009 1.0156119935273804 1.1525610799440311 1.1159969312149605 1.090336447070821 \n",
      "iteration = 60 12.63406159993222\n",
      "0.878315340066553 1.349053613788724 1.4736393623655668 0.9071068734212774 2.630622384938168 1.119072232326009 1.0156119935273804 1.1525610799440311 1.1159969312149605 1.090336447070821 \n",
      "iteration = 61 12.63406159993222\n",
      "0.878315340066553 1.349053613788724 1.4736393623655668 0.9071068734212774 2.630622384938168 1.119072232326009 1.0156119935273804 1.1525610799440311 1.1159969312149605 1.090336447070821 \n",
      "iteration = 62 12.63406159993222\n",
      "0.8765224068539325 1.347621731244255 1.4728774246979166 0.9050788696887219 2.636669440555313 1.1194794959961043 1.0122101537874186 1.1547550695871869 1.1148591560669758 1.0932897933871817 \n",
      "iteration = 63 12.635353190774456\n",
      "0.8902301942544056 1.361729645964737 1.4740157452173066 0.914927779276902 2.609225282356429 1.1147300687286354 1.0191672975454977 1.1502296044937133 1.1145091102112679 1.0867259230970474 \n",
      "iteration = 64 12.636288156797413\n",
      "0.8902301942544056 1.361729645964737 1.4740157452173066 0.914927779276902 2.609225282356429 1.1147300687286354 1.0191672975454977 1.1502296044937133 1.1145091102112679 1.0867259230970474 \n",
      "iteration = 65 12.636288156797413\n",
      "0.8902301942544056 1.361729645964737 1.4740157452173066 0.914927779276902 2.609225282356429 1.1147300687286354 1.0191672975454977 1.1502296044937133 1.1145091102112679 1.0867259230970474 \n",
      "iteration = 66 12.636288156797413\n",
      "0.8902301942544056 1.361729645964737 1.4740157452173066 0.914927779276902 2.609225282356429 1.1147300687286354 1.0191672975454977 1.1502296044937133 1.1145091102112679 1.0867259230970474 \n",
      "iteration = 67 12.636288156797413\n",
      "0.8902301942544056 1.361729645964737 1.4740157452173066 0.914927779276902 2.609225282356429 1.1147300687286354 1.0191672975454977 1.1502296044937133 1.1145091102112679 1.0867259230970474 \n",
      "iteration = 68 12.636288156797413\n",
      "0.8902301942544056 1.361729645964737 1.4740157452173066 0.914927779276902 2.609225282356429 1.1147300687286354 1.0191672975454977 1.1502296044937133 1.1145091102112679 1.0867259230970474 \n",
      "iteration = 69 12.636288156797413\n",
      "0.8902301942544056 1.361729645964737 1.4740157452173066 0.914927779276902 2.609225282356429 1.1147300687286354 1.0191672975454977 1.1502296044937133 1.1145091102112679 1.0867259230970474 \n",
      "iteration = 70 12.636288156797413\n",
      "0.8902301942544056 1.361729645964737 1.4740157452173066 0.914927779276902 2.609225282356429 1.1147300687286354 1.0191672975454977 1.1502296044937133 1.1145091102112679 1.0867259230970474 \n",
      "iteration = 71 12.636288156797413\n",
      "0.9286059172517531 1.3141567631454363 1.4085062027484203 0.9949923079841043 2.6047035087934196 1.229312878382506 1.0434254835627508 1.3023649382897624 1.1534332595220826 0.8757270867971374 \n",
      "iteration = 72 12.752123779144172\n",
      "0.9286059172517531 1.3141567631454363 1.4085062027484203 0.9949923079841043 2.6047035087934196 1.229312878382506 1.0434254835627508 1.3023649382897624 1.1534332595220826 0.8757270867971374 \n",
      "iteration = 73 12.752123779144172\n",
      "0.9286059172517531 1.3141567631454363 1.4085062027484203 0.9949923079841043 2.6047035087934196 1.229312878382506 1.0434254835627508 1.3023649382897624 1.1534332595220826 0.8757270867971374 \n",
      "iteration = 74 12.752123779144172\n",
      "0.9008569838451164 1.273976791438466 1.502294181510797 0.9619442535943485 2.7392116030976656 1.232033676411334 0.9636326537293199 1.1219647151714234 1.2052879532625793 1.0791106153351213 \n",
      "iteration = 75 12.878548948504953\n",
      "0.9008569838451164 1.273976791438466 1.502294181510797 0.9619442535943485 2.7392116030976656 1.232033676411334 0.9636326537293199 1.1219647151714234 1.2052879532625793 1.0791106153351213 \n",
      "iteration = 76 12.878548948504953\n",
      "0.9106679695322155 1.288170553776484 1.5041774652026758 0.9670815119174451 2.6994464875805804 1.2300633277084854 0.9663122497981622 1.1335768276144242 1.2181036054872714 1.0685769156017135 \n",
      "iteration = 77 12.884273793460894\n",
      "0.9106679695322155 1.288170553776484 1.5041774652026758 0.9670815119174451 2.6994464875805804 1.2300633277084854 0.9663122497981622 1.1335768276144242 1.2181036054872714 1.0685769156017135 \n",
      "iteration = 78 12.884273793460894\n",
      "0.9106679695322155 1.288170553776484 1.5041774652026758 0.9670815119174451 2.6994464875805804 1.2300633277084854 0.9663122497981622 1.1335768276144242 1.2181036054872714 1.0685769156017135 \n",
      "iteration = 79 12.884273793460894\n",
      "0.9125553468710382 1.276941318332497 1.5015277774669027 0.9749578894353049 2.7056190109679363 1.2350763434979997 0.9627759506196849 1.1332908397076282 1.2284202192504732 1.058977266109144 \n",
      "iteration = 80 12.88726962394064\n",
      "0.9125553468710382 1.276941318332497 1.5015277774669027 0.9749578894353049 2.7056190109679363 1.2350763434979997 0.9627759506196849 1.1332908397076282 1.2284202192504732 1.058977266109144 \n",
      "iteration = 81 12.88726962394064\n",
      "0.9125553468710382 1.276941318332497 1.5015277774669027 0.9749578894353049 2.7056190109679363 1.2350763434979997 0.9627759506196849 1.1332908397076282 1.2284202192504732 1.058977266109144 \n",
      "iteration = 82 12.88726962394064\n",
      "0.9073911106485618 1.2833656826715252 1.4974196175661372 0.9713684848904325 2.7233772261420466 1.2443542830814929 0.9753356056833449 1.1407126265866814 1.2040342386992384 1.0416893928702375 \n",
      "iteration = 83 12.88751078858608\n",
      "0.9073911106485618 1.2833656826715252 1.4974196175661372 0.9713684848904325 2.7233772261420466 1.2443542830814929 0.9753356056833449 1.1407126265866814 1.2040342386992384 1.0416893928702375 \n",
      "iteration = 84 12.88751078858608\n",
      "0.9329479261757243 1.2577896031351112 1.3631126836042027 0.9516435582799749 2.7648734649488347 1.2438611027283035 1.0083782529051786 1.2434300728307366 1.187314361800618 1.0790216019477188 \n",
      "iteration = 85 12.926995046392404\n",
      "0.9329479261757243 1.2577896031351112 1.3631126836042027 0.9516435582799749 2.7648734649488347 1.2438611027283035 1.0083782529051786 1.2434300728307366 1.187314361800618 1.0790216019477188 \n",
      "iteration = 86 12.926995046392404\n",
      "0.9329479261757243 1.2577896031351112 1.3631126836042027 0.9516435582799749 2.7648734649488347 1.2438611027283035 1.0083782529051786 1.2434300728307366 1.187314361800618 1.0790216019477188 \n",
      "iteration = 87 12.926995046392404\n",
      "0.9206195983722261 1.274540335704223 1.4306897078832368 0.9559901172040067 2.7739895871958766 1.237556455186925 0.9937066090460013 1.2011488555066132 1.1923342914060742 1.0757405615593463 \n",
      "iteration = 88 12.95456202733035\n",
      "0.9206195983722261 1.274540335704223 1.4306897078832368 0.9559901172040067 2.7739895871958766 1.237556455186925 0.9937066090460013 1.2011488555066132 1.1923342914060742 1.0757405615593463 \n",
      "iteration = 89 12.95456202733035\n",
      "0.9206195983722261 1.274540335704223 1.4306897078832368 0.9559901172040067 2.7739895871958766 1.237556455186925 0.9937066090460013 1.2011488555066132 1.1923342914060742 1.0757405615593463 \n",
      "iteration = 90 12.95456202733035\n",
      "0.9206195983722261 1.274540335704223 1.4306897078832368 0.9559901172040067 2.7739895871958766 1.237556455186925 0.9937066090460013 1.2011488555066132 1.1923342914060742 1.0757405615593463 \n",
      "iteration = 91 12.95456202733035\n",
      "0.9206195983722261 1.274540335704223 1.4306897078832368 0.9559901172040067 2.7739895871958766 1.237556455186925 0.9937066090460013 1.2011488555066132 1.1923342914060742 1.0757405615593463 \n",
      "iteration = 92 12.95456202733035\n",
      "0.9235013079406077 1.2702210581717441 1.426021846887305 0.9598299687683143 2.7768540112952946 1.2418655719848575 0.9935154628805832 1.2051906606939708 1.1970860907792764 1.0707592840636737 \n",
      "iteration = 93 12.962474884013352\n",
      "0.9227914999371293 1.268592132410326 1.4307777207156052 0.960938737881118 2.7778238806992737 1.2415317512631439 0.9903222010069248 1.199593641847316 1.2000275644106513 1.0727035708755686 \n",
      "iteration = 94 12.962691645019214\n",
      "0.9227875871430805 1.2661960022710903 1.4299532565099922 0.9626654520512739 2.782028055294719 1.2439881247489397 0.9905528894245632 1.1995345188042659 1.2000391486999518 1.0690383994359325 \n",
      "iteration = 95 12.964227930810871\n",
      "0.9227875871430805 1.2661960022710903 1.4299532565099922 0.9626654520512739 2.782028055294719 1.2439881247489397 0.9905528894245632 1.1995345188042659 1.2000391486999518 1.0690383994359325 \n",
      "iteration = 96 12.964227930810871\n",
      "0.926543110802872 1.266159626042873 1.412720228157247 0.9588474706058456 2.7793017938526843 1.2421415296824 0.9954491111977594 1.2139226561552205 1.1977351399815663 1.0749054180259832 \n",
      "iteration = 97 12.964559632888212\n",
      "0.926543110802872 1.266159626042873 1.412720228157247 0.9588474706058456 2.7793017938526843 1.2421415296824 0.9954491111977594 1.2139226561552205 1.1977351399815663 1.0749054180259832 \n",
      "iteration = 98 12.964559632888212\n",
      "0.926543110802872 1.266159626042873 1.412720228157247 0.9588474706058456 2.7793017938526843 1.2421415296824 0.9954491111977594 1.2139226561552205 1.1977351399815663 1.0749054180259832 \n",
      "iteration = 99 12.964559632888212\n",
      "0.92502572451699 1.267267525583171 1.4215299564283153 0.9600427727840813 2.7784916302029363 1.2417707360322068 0.9926648406497902 1.2072902620841781 1.199738315682638 1.0741173395096888 \n",
      "iteration = 100 12.965109501801376\n",
      "0.92502572451699 1.267267525583171 1.4215299564283153 0.9600427727840813 2.7784916302029363 1.2417707360322068 0.9926648406497902 1.2072902620841781 1.199738315682638 1.0741173395096888 \n",
      "iteration = 101 12.965109501801376\n",
      "0.92502572451699 1.267267525583171 1.4215299564283153 0.9600427727840813 2.7784916302029363 1.2417707360322068 0.9926648406497902 1.2072902620841781 1.199738315682638 1.0741173395096888 \n",
      "iteration = 102 12.965109501801376\n",
      "0.9388833244798973 1.2695857542543547 1.597510387581275 1.03302752824484 2.5604938757106406 1.435963354694466 1.0863795890648988 1.2052835824323582 1.24554208606811 0.8108744722769211 \n",
      "iteration = 103 13.084102811792306\n",
      "0.940699479351137 1.2729417996402537 1.5292501284573659 1.0019845538884296 2.686560562148226 1.3754287748717602 1.0692796327061722 1.207884779873511 1.230818416495199 0.8714989457416153 \n",
      "iteration = 104 13.086670756594978\n",
      "0.9421192246909865 1.271594684503617 1.5242092579131155 1.0019811277850594 2.6875602664086804 1.3758326582608476 1.0702809523728791 1.2117737011318304 1.2314396183213767 0.8718988656653183 \n",
      "iteration = 105 13.088730876405974\n",
      "0.9421192246909865 1.271594684503617 1.5242092579131155 1.0019811277850594 2.6875602664086804 1.3758326582608476 1.0702809523728791 1.2117737011318304 1.2314396183213767 0.8718988656653183 \n",
      "iteration = 106 13.088730876405974\n",
      "0.8930291547757323 1.2427972038820885 1.2171767025636857 0.9541531243398325 2.9791135183462036 1.2637925697777164 1.0457451901166654 1.3576294609990147 1.1968356426261393 1.040475760903047 \n",
      "iteration = 107 13.088802067273349\n",
      "0.943022017699979 1.2712877044129212 1.5344131224191107 1.0065608531973873 2.6738922757033325 1.388054970062276 1.0757468112671071 1.2120546691709846 1.2341939576339052 0.8560295672452136 \n",
      "iteration = 108 13.095436739962956\n",
      "0.936272537549574 0.9631382168433444 1.4332835512154118 0.9401112665514215 2.9496382804887658 1.2465174408021227 0.9786870255555918 1.5086443397096523 1.1924503636009558 1.0852187962458442 \n",
      "iteration = 109 13.141136725277434\n",
      "0.936272537549574 0.9631382168433444 1.4332835512154118 0.9401112665514215 2.9496382804887658 1.2465174408021227 0.9786870255555918 1.5086443397096523 1.1924503636009558 1.0852187962458442 \n",
      "iteration = 110 13.141136725277434\n",
      "0.9488023569447299 0.9646974162402034 1.4831937985302674 0.9617891375444436 2.9033784354139227 1.3217214390082925 1.0252368621920327 1.5189938169077923 1.210665144010326 0.9682545776379274 \n",
      "iteration = 111 13.21539419866377\n",
      "0.9488023569447299 0.9646974162402034 1.4831937985302674 0.9617891375444436 2.9033784354139227 1.3217214390082925 1.0252368621920327 1.5189938169077923 1.210665144010326 0.9682545776379274 \n",
      "iteration = 112 13.21539419866377\n",
      "0.9488023569447299 0.9646974162402034 1.4831937985302674 0.9617891375444436 2.9033784354139227 1.3217214390082925 1.0252368621920327 1.5189938169077923 1.210665144010326 0.9682545776379274 \n",
      "iteration = 113 13.21539419866377\n",
      "0.8975731640684665 1.279960349181803 1.3652326978046714 0.9684899360405692 2.922508368958512 1.3115865694322153 1.051349644357555 1.3345645312437475 1.2107214698248703 0.9928756750048598 \n",
      "iteration = 114 13.234381864263637\n",
      "0.8975731640684665 1.279960349181803 1.3652326978046714 0.9684899360405692 2.922508368958512 1.3115865694322153 1.051349644357555 1.3345645312437475 1.2107214698248703 0.9928756750048598 \n",
      "iteration = 115 13.234381864263637\n",
      "0.8975731640684665 1.279960349181803 1.3652326978046714 0.9684899360405692 2.922508368958512 1.3115865694322153 1.051349644357555 1.3345645312437475 1.2107214698248703 0.9928756750048598 \n",
      "iteration = 116 13.234381864263637\n",
      "0.925267024664358 1.1992515492565785 1.4335648626279132 0.9761648565754216 2.8783526347338557 1.3294242857325629 1.0512391373319625 1.3587640827996827 1.2218847618979776 0.9660972535709008 \n",
      "iteration = 117 13.241868981524426\n",
      "0.9264206333615139 1.1753609320312988 1.4282461361566154 0.9704201525115286 2.8979956377789042 1.3208237734006671 1.0456204195029803 1.3815406832996784 1.2165964739753798 0.9828936895133974 \n",
      "iteration = 118 13.248121139962599\n",
      "0.9447985976705299 0.9938370202083909 1.4767728694744557 0.9647987761414608 2.8943147853970697 1.3198083146988644 1.0445597898470929 1.4380306067401614 1.296475442363613 0.9714818771639635 \n",
      "iteration = 119 13.253915168931334\n",
      "0.9284332607013442 1.1583521961835073 1.4283830362043257 0.9717563282350494 2.9054751809370827 1.321885950926426 1.0455767514966772 1.3982551722381285 1.2204033682900495 0.9809072745028626 \n",
      "iteration = 120 13.262220821578453\n",
      "0.9336710645089875 1.1412726379228826 1.4365040905987856 0.9910766325693121 2.9374247052945726 1.2723183500207245 1.0398139785234137 1.4013125784754759 1.2227795408751536 1.0248015112270636 \n",
      "iteration = 121 13.301343146413345\n",
      "0.9336710645089875 1.1412726379228826 1.4365040905987856 0.9910766325693121 2.9374247052945726 1.2723183500207245 1.0398139785234137 1.4013125784754759 1.2227795408751536 1.0248015112270636 \n",
      "iteration = 122 13.301343146413345\n",
      "0.9360024569465393 1.070477306756949 1.4470188291412833 0.9698170260777497 2.934821280208036 1.312491070314956 1.0451531525998823 1.4280905373787172 1.264246738316135 0.9900515359803893 \n",
      "iteration = 123 13.303840563100742\n",
      "0.9360024569465393 1.070477306756949 1.4470188291412833 0.9698170260777497 2.934821280208036 1.312491070314956 1.0451531525998823 1.4280905373787172 1.264246738316135 0.9900515359803893 \n",
      "iteration = 124 13.303840563100742\n",
      "0.9360024569465393 1.070477306756949 1.4470188291412833 0.9698170260777497 2.934821280208036 1.312491070314956 1.0451531525998823 1.4280905373787172 1.264246738316135 0.9900515359803893 \n",
      "iteration = 125 13.303840563100742\n",
      "0.9360024569465393 1.070477306756949 1.4470188291412833 0.9698170260777497 2.934821280208036 1.312491070314956 1.0451531525998823 1.4280905373787172 1.264246738316135 0.9900515359803893 \n",
      "iteration = 126 13.303840563100742\n",
      "0.9360024569465393 1.070477306756949 1.4470188291412833 0.9698170260777497 2.934821280208036 1.312491070314956 1.0451531525998823 1.4280905373787172 1.264246738316135 0.9900515359803893 \n",
      "iteration = 127 13.303840563100742\n",
      "0.9360024569465393 1.070477306756949 1.4470188291412833 0.9698170260777497 2.934821280208036 1.312491070314956 1.0451531525998823 1.4280905373787172 1.264246738316135 0.9900515359803893 \n",
      "iteration = 128 13.303840563100742\n",
      "0.9360024569465393 1.070477306756949 1.4470188291412833 0.9698170260777497 2.934821280208036 1.312491070314956 1.0451531525998823 1.4280905373787172 1.264246738316135 0.9900515359803893 \n",
      "iteration = 129 13.303840563100742\n",
      "0.9360024569465393 1.070477306756949 1.4470188291412833 0.9698170260777497 2.934821280208036 1.312491070314956 1.0451531525998823 1.4280905373787172 1.264246738316135 0.9900515359803893 \n",
      "iteration = 130 13.303840563100742\n",
      "0.9360024569465393 1.070477306756949 1.4470188291412833 0.9698170260777497 2.934821280208036 1.312491070314956 1.0451531525998823 1.4280905373787172 1.264246738316135 0.9900515359803893 \n",
      "iteration = 131 13.303840563100742\n",
      "0.9383188780611689 1.0860553657446048 1.4476166248227291 0.9763853860712377 2.9339207912556695 1.3034034032994775 1.0431431887843956 1.42809140093193 1.2451109486945808 0.9978774368457248 \n",
      "iteration = 132 13.304121182926977\n",
      "0.9369932296118363 1.1007430604689412 1.4435679417767509 0.9798351411409407 2.938084690960545 1.2978089376097994 1.0430908553057852 1.4262301075537256 1.2370350415276523 1.0031649982258084 \n",
      "iteration = 133 13.30983583710439\n",
      "0.9933362987758139 1.2334359917509028 1.4183054133743627 1.0410244549432737 3.035387600315708 1.3367030049397797 1.0384837486316556 1.207580709369117 1.2434819336279679 1.0187028612629376 \n",
      "iteration = 134 13.459311279951875\n",
      "0.9788776744418163 1.169193346384508 1.4539435463546992 1.0256106608118054 2.9979958837046774 1.320490413251983 1.0441014252827074 1.3161629820058762 1.2453435846448426 1.0093360701046423 \n",
      "iteration = 135 13.460741911174253\n",
      "0.9788776744418163 1.169193346384508 1.4539435463546992 1.0256106608118054 2.9979958837046774 1.320490413251983 1.0441014252827074 1.3161629820058762 1.2453435846448426 1.0093360701046423 \n",
      "iteration = 136 13.460741911174253\n",
      "0.9770530226275447 1.172750141101676 1.4513571969866133 1.0240534229178935 2.999276499013639 1.3222428053338307 1.0447246321103747 1.314410586123077 1.2482189711806555 1.008576253984129 \n",
      "iteration = 137 13.462471595803134\n",
      "0.9711799620470003 1.2138855020833137 1.4391193519479653 1.0267681658923593 3.003608175597412 1.3185321596152146 1.0458039199541447 1.3017548355012234 1.2367847696232595 1.01338217511787 \n",
      "iteration = 138 13.469180820801261\n",
      "0.9711799620470003 1.2138855020833137 1.4391193519479653 1.0267681658923593 3.003608175597412 1.3185321596152146 1.0458039199541447 1.3017548355012234 1.2367847696232595 1.01338217511787 \n",
      "iteration = 139 13.469180820801261\n",
      "0.9831477224240152 1.1920559304042122 1.445758977694741 1.031530349588685 3.0123056566892803 1.3254780950052671 1.0437002697782165 1.286836115495174 1.247329280813698 1.0122005790967106 \n",
      "iteration = 140 13.478589540445551\n",
      "0.9890388132027538 1.2073415885852183 1.4401099550127796 1.0377106112057166 3.0205689201683166 1.3289607437099515 1.0422475283803307 1.2603267546900543 1.2445829355782478 1.0143571486006575 \n",
      "iteration = 141 13.481762064602067\n",
      "0.9890388132027538 1.2073415885852183 1.4401099550127796 1.0377106112057166 3.0205689201683166 1.3289607437099515 1.0422475283803307 1.2603267546900543 1.2445829355782478 1.0143571486006575 \n",
      "iteration = 142 13.481762064602067\n",
      "0.9567200338998 1.1739695427357153 1.441404681212089 0.9293528200418785 3.075177830954487 1.337500635450455 1.0530293963831376 1.3611882310255634 1.2436283529145062 1.0192034978457725 \n",
      "iteration = 143 13.494062627163718\n",
      "0.962749008956378 1.1709032424651007 1.4456961890908635 0.9333097731037185 3.0792120057399495 1.3395144303975477 1.0522304796245114 1.3536530356857455 1.2450943673716528 1.01969606894107 \n",
      "iteration = 144 13.504777763763366\n",
      "0.9637407669062434 1.176607209927827 1.4446447273685041 0.9349131921984285 3.0824663805818275 1.340453929663794 1.0523705048961614 1.3479247237656273 1.2452331089874813 1.0202190429462488 \n",
      "iteration = 145 13.51104384751248\n",
      "0.969799946597399 1.1938033872845544 1.4467185596337013 1.0078413656490888 3.0567963358591563 1.3596260581997444 1.06691671747894 1.3234005339286878 1.1800935116735618 1.0116114538555983 \n",
      "iteration = 146 13.516126162578582\n",
      "0.969799946597399 1.1938033872845544 1.4467185596337013 1.0078413656490888 3.0567963358591563 1.3596260581997444 1.06691671747894 1.3234005339286878 1.1800935116735618 1.0116114538555983 \n",
      "iteration = 147 13.516126162578582\n",
      "0.969799946597399 1.1938033872845544 1.4467185596337013 1.0078413656490888 3.0567963358591563 1.3596260581997444 1.06691671747894 1.3234005339286878 1.1800935116735618 1.0116114538555983 \n",
      "iteration = 148 13.516126162578582\n",
      "0.969799946597399 1.1938033872845544 1.4467185596337013 1.0078413656490888 3.0567963358591563 1.3596260581997444 1.06691671747894 1.3234005339286878 1.1800935116735618 1.0116114538555983 \n",
      "iteration = 149 13.516126162578582\n",
      "0.969799946597399 1.1938033872845544 1.4467185596337013 1.0078413656490888 3.0567963358591563 1.3596260581997444 1.06691671747894 1.3234005339286878 1.1800935116735618 1.0116114538555983 \n",
      "iteration = 150 13.516126162578582\n",
      "0.969799946597399 1.1938033872845544 1.4467185596337013 1.0078413656490888 3.0567963358591563 1.3596260581997444 1.06691671747894 1.3234005339286878 1.1800935116735618 1.0116114538555983 \n",
      "iteration = 151 13.516126162578582\n",
      "0.9700746702808033 1.1869068321342464 1.4460895455572385 0.9710650551147051 3.0704338880667303 1.3444214214595644 1.0550967274109389 1.3285445300325678 1.2290941561161466 1.0171153513411155 \n",
      "iteration = 152 13.51979929705838\n",
      "0.9700746702808033 1.1869068321342464 1.4460895455572385 0.9710650551147051 3.0704338880667303 1.3444214214595644 1.0550967274109389 1.3285445300325678 1.2290941561161466 1.0171153513411155 \n",
      "iteration = 153 13.51979929705838\n",
      "0.9700746702808033 1.1869068321342464 1.4460895455572385 0.9710650551147051 3.0704338880667303 1.3444214214595644 1.0550967274109389 1.3285445300325678 1.2290941561161466 1.0171153513411155 \n",
      "iteration = 154 13.51979929705838\n",
      "0.9700746702808033 1.1869068321342464 1.4460895455572385 0.9710650551147051 3.0704338880667303 1.3444214214595644 1.0550967274109389 1.3285445300325678 1.2290941561161466 1.0171153513411155 \n",
      "iteration = 155 13.51979929705838\n",
      "0.9700746702808033 1.1869068321342464 1.4460895455572385 0.9710650551147051 3.0704338880667303 1.3444214214595644 1.0550967274109389 1.3285445300325678 1.2290941561161466 1.0171153513411155 \n",
      "iteration = 156 13.51979929705838\n",
      "1.1136093992888376 0.9914406882952577 1.3757971393888229 0.9944928108063724 3.5523282333969006 1.2938774252098157 1.047807841337737 1.3277055613965039 1.1969472776385437 1.0250577182822553 \n",
      "iteration = 157 13.8185509138345\n",
      "1.1136093992888376 0.9914406882952577 1.3757971393888229 0.9944928108063724 3.5523282333969006 1.2938774252098157 1.047807841337737 1.3277055613965039 1.1969472776385437 1.0250577182822553 \n",
      "iteration = 158 13.8185509138345\n",
      "1.1136093992888376 0.9914406882952577 1.3757971393888229 0.9944928108063724 3.5523282333969006 1.2938774252098157 1.047807841337737 1.3277055613965039 1.1969472776385437 1.0250577182822553 \n",
      "iteration = 159 13.8185509138345\n",
      "1.1136093992888376 0.9914406882952577 1.3757971393888229 0.9944928108063724 3.5523282333969006 1.2938774252098157 1.047807841337737 1.3277055613965039 1.1969472776385437 1.0250577182822553 \n",
      "iteration = 160 13.8185509138345\n",
      "1.0797758315726493 1.0222458733816029 1.419721073011446 0.9984326561692188 3.4810035387410423 1.3147490049531547 1.0474269596102173 1.3351362338666473 1.2124275829353208 1.0268130927803802 \n",
      "iteration = 161 13.839577870981582\n",
      "1.0797758315726493 1.0222458733816029 1.419721073011446 0.9984326561692188 3.4810035387410423 1.3147490049531547 1.0474269596102173 1.3351362338666473 1.2124275829353208 1.0268130927803802 \n",
      "iteration = 162 13.839577870981582\n",
      "1.0797758315726493 1.0222458733816029 1.419721073011446 0.9984326561692188 3.4810035387410423 1.3147490049531547 1.0474269596102173 1.3351362338666473 1.2124275829353208 1.0268130927803802 \n",
      "iteration = 163 13.839577870981582\n",
      "1.0797758315726493 1.0222458733816029 1.419721073011446 0.9984326561692188 3.4810035387410423 1.3147490049531547 1.0474269596102173 1.3351362338666473 1.2124275829353208 1.0268130927803802 \n",
      "iteration = 164 13.839577870981582\n",
      "1.0797758315726493 1.0222458733816029 1.419721073011446 0.9984326561692188 3.4810035387410423 1.3147490049531547 1.0474269596102173 1.3351362338666473 1.2124275829353208 1.0268130927803802 \n",
      "iteration = 165 13.839577870981582\n",
      "1.0797758315726493 1.0222458733816029 1.419721073011446 0.9984326561692188 3.4810035387410423 1.3147490049531547 1.0474269596102173 1.3351362338666473 1.2124275829353208 1.0268130927803802 \n",
      "iteration = 166 13.839577870981582\n",
      "1.0797758315726493 1.0222458733816029 1.419721073011446 0.9984326561692188 3.4810035387410423 1.3147490049531547 1.0474269596102173 1.3351362338666473 1.2124275829353208 1.0268130927803802 \n",
      "iteration = 167 13.839577870981582\n",
      "1.0797758315726493 1.0222458733816029 1.419721073011446 0.9984326561692188 3.4810035387410423 1.3147490049531547 1.0474269596102173 1.3351362338666473 1.2124275829353208 1.0268130927803802 \n",
      "iteration = 168 13.839577870981582\n",
      "1.0797758315726493 1.0222458733816029 1.419721073011446 0.9984326561692188 3.4810035387410423 1.3147490049531547 1.0474269596102173 1.3351362338666473 1.2124275829353208 1.0268130927803802 \n",
      "iteration = 169 13.839577870981582\n",
      "1.0797758315726493 1.0222458733816029 1.419721073011446 0.9984326561692188 3.4810035387410423 1.3147490049531547 1.0474269596102173 1.3351362338666473 1.2124275829353208 1.0268130927803802 \n",
      "iteration = 170 13.839577870981582\n",
      "1.0797758315726493 1.0222458733816029 1.419721073011446 0.9984326561692188 3.4810035387410423 1.3147490049531547 1.0474269596102173 1.3351362338666473 1.2124275829353208 1.0268130927803802 \n",
      "iteration = 171 13.839577870981582\n",
      "1.0797758315726493 1.0222458733816029 1.419721073011446 0.9984326561692188 3.4810035387410423 1.3147490049531547 1.0474269596102173 1.3351362338666473 1.2124275829353208 1.0268130927803802 \n",
      "iteration = 172 13.839577870981582\n",
      "1.093406441521217 1.0085400353617546 1.4039583456768268 0.9978197721483643 3.5164994956932225 1.3080220700980962 1.0478996921119494 1.3329360343134151 1.2050863209016671 1.0264970496602233 \n",
      "iteration = 173 13.841718185735491\n",
      "1.093406441521217 1.0085400353617546 1.4039583456768268 0.9978197721483643 3.5164994956932225 1.3080220700980962 1.0478996921119494 1.3329360343134151 1.2050863209016671 1.0264970496602233 \n",
      "iteration = 174 13.841718185735491\n",
      "1.0844142034259363 1.0181661402766176 1.414313519134065 0.9993523922202342 3.4948045573410247 1.313406592460497 1.0480903554259577 1.331511598094276 1.2090236169399045 1.0270807041091137 \n",
      "iteration = 175 13.841830113194707\n",
      "1.0844142034259363 1.0181661402766176 1.414313519134065 0.9993523922202342 3.4948045573410247 1.313406592460497 1.0480903554259577 1.331511598094276 1.2090236169399045 1.0270807041091137 \n",
      "iteration = 176 13.841830113194707\n",
      "1.0852859747522194 1.0173648373094426 1.4133331044465345 0.9996060812833549 3.4968403260818435 1.3129246485663884 1.0479687363947063 1.3312832680811748 1.2086786985983444 1.0272364476862195 \n",
      "iteration = 177 13.842123884571768\n",
      "1.0852859747522194 1.0173648373094426 1.4133331044465345 0.9996060812833549 3.4968403260818435 1.3129246485663884 1.0479687363947063 1.3312832680811748 1.2086786985983444 1.0272364476862195 \n",
      "iteration = 178 13.842123884571768\n",
      "1.0852859747522194 1.0173648373094426 1.4133331044465345 0.9996060812833549 3.4968403260818435 1.3129246485663884 1.0479687363947063 1.3312832680811748 1.2086786985983444 1.0272364476862195 \n",
      "iteration = 179 13.842123884571768\n",
      "1.0846486505468773 1.0175054299879702 1.414166915363625 0.9987279261272116 3.495701775527446 1.3131609923189669 1.0480079242800169 1.333084752082181 1.208870227212193 1.0269139794974733 \n",
      "iteration = 180 13.842410861674582\n",
      "1.0834710336400764 1.0185796759647892 1.4154903367251237 0.9986918364469453 3.4930419284196677 1.3138761263823178 1.0479702877426018 1.334073126173238 1.2090240885528312 1.0269858915786179 \n",
      "iteration = 181 13.842860170784936\n",
      "1.0834710336400764 1.0185796759647892 1.4154903367251237 0.9986918364469453 3.4930419284196677 1.3138761263823178 1.0479702877426018 1.334073126173238 1.2090240885528312 1.0269858915786179 \n",
      "iteration = 182 13.842860170784936\n",
      "1.0834710336400764 1.0185796759647892 1.4154903367251237 0.9986918364469453 3.4930419284196677 1.3138761263823178 1.0479702877426018 1.334073126173238 1.2090240885528312 1.0269858915786179 \n",
      "iteration = 183 13.842860170784936\n",
      "1.0834710336400764 1.0185796759647892 1.4154903367251237 0.9986918364469453 3.4930419284196677 1.3138761263823178 1.0479702877426018 1.334073126173238 1.2090240885528312 1.0269858915786179 \n",
      "iteration = 184 13.842860170784936\n",
      "1.0834710336400764 1.0185796759647892 1.4154903367251237 0.9986918364469453 3.4930419284196677 1.3138761263823178 1.0479702877426018 1.334073126173238 1.2090240885528312 1.0269858915786179 \n",
      "iteration = 185 13.842860170784936\n",
      "1.0834710336400764 1.0185796759647892 1.4154903367251237 0.9986918364469453 3.4930419284196677 1.3138761263823178 1.0479702877426018 1.334073126173238 1.2090240885528312 1.0269858915786179 \n",
      "iteration = 186 13.842860170784936\n",
      "1.0851700305044667 1.0167273288979655 1.4136704834851683 0.9985158708790838 3.4971883012173244 1.3128526253701436 1.0478859150414834 1.3342766085588627 1.2084293637146695 1.0269049823651377 \n",
      "iteration = 187 13.84317021195476\n",
      "1.0851700305044667 1.0167273288979655 1.4136704834851683 0.9985158708790838 3.4971883012173244 1.3128526253701436 1.0478859150414834 1.3342766085588627 1.2084293637146695 1.0269049823651377 \n",
      "iteration = 188 13.84317021195476\n",
      "1.0851700305044667 1.0167273288979655 1.4136704834851683 0.9985158708790838 3.4971883012173244 1.3128526253701436 1.0478859150414834 1.3342766085588627 1.2084293637146695 1.0269049823651377 \n",
      "iteration = 189 13.84317021195476\n",
      "1.0851700305044667 1.0167273288979655 1.4136704834851683 0.9985158708790838 3.4971883012173244 1.3128526253701436 1.0478859150414834 1.3342766085588627 1.2084293637146695 1.0269049823651377 \n",
      "iteration = 190 13.84317021195476\n",
      "1.0851700305044667 1.0167273288979655 1.4136704834851683 0.9985158708790838 3.4971883012173244 1.3128526253701436 1.0478859150414834 1.3342766085588627 1.2084293637146695 1.0269049823651377 \n",
      "iteration = 191 13.84317021195476\n",
      "1.0925298559894832 0.9366066510304332 1.4352273717602082 0.896789058847371 3.7013349067561574 1.429729306305236 1.0752580397609497 1.4049732137118103 1.2811894454205799 0.9574186651887634 \n",
      "iteration = 192 14.110122428136739\n",
      "1.0925298559894832 0.9366066510304332 1.4352273717602082 0.896789058847371 3.7013349067561574 1.429729306305236 1.0752580397609497 1.4049732137118103 1.2811894454205799 0.9574186651887634 \n",
      "iteration = 193 14.110122428136739\n",
      "1.0925298559894832 0.9366066510304332 1.4352273717602082 0.896789058847371 3.7013349067561574 1.429729306305236 1.0752580397609497 1.4049732137118103 1.2811894454205799 0.9574186651887634 \n",
      "iteration = 194 14.110122428136739\n",
      "1.0925298559894832 0.9366066510304332 1.4352273717602082 0.896789058847371 3.7013349067561574 1.429729306305236 1.0752580397609497 1.4049732137118103 1.2811894454205799 0.9574186651887634 \n",
      "iteration = 195 14.110122428136739\n",
      "1.0925298559894832 0.9366066510304332 1.4352273717602082 0.896789058847371 3.7013349067561574 1.429729306305236 1.0752580397609497 1.4049732137118103 1.2811894454205799 0.9574186651887634 \n",
      "iteration = 196 14.110122428136739\n",
      "1.0925298559894832 0.9366066510304332 1.4352273717602082 0.896789058847371 3.7013349067561574 1.429729306305236 1.0752580397609497 1.4049732137118103 1.2811894454205799 0.9574186651887634 \n",
      "iteration = 197 14.110122428136739\n",
      "1.0925298559894832 0.9366066510304332 1.4352273717602082 0.896789058847371 3.7013349067561574 1.429729306305236 1.0752580397609497 1.4049732137118103 1.2811894454205799 0.9574186651887634 \n",
      "iteration = 198 14.110122428136739\n",
      "1.0925298559894832 0.9366066510304332 1.4352273717602082 0.896789058847371 3.7013349067561574 1.429729306305236 1.0752580397609497 1.4049732137118103 1.2811894454205799 0.9574186651887634 \n",
      "iteration = 199 14.110122428136739\n",
      "1.0925298559894832 0.9366066510304332 1.4352273717602082 0.896789058847371 3.7013349067561574 1.429729306305236 1.0752580397609497 1.4049732137118103 1.2811894454205799 0.9574186651887634 \n",
      "Initial Secrecy Rate GA: 8.711394027055588\n",
      "[np.float64(8.711394027055588), np.float64(10.449327113062685), np.float64(10.73247287090803), np.float64(10.776926157469974), np.float64(11.140555598703731), np.float64(11.455838132666749), np.float64(11.455838132666749), np.float64(11.571991199909178), np.float64(11.575023584553582), np.float64(11.5781696474601), np.float64(11.811674698626), np.float64(11.811674698626), np.float64(11.811674698626), np.float64(11.811674698626), np.float64(11.907056561082273), np.float64(12.169041955349943), np.float64(12.169041955349943), np.float64(12.169041955349943), np.float64(12.169041955349943), np.float64(12.169041955349943), np.float64(12.169041955349943), np.float64(12.173689046249592), np.float64(12.173689046249592), np.float64(12.21557564471722), np.float64(12.29655841820717), np.float64(12.29655841820717), np.float64(12.29655841820717), np.float64(12.29655841820717), np.float64(12.29655841820717), np.float64(12.29655841820717), np.float64(12.29655841820717), np.float64(12.367936356478793), np.float64(12.382512796407125), np.float64(12.38577684410212), np.float64(12.397068595753748), np.float64(12.404798016859479), np.float64(12.40982373367344), np.float64(12.458815324937584), np.float64(12.458815324937584), np.float64(12.458815324937584), np.float64(12.477379627165712), np.float64(12.477379627165712), np.float64(12.477379627165712), np.float64(12.477379627165712), np.float64(12.477379627165712), np.float64(12.514235187744276), np.float64(12.514235187744276), np.float64(12.514399682277206), np.float64(12.599636109227276), np.float64(12.599636109227276), np.float64(12.599636109227276), np.float64(12.599636109227276), np.float64(12.599636109227276), np.float64(12.619785039772445), np.float64(12.633893713506321), np.float64(12.633893713506321), np.float64(12.633893713506321), np.float64(12.633893713506321), np.float64(12.63406159993222), np.float64(12.63406159993222), np.float64(12.63406159993222), np.float64(12.63406159993222), np.float64(12.63406159993222), np.float64(12.635353190774456), np.float64(12.636288156797413), np.float64(12.636288156797413), np.float64(12.636288156797413), np.float64(12.636288156797413), np.float64(12.636288156797413), np.float64(12.636288156797413), np.float64(12.636288156797413), np.float64(12.636288156797413), np.float64(12.752123779144172), np.float64(12.752123779144172), np.float64(12.752123779144172), np.float64(12.878548948504953), np.float64(12.878548948504953), np.float64(12.884273793460894), np.float64(12.884273793460894), np.float64(12.884273793460894), np.float64(12.88726962394064), np.float64(12.88726962394064), np.float64(12.88726962394064), np.float64(12.88751078858608), np.float64(12.88751078858608), np.float64(12.926995046392404), np.float64(12.926995046392404), np.float64(12.926995046392404), np.float64(12.95456202733035), np.float64(12.95456202733035), np.float64(12.95456202733035), np.float64(12.95456202733035), np.float64(12.95456202733035), np.float64(12.962474884013352), np.float64(12.962691645019214), np.float64(12.964227930810871), np.float64(12.964227930810871), np.float64(12.964559632888212), np.float64(12.964559632888212), np.float64(12.964559632888212), np.float64(12.965109501801376), np.float64(12.965109501801376), np.float64(12.965109501801376), np.float64(13.084102811792306), np.float64(13.086670756594978), np.float64(13.088730876405974), np.float64(13.088730876405974), np.float64(13.088802067273349), np.float64(13.095436739962956), np.float64(13.141136725277434), np.float64(13.141136725277434), np.float64(13.21539419866377), np.float64(13.21539419866377), np.float64(13.21539419866377), np.float64(13.234381864263637), np.float64(13.234381864263637), np.float64(13.234381864263637), np.float64(13.241868981524426), np.float64(13.248121139962599), np.float64(13.253915168931334), np.float64(13.262220821578453), np.float64(13.301343146413345), np.float64(13.301343146413345), np.float64(13.303840563100742), np.float64(13.303840563100742), np.float64(13.303840563100742), np.float64(13.303840563100742), np.float64(13.303840563100742), np.float64(13.303840563100742), np.float64(13.303840563100742), np.float64(13.303840563100742), np.float64(13.303840563100742), np.float64(13.304121182926977), np.float64(13.30983583710439), np.float64(13.459311279951875), np.float64(13.460741911174253), np.float64(13.460741911174253), np.float64(13.462471595803134), np.float64(13.469180820801261), np.float64(13.469180820801261), np.float64(13.478589540445551), np.float64(13.481762064602067), np.float64(13.481762064602067), np.float64(13.494062627163718), np.float64(13.504777763763366), np.float64(13.51104384751248), np.float64(13.516126162578582), np.float64(13.516126162578582), np.float64(13.516126162578582), np.float64(13.516126162578582), np.float64(13.516126162578582), np.float64(13.516126162578582), np.float64(13.51979929705838), np.float64(13.51979929705838), np.float64(13.51979929705838), np.float64(13.51979929705838), np.float64(13.51979929705838), np.float64(13.8185509138345), np.float64(13.8185509138345), np.float64(13.8185509138345), np.float64(13.8185509138345), np.float64(13.839577870981582), np.float64(13.839577870981582), np.float64(13.839577870981582), np.float64(13.839577870981582), np.float64(13.839577870981582), np.float64(13.839577870981582), np.float64(13.839577870981582), np.float64(13.839577870981582), np.float64(13.839577870981582), np.float64(13.839577870981582), np.float64(13.839577870981582), np.float64(13.839577870981582), np.float64(13.841718185735491), np.float64(13.841718185735491), np.float64(13.841830113194707), np.float64(13.841830113194707), np.float64(13.842123884571768), np.float64(13.842123884571768), np.float64(13.842123884571768), np.float64(13.842410861674582), np.float64(13.842860170784936), np.float64(13.842860170784936), np.float64(13.842860170784936), np.float64(13.842860170784936), np.float64(13.842860170784936), np.float64(13.842860170784936), np.float64(13.84317021195476), np.float64(13.84317021195476), np.float64(13.84317021195476), np.float64(13.84317021195476), np.float64(13.84317021195476), np.float64(14.110122428136739), np.float64(14.110122428136739), np.float64(14.110122428136739), np.float64(14.110122428136739), np.float64(14.110122428136739), np.float64(14.110122428136739), np.float64(14.110122428136739), np.float64(14.110122428136739), np.float64(14.110122428136739)]\n",
      "Final Secrecy Rate GA: 14.110122428136739\n"
     ]
    }
   ],
   "source": [
    "population_size = 100\n",
    "num_generations = 200\n",
    "crossover_rate = 0.9\n",
    "mutation_rate = 0.3\n",
    "\n",
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# GA Algorithm\n",
    "GA_results = GA_optimize_w_theta(population_size, num_generations, crossover_rate, mutation_rate)\n",
    "print(\"Initial Secrecy Rate GA:\", GA_results[0])\n",
    "print(GA_results)\n",
    "print(\"Final Secrecy Rate GA:\", GA_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of PSO and GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO_GD(max_pso_iter, max_gd_iter, number_of_particles, learning_rate, w_max, w_min, c1, c2):\n",
    "    particles = [PSOParticle() for _ in range(number_of_particles)]\n",
    "    global_best_secrecy_rate = -np.inf\n",
    "    global_best_theta = np.zeros((1, Nris))\n",
    "    global_best_w = [np.zeros((N, 1)) for i in range(number_of_users)]\n",
    "\n",
    "    results_secrecy_rate = []\n",
    "\n",
    "    for particle in particles:\n",
    "        if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "            global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "            global_best_theta = deepcopy(particle.best_theta)\n",
    "            global_best_w = deepcopy(particle.best_w)\n",
    "\n",
    "    results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "    \n",
    "    for iteration in range(max_pso_iter):\n",
    "        print(\"iteration =\", iteration, \"Global Best Secrecy Rate:\", global_best_secrecy_rate)\n",
    "        inertia = dynamic_inertia(iteration, max_iter, w_max, w_min)\n",
    "\n",
    "        \"\"\"\n",
    "            Update particles theta by velocity\n",
    "        \"\"\"\n",
    "        for particle in particles:\n",
    "            particle.update_velocity(inertia, c1, c2, global_best_theta, global_best_w)\n",
    "            particle.update_position()\n",
    "            particle.update_best()\n",
    "            \n",
    "            if particle.best_secrecy_rate > global_best_secrecy_rate:\n",
    "                global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "                global_best_theta = deepcopy(particle.best_theta)\n",
    "                global_best_w = deepcopy(particle.best_w)\n",
    "        \n",
    "        # GD\n",
    "        for particle in particles:\n",
    "            for _ in range (max_gd_iter):\n",
    "                new_w, new_theta = gradient_descent_update(particle.w, theta_angles_to_theta_vector(particle.theta), learning_rate)\n",
    "                new_secrecy_rate = secrecy_rate_objective_function(new_theta, new_w)\n",
    "                if (new_secrecy_rate - particle.current_secrecy_rate) < 1e-9:\n",
    "                    break\n",
    "                \n",
    "                particle.w = new_w\n",
    "                particle.theta = theta_vector_to_theta_angles(new_theta)\n",
    "                particle.current_secrecy_rate = new_secrecy_rate\n",
    "\n",
    "            particle.update_best()\n",
    "            \n",
    "            if particle.best_secrecy_rate > global_best_secrecy_rate: \n",
    "                # No need to check validity as we already checked it in the inner loop\n",
    "                global_best_secrecy_rate = particle.best_secrecy_rate\n",
    "                global_best_theta = deepcopy(particle.best_theta)\n",
    "                global_best_w = deepcopy(particle.best_w)\n",
    "       \n",
    "        results_secrecy_rate.append(global_best_secrecy_rate)\n",
    "    return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0 Global Best Secrecy Rate: 8.664443500201392\n",
      "iteration = 1 Global Best Secrecy Rate: 12.17887653439416\n",
      "iteration = 2 Global Best Secrecy Rate: 12.17887653439416\n",
      "iteration = 3 Global Best Secrecy Rate: 12.32229568540885\n",
      "iteration = 4 Global Best Secrecy Rate: 12.79543589856743\n",
      "iteration = 5 Global Best Secrecy Rate: 12.79543589856743\n",
      "iteration = 6 Global Best Secrecy Rate: 13.243702005965075\n",
      "iteration = 7 Global Best Secrecy Rate: 13.656665676095649\n",
      "iteration = 8 Global Best Secrecy Rate: 13.80758956426458\n",
      "iteration = 9 Global Best Secrecy Rate: 14.184404682225367\n",
      "iteration = 10 Global Best Secrecy Rate: 14.79792806693585\n",
      "iteration = 11 Global Best Secrecy Rate: 15.879947227663894\n",
      "iteration = 12 Global Best Secrecy Rate: 15.926024222320866\n",
      "iteration = 13 Global Best Secrecy Rate: 16.16968129871003\n",
      "iteration = 14 Global Best Secrecy Rate: 16.43555143067271\n",
      "iteration = 15 Global Best Secrecy Rate: 16.642279415303815\n",
      "iteration = 16 Global Best Secrecy Rate: 16.65443909562719\n",
      "iteration = 17 Global Best Secrecy Rate: 16.893335537845445\n",
      "iteration = 18 Global Best Secrecy Rate: 16.929633633405675\n",
      "iteration = 19 Global Best Secrecy Rate: 16.929633633405675\n",
      "iteration = 20 Global Best Secrecy Rate: 16.929633633405675\n",
      "iteration = 21 Global Best Secrecy Rate: 16.929633633405675\n",
      "iteration = 22 Global Best Secrecy Rate: 16.929633633405675\n",
      "iteration = 23 Global Best Secrecy Rate: 16.929633633405675\n",
      "iteration = 24 Global Best Secrecy Rate: 16.933171991077177\n",
      "iteration = 25 Global Best Secrecy Rate: 17.02510285223651\n",
      "iteration = 26 Global Best Secrecy Rate: 17.02510285223651\n",
      "iteration = 27 Global Best Secrecy Rate: 17.04660689412141\n",
      "iteration = 28 Global Best Secrecy Rate: 17.07170398160646\n",
      "iteration = 29 Global Best Secrecy Rate: 17.164882663631914\n",
      "iteration = 30 Global Best Secrecy Rate: 17.183898488049792\n",
      "iteration = 31 Global Best Secrecy Rate: 17.23075676746876\n",
      "iteration = 32 Global Best Secrecy Rate: 17.29721135302767\n",
      "iteration = 33 Global Best Secrecy Rate: 17.29721135302767\n",
      "iteration = 34 Global Best Secrecy Rate: 17.395555019469818\n",
      "iteration = 35 Global Best Secrecy Rate: 17.395555019469818\n",
      "iteration = 36 Global Best Secrecy Rate: 17.39903397667807\n",
      "iteration = 37 Global Best Secrecy Rate: 17.39903397667807\n",
      "iteration = 38 Global Best Secrecy Rate: 17.39903397667807\n",
      "iteration = 39 Global Best Secrecy Rate: 17.406191396636295\n",
      "iteration = 40 Global Best Secrecy Rate: 17.432971859885704\n",
      "iteration = 41 Global Best Secrecy Rate: 17.435937700828593\n",
      "iteration = 42 Global Best Secrecy Rate: 17.435937700828593\n",
      "iteration = 43 Global Best Secrecy Rate: 17.446535492754126\n",
      "iteration = 44 Global Best Secrecy Rate: 17.487756633823594\n",
      "iteration = 45 Global Best Secrecy Rate: 17.487756633823594\n",
      "iteration = 46 Global Best Secrecy Rate: 17.48777981930192\n",
      "iteration = 47 Global Best Secrecy Rate: 17.48777981930192\n",
      "iteration = 48 Global Best Secrecy Rate: 17.48777981930192\n",
      "iteration = 49 Global Best Secrecy Rate: 17.496839509313652\n",
      "iteration = 50 Global Best Secrecy Rate: 17.51778810127867\n",
      "iteration = 51 Global Best Secrecy Rate: 17.51778810127867\n",
      "iteration = 52 Global Best Secrecy Rate: 17.51778810127867\n",
      "iteration = 53 Global Best Secrecy Rate: 17.61537955193308\n",
      "iteration = 54 Global Best Secrecy Rate: 17.61537955193308\n",
      "iteration = 55 Global Best Secrecy Rate: 17.660012877753328\n",
      "iteration = 56 Global Best Secrecy Rate: 17.660012877753328\n",
      "iteration = 57 Global Best Secrecy Rate: 17.660012877753328\n",
      "iteration = 58 Global Best Secrecy Rate: 17.660012877753328\n",
      "iteration = 59 Global Best Secrecy Rate: 17.660012877753328\n",
      "iteration = 60 Global Best Secrecy Rate: 17.660012877753328\n",
      "iteration = 61 Global Best Secrecy Rate: 17.660012877753328\n",
      "iteration = 62 Global Best Secrecy Rate: 17.660012877753328\n",
      "iteration = 63 Global Best Secrecy Rate: 17.663647359427056\n",
      "iteration = 64 Global Best Secrecy Rate: 17.663647359427056\n",
      "iteration = 65 Global Best Secrecy Rate: 17.663647359427056\n",
      "iteration = 66 Global Best Secrecy Rate: 17.663647359427056\n",
      "iteration = 67 Global Best Secrecy Rate: 17.663647359427056\n",
      "iteration = 68 Global Best Secrecy Rate: 17.663647359427056\n",
      "iteration = 69 Global Best Secrecy Rate: 17.663647359427056\n",
      "iteration = 70 Global Best Secrecy Rate: 17.665160601456037\n",
      "iteration = 71 Global Best Secrecy Rate: 17.665160601456037\n",
      "iteration = 72 Global Best Secrecy Rate: 17.665160601456037\n",
      "iteration = 73 Global Best Secrecy Rate: 17.665160601456037\n",
      "iteration = 74 Global Best Secrecy Rate: 17.76021287969983\n",
      "iteration = 75 Global Best Secrecy Rate: 17.76021287969983\n",
      "iteration = 76 Global Best Secrecy Rate: 17.76021287969983\n",
      "iteration = 77 Global Best Secrecy Rate: 17.771435296396852\n",
      "iteration = 78 Global Best Secrecy Rate: 17.771435296396852\n",
      "iteration = 79 Global Best Secrecy Rate: 17.77225631291958\n",
      "iteration = 80 Global Best Secrecy Rate: 17.77225631291958\n",
      "iteration = 81 Global Best Secrecy Rate: 17.77225631291958\n",
      "iteration = 82 Global Best Secrecy Rate: 17.77225631291958\n",
      "iteration = 83 Global Best Secrecy Rate: 17.77225631291958\n",
      "iteration = 84 Global Best Secrecy Rate: 17.77225631291958\n",
      "iteration = 85 Global Best Secrecy Rate: 17.77225631291958\n",
      "iteration = 86 Global Best Secrecy Rate: 17.77225631291958\n",
      "iteration = 87 Global Best Secrecy Rate: 17.77225631291958\n",
      "iteration = 88 Global Best Secrecy Rate: 17.80328380650578\n",
      "iteration = 89 Global Best Secrecy Rate: 17.80328380650578\n",
      "iteration = 90 Global Best Secrecy Rate: 17.80328380650578\n",
      "iteration = 91 Global Best Secrecy Rate: 17.80328380650578\n",
      "iteration = 92 Global Best Secrecy Rate: 17.80328380650578\n",
      "iteration = 93 Global Best Secrecy Rate: 17.826028195596344\n",
      "iteration = 94 Global Best Secrecy Rate: 17.863332379097972\n",
      "iteration = 95 Global Best Secrecy Rate: 17.863332379097972\n",
      "iteration = 96 Global Best Secrecy Rate: 17.863332379097972\n",
      "iteration = 97 Global Best Secrecy Rate: 17.877224310066662\n",
      "iteration = 98 Global Best Secrecy Rate: 17.877224310066662\n",
      "iteration = 99 Global Best Secrecy Rate: 17.877224310066662\n",
      "iteration = 100 Global Best Secrecy Rate: 17.877224310066662\n",
      "iteration = 101 Global Best Secrecy Rate: 17.877224310066662\n",
      "iteration = 102 Global Best Secrecy Rate: 17.877224310066662\n",
      "iteration = 103 Global Best Secrecy Rate: 17.877224310066662\n",
      "iteration = 104 Global Best Secrecy Rate: 17.877224310066662\n",
      "iteration = 105 Global Best Secrecy Rate: 17.877224310066662\n",
      "iteration = 106 Global Best Secrecy Rate: 18.002501930916253\n",
      "iteration = 107 Global Best Secrecy Rate: 18.002501930916253\n",
      "iteration = 108 Global Best Secrecy Rate: 18.002501930916253\n",
      "iteration = 109 Global Best Secrecy Rate: 18.002501930916253\n",
      "iteration = 110 Global Best Secrecy Rate: 18.04232388679048\n",
      "iteration = 111 Global Best Secrecy Rate: 18.04232388679048\n",
      "iteration = 112 Global Best Secrecy Rate: 18.04232388679048\n",
      "iteration = 113 Global Best Secrecy Rate: 18.04232388679048\n",
      "iteration = 114 Global Best Secrecy Rate: 18.04232388679048\n",
      "iteration = 115 Global Best Secrecy Rate: 18.04232388679048\n",
      "iteration = 116 Global Best Secrecy Rate: 18.04304510330147\n",
      "iteration = 117 Global Best Secrecy Rate: 18.04304510330147\n",
      "iteration = 118 Global Best Secrecy Rate: 18.082619339557766\n",
      "iteration = 119 Global Best Secrecy Rate: 18.101413323853112\n",
      "iteration = 120 Global Best Secrecy Rate: 18.101413323853112\n",
      "iteration = 121 Global Best Secrecy Rate: 18.101413323853112\n",
      "iteration = 122 Global Best Secrecy Rate: 18.101413323853112\n",
      "iteration = 123 Global Best Secrecy Rate: 18.101413323853112\n",
      "iteration = 124 Global Best Secrecy Rate: 18.101413323853112\n",
      "iteration = 125 Global Best Secrecy Rate: 18.101413323853112\n",
      "iteration = 126 Global Best Secrecy Rate: 18.101413323853112\n",
      "iteration = 127 Global Best Secrecy Rate: 18.101413323853112\n",
      "iteration = 128 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 129 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 130 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 131 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 132 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 133 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 134 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 135 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 136 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 137 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 138 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 139 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 140 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 141 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 142 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 143 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 144 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 145 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 146 Global Best Secrecy Rate: 18.1581045453836\n",
      "iteration = 147 Global Best Secrecy Rate: 18.169132245944112\n",
      "iteration = 148 Global Best Secrecy Rate: 18.169778321020722\n",
      "iteration = 149 Global Best Secrecy Rate: 18.182122152310626\n",
      "iteration = 150 Global Best Secrecy Rate: 18.29553666294503\n",
      "iteration = 151 Global Best Secrecy Rate: 18.29553666294503\n",
      "iteration = 152 Global Best Secrecy Rate: 18.29553666294503\n",
      "iteration = 153 Global Best Secrecy Rate: 18.29553666294503\n",
      "iteration = 154 Global Best Secrecy Rate: 18.310801453330974\n",
      "iteration = 155 Global Best Secrecy Rate: 18.310801453330974\n",
      "iteration = 156 Global Best Secrecy Rate: 18.399746579233536\n",
      "iteration = 157 Global Best Secrecy Rate: 18.53710940331176\n",
      "iteration = 158 Global Best Secrecy Rate: 18.580611634344205\n",
      "iteration = 159 Global Best Secrecy Rate: 18.580611634344205\n",
      "iteration = 160 Global Best Secrecy Rate: 18.580805866731946\n",
      "iteration = 161 Global Best Secrecy Rate: 18.580805866731946\n",
      "iteration = 162 Global Best Secrecy Rate: 18.59099165561102\n",
      "iteration = 163 Global Best Secrecy Rate: 18.59099165561102\n",
      "iteration = 164 Global Best Secrecy Rate: 18.599717844635165\n",
      "iteration = 165 Global Best Secrecy Rate: 18.599717844635165\n",
      "iteration = 166 Global Best Secrecy Rate: 18.599717844635165\n",
      "iteration = 167 Global Best Secrecy Rate: 18.599717844635165\n",
      "iteration = 168 Global Best Secrecy Rate: 18.599717844635165\n",
      "iteration = 169 Global Best Secrecy Rate: 18.604120123192196\n",
      "iteration = 170 Global Best Secrecy Rate: 18.604120123192196\n",
      "iteration = 171 Global Best Secrecy Rate: 18.604120123192196\n",
      "iteration = 172 Global Best Secrecy Rate: 18.604120123192196\n",
      "iteration = 173 Global Best Secrecy Rate: 18.67208211950127\n",
      "iteration = 174 Global Best Secrecy Rate: 18.67208211950127\n",
      "iteration = 175 Global Best Secrecy Rate: 18.7269393742312\n",
      "iteration = 176 Global Best Secrecy Rate: 18.7269393742312\n",
      "iteration = 177 Global Best Secrecy Rate: 18.7269393742312\n",
      "iteration = 178 Global Best Secrecy Rate: 18.7269393742312\n",
      "iteration = 179 Global Best Secrecy Rate: 18.732944708691978\n",
      "iteration = 180 Global Best Secrecy Rate: 18.732944708691978\n",
      "iteration = 181 Global Best Secrecy Rate: 18.82839302585994\n",
      "iteration = 182 Global Best Secrecy Rate: 18.82839302585994\n",
      "iteration = 183 Global Best Secrecy Rate: 18.82839302585994\n",
      "iteration = 184 Global Best Secrecy Rate: 18.82839302585994\n",
      "iteration = 185 Global Best Secrecy Rate: 18.82839302585994\n",
      "iteration = 186 Global Best Secrecy Rate: 18.82839302585994\n",
      "iteration = 187 Global Best Secrecy Rate: 18.918334569788705\n",
      "iteration = 188 Global Best Secrecy Rate: 18.9298810036848\n",
      "iteration = 189 Global Best Secrecy Rate: 18.973433223363546\n",
      "iteration = 190 Global Best Secrecy Rate: 19.09895524777518\n",
      "iteration = 191 Global Best Secrecy Rate: 19.11551178909478\n",
      "iteration = 192 Global Best Secrecy Rate: 19.11551178909478\n",
      "iteration = 193 Global Best Secrecy Rate: 19.11551178909478\n",
      "iteration = 194 Global Best Secrecy Rate: 19.141857042650173\n",
      "iteration = 195 Global Best Secrecy Rate: 19.141857042650173\n",
      "iteration = 196 Global Best Secrecy Rate: 19.141857042650173\n",
      "iteration = 197 Global Best Secrecy Rate: 19.18165625806146\n",
      "iteration = 198 Global Best Secrecy Rate: 19.18165625806146\n",
      "iteration = 199 Global Best Secrecy Rate: 19.184643776589915\n",
      "Initial Secrecy Rate PSO-GD: 8.664443500201392\n",
      "Final Secrecy Rate PSO-GD: 19.196966510926615\n"
     ]
    }
   ],
   "source": [
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "max_pso_iter = 200\n",
    "max_gd_iter = 50\n",
    "number_of_particles = 50\n",
    "w_max = 0.9\n",
    "w_min = 0.5\n",
    "c1 = 1.5\n",
    "c2 = 1.5\n",
    "\n",
    "PSO_GD_results = PSO_GD(max_pso_iter, max_gd_iter, number_of_particles, learning_rate, w_max, w_min, c1, c2)\n",
    "print(\"Initial Secrecy Rate PSO-GD:\", PSO_GD_results[0])\n",
    "print(\"Final Secrecy Rate PSO-GD:\", PSO_GD_results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination of GA and GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_GD_optimize_w_theta(population_size: int, max_iter: int, max_iter_gd: int, crossover_rate: float = 0.85, mutation_rate: float = 0.85):\n",
    "  population = GAPopulation(population_size, crossover_rate, mutation_rate)\n",
    "  population.sort_population()\n",
    "  results_secrecy_rate = []\n",
    "  results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "\n",
    "  for iteration in range(max_iter):\n",
    "    print(\"iteration =\", iteration)\n",
    "    print(\"Best secrecy rate:\", population.individuals[0].fitness)\n",
    "    # Crossover\n",
    "    for _ in range(population_size):\n",
    "      if np.random.rand() < population.crossover_rate:\n",
    "        parent1, parent2 = population.select_parents()\n",
    "        child = population.crossover(parent1, parent2)\n",
    "    #Mutate \n",
    "        population.mutate(child)\n",
    "        population.add_individual(child)\n",
    "\n",
    "\n",
    "    # GD\n",
    "    for individual in population.individuals:\n",
    "      for _ in range(max_iter_gd):\n",
    "        new_w, new_theta = gradient_descent_update(individual.w, theta_angles_to_theta_vector(individual.theta), learning_rate)\n",
    "        new_secrecy_rate = secrecy_rate_objective_function(new_theta, new_w)\n",
    "        if (new_secrecy_rate - individual.fitness) < 1e-9:\n",
    "          break\n",
    "        \n",
    "        individual.w = new_w\n",
    "        individual.theta = theta_vector_to_theta_angles(new_theta)\n",
    "        individual.update_fitness()\n",
    "\n",
    "      individual.theta, individual.w = repair(theta_angles_to_theta_vector(individual.theta), individual.w)\n",
    "      individual.theta = theta_vector_to_theta_angles(individual.theta)\n",
    "      individual.update_fitness()\n",
    "\n",
    "    # Filter\n",
    "    population.filter_population() \n",
    "\n",
    "    # Sort\n",
    "    population.sort_population()\n",
    "    \n",
    "    #print(f\"[Generation {iteration + 1}] Population before GD: {list(map(lambda x: x.fitness, population.individuals))}\")\n",
    "\n",
    "    print(\"Best secrecy rate:\", population.individuals[0].fitness)\n",
    "    results_secrecy_rate.append(population.individuals[0].fitness)\n",
    "\n",
    "  return results_secrecy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0\n",
      "Best secrecy rate: 8.664443500201392\n",
      "Best secrecy rate: 12.059064195910675\n",
      "iteration = 1\n",
      "Best secrecy rate: 12.059064195910675\n",
      "Best secrecy rate: 12.619843571350259\n",
      "iteration = 2\n",
      "Best secrecy rate: 12.619843571350259\n",
      "Best secrecy rate: 13.220095682605065\n",
      "iteration = 3\n",
      "Best secrecy rate: 13.220095682605065\n",
      "Best secrecy rate: 13.594626239881602\n",
      "iteration = 4\n",
      "Best secrecy rate: 13.594626239881602\n",
      "Best secrecy rate: 13.718158952796275\n",
      "iteration = 5\n",
      "Best secrecy rate: 13.718158952796275\n",
      "Best secrecy rate: 14.064934797819307\n",
      "iteration = 6\n",
      "Best secrecy rate: 14.064934797819307\n",
      "Best secrecy rate: 14.06639865714974\n",
      "iteration = 7\n",
      "Best secrecy rate: 14.06639865714974\n",
      "Best secrecy rate: 14.064934797819307\n",
      "iteration = 8\n",
      "Best secrecy rate: 14.064934797819307\n",
      "Best secrecy rate: 14.064934797819307\n",
      "iteration = 9\n",
      "Best secrecy rate: 14.064934797819307\n",
      "Best secrecy rate: 14.173885691516483\n",
      "iteration = 10\n",
      "Best secrecy rate: 14.173885691516483\n",
      "Best secrecy rate: 14.173902225969815\n",
      "iteration = 11\n",
      "Best secrecy rate: 14.173902225969815\n",
      "Best secrecy rate: 14.41169912155339\n",
      "iteration = 12\n",
      "Best secrecy rate: 14.41169912155339\n",
      "Best secrecy rate: 14.51083157129954\n",
      "iteration = 13\n",
      "Best secrecy rate: 14.51083157129954\n",
      "Best secrecy rate: 14.59075023751646\n",
      "iteration = 14\n",
      "Best secrecy rate: 14.59075023751646\n",
      "Best secrecy rate: 14.68491780083069\n",
      "iteration = 15\n",
      "Best secrecy rate: 14.68491780083069\n",
      "Best secrecy rate: 14.542109558577897\n",
      "iteration = 16\n",
      "Best secrecy rate: 14.542109558577897\n",
      "Best secrecy rate: 14.542109558577897\n",
      "iteration = 17\n",
      "Best secrecy rate: 14.542109558577897\n",
      "Best secrecy rate: 14.542109558577897\n",
      "iteration = 18\n",
      "Best secrecy rate: 14.542109558577897\n",
      "Best secrecy rate: 14.542109558577897\n",
      "iteration = 19\n",
      "Best secrecy rate: 14.542109558577897\n",
      "Best secrecy rate: 14.595768217624187\n",
      "iteration = 20\n",
      "Best secrecy rate: 14.595768217624187\n",
      "Best secrecy rate: 14.542109558577897\n",
      "iteration = 21\n",
      "Best secrecy rate: 14.542109558577897\n",
      "Best secrecy rate: 14.542109558577897\n",
      "iteration = 22\n",
      "Best secrecy rate: 14.542109558577897\n",
      "Best secrecy rate: 14.542109558577897\n",
      "iteration = 23\n",
      "Best secrecy rate: 14.542109558577897\n",
      "Best secrecy rate: 14.60114044575083\n",
      "iteration = 24\n",
      "Best secrecy rate: 14.60114044575083\n",
      "Best secrecy rate: 14.557564588546295\n",
      "iteration = 25\n",
      "Best secrecy rate: 14.557564588546295\n",
      "Best secrecy rate: 14.626575126567843\n",
      "iteration = 26\n",
      "Best secrecy rate: 14.626575126567843\n",
      "Best secrecy rate: 14.665989511217802\n",
      "iteration = 27\n",
      "Best secrecy rate: 14.665989511217802\n",
      "Best secrecy rate: 14.588463590619844\n",
      "iteration = 28\n",
      "Best secrecy rate: 14.588463590619844\n",
      "Best secrecy rate: 14.588463590619844\n",
      "iteration = 29\n",
      "Best secrecy rate: 14.588463590619844\n",
      "Best secrecy rate: 14.588463590619844\n",
      "iteration = 30\n",
      "Best secrecy rate: 14.588463590619844\n",
      "Best secrecy rate: 14.807641928985053\n",
      "iteration = 31\n",
      "Best secrecy rate: 14.807641928985053\n",
      "Best secrecy rate: 14.63741103446087\n",
      "iteration = 32\n",
      "Best secrecy rate: 14.63741103446087\n",
      "Best secrecy rate: 14.59073970129223\n",
      "iteration = 33\n",
      "Best secrecy rate: 14.59073970129223\n",
      "Best secrecy rate: 14.59073970129223\n",
      "iteration = 34\n",
      "Best secrecy rate: 14.59073970129223\n",
      "Best secrecy rate: 14.592140151091515\n",
      "iteration = 35\n",
      "Best secrecy rate: 14.592140151091515\n",
      "Best secrecy rate: 14.592140151091515\n",
      "iteration = 36\n",
      "Best secrecy rate: 14.592140151091515\n",
      "Best secrecy rate: 14.592140151091515\n",
      "iteration = 37\n",
      "Best secrecy rate: 14.592140151091515\n",
      "Best secrecy rate: 14.59588053854782\n",
      "iteration = 38\n",
      "Best secrecy rate: 14.59588053854782\n",
      "Best secrecy rate: 14.59588053854782\n",
      "iteration = 39\n",
      "Best secrecy rate: 14.59588053854782\n",
      "Best secrecy rate: 14.59679333788159\n",
      "iteration = 40\n",
      "Best secrecy rate: 14.59679333788159\n",
      "Best secrecy rate: 14.634757390433043\n",
      "iteration = 41\n",
      "Best secrecy rate: 14.634757390433043\n",
      "Best secrecy rate: 14.634757390433043\n",
      "iteration = 42\n",
      "Best secrecy rate: 14.634757390433043\n",
      "Best secrecy rate: 14.636217377242884\n",
      "iteration = 43\n",
      "Best secrecy rate: 14.636217377242884\n",
      "Best secrecy rate: 14.639090385848103\n",
      "iteration = 44\n",
      "Best secrecy rate: 14.639090385848103\n",
      "Best secrecy rate: 14.639090385848103\n",
      "iteration = 45\n",
      "Best secrecy rate: 14.639090385848103\n",
      "Best secrecy rate: 14.639090385848103\n",
      "iteration = 46\n",
      "Best secrecy rate: 14.639090385848103\n",
      "Best secrecy rate: 14.739869179913377\n",
      "iteration = 47\n",
      "Best secrecy rate: 14.739869179913377\n",
      "Best secrecy rate: 14.763283381842434\n",
      "iteration = 48\n",
      "Best secrecy rate: 14.763283381842434\n",
      "Best secrecy rate: 14.763283381842434\n",
      "iteration = 49\n",
      "Best secrecy rate: 14.763283381842434\n",
      "Best secrecy rate: 14.763283381842434\n",
      "iteration = 50\n",
      "Best secrecy rate: 14.763283381842434\n",
      "Best secrecy rate: 14.763283381842434\n",
      "iteration = 51\n",
      "Best secrecy rate: 14.763283381842434\n",
      "Best secrecy rate: 14.763283381842434\n",
      "iteration = 52\n",
      "Best secrecy rate: 14.763283381842434\n",
      "Best secrecy rate: 14.763283381842434\n",
      "iteration = 53\n",
      "Best secrecy rate: 14.763283381842434\n",
      "Best secrecy rate: 14.763283381842434\n",
      "iteration = 54\n",
      "Best secrecy rate: 14.763283381842434\n",
      "Best secrecy rate: 14.884340084913202\n",
      "iteration = 55\n",
      "Best secrecy rate: 14.884340084913202\n",
      "Best secrecy rate: 14.763283381842434\n",
      "iteration = 56\n",
      "Best secrecy rate: 14.763283381842434\n",
      "Best secrecy rate: 14.763283381842434\n",
      "iteration = 57\n",
      "Best secrecy rate: 14.763283381842434\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 58\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 59\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 60\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 61\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 62\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 63\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 64\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 65\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 66\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 67\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 68\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 69\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 70\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 71\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 72\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 73\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 74\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 75\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 76\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 77\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 78\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 79\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 80\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 81\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 82\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 83\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.856336355785091\n",
      "iteration = 84\n",
      "Best secrecy rate: 14.856336355785091\n",
      "Best secrecy rate: 14.859459516344884\n",
      "iteration = 85\n",
      "Best secrecy rate: 14.859459516344884\n",
      "Best secrecy rate: 14.859588604738388\n",
      "iteration = 86\n",
      "Best secrecy rate: 14.859588604738388\n",
      "Best secrecy rate: 14.860800753622568\n",
      "iteration = 87\n",
      "Best secrecy rate: 14.860800753622568\n",
      "Best secrecy rate: 14.867241976828419\n",
      "iteration = 88\n",
      "Best secrecy rate: 14.867241976828419\n",
      "Best secrecy rate: 14.869440204778252\n",
      "iteration = 89\n",
      "Best secrecy rate: 14.869440204778252\n",
      "Best secrecy rate: 14.87027072241737\n",
      "iteration = 90\n",
      "Best secrecy rate: 14.87027072241737\n",
      "Best secrecy rate: 14.870702497032624\n",
      "iteration = 91\n",
      "Best secrecy rate: 14.870702497032624\n",
      "Best secrecy rate: 14.874535115429296\n",
      "iteration = 92\n",
      "Best secrecy rate: 14.874535115429296\n",
      "Best secrecy rate: 14.878908088296987\n",
      "iteration = 93\n",
      "Best secrecy rate: 14.878908088296987\n",
      "Best secrecy rate: 14.880424364976268\n",
      "iteration = 94\n",
      "Best secrecy rate: 14.880424364976268\n",
      "Best secrecy rate: 14.880424364976268\n",
      "iteration = 95\n",
      "Best secrecy rate: 14.880424364976268\n",
      "Best secrecy rate: 14.881701060697301\n",
      "iteration = 96\n",
      "Best secrecy rate: 14.881701060697301\n",
      "Best secrecy rate: 14.881701060697301\n",
      "iteration = 97\n",
      "Best secrecy rate: 14.881701060697301\n",
      "Best secrecy rate: 14.881701060697301\n",
      "iteration = 98\n",
      "Best secrecy rate: 14.881701060697301\n",
      "Best secrecy rate: 14.884324256659923\n",
      "iteration = 99\n",
      "Best secrecy rate: 14.884324256659923\n",
      "Best secrecy rate: 14.884324256659923\n",
      "iteration = 100\n",
      "Best secrecy rate: 14.884324256659923\n",
      "Best secrecy rate: 14.885521223385966\n",
      "iteration = 101\n",
      "Best secrecy rate: 14.885521223385966\n",
      "Best secrecy rate: 14.886092553960006\n",
      "iteration = 102\n",
      "Best secrecy rate: 14.886092553960006\n",
      "Best secrecy rate: 14.886669143389009\n",
      "iteration = 103\n",
      "Best secrecy rate: 14.886669143389009\n",
      "Best secrecy rate: 14.886669143389009\n",
      "iteration = 104\n",
      "Best secrecy rate: 14.886669143389009\n",
      "Best secrecy rate: 14.88700438552472\n",
      "iteration = 105\n",
      "Best secrecy rate: 14.88700438552472\n",
      "Best secrecy rate: 14.887175890188772\n",
      "iteration = 106\n",
      "Best secrecy rate: 14.887175890188772\n",
      "Best secrecy rate: 14.897078305142045\n",
      "iteration = 107\n",
      "Best secrecy rate: 14.897078305142045\n",
      "Best secrecy rate: 14.897078305142045\n",
      "iteration = 108\n",
      "Best secrecy rate: 14.897078305142045\n",
      "Best secrecy rate: 14.897078305142045\n",
      "iteration = 109\n",
      "Best secrecy rate: 14.897078305142045\n",
      "Best secrecy rate: 14.897078305142045\n",
      "iteration = 110\n",
      "Best secrecy rate: 14.897078305142045\n",
      "Best secrecy rate: 14.897078305142045\n",
      "iteration = 111\n",
      "Best secrecy rate: 14.897078305142045\n",
      "Best secrecy rate: 14.897078305142045\n",
      "iteration = 112\n",
      "Best secrecy rate: 14.897078305142045\n",
      "Best secrecy rate: 14.897078305142045\n",
      "iteration = 113\n",
      "Best secrecy rate: 14.897078305142045\n",
      "Best secrecy rate: 14.897078305142045\n",
      "iteration = 114\n",
      "Best secrecy rate: 14.897078305142045\n",
      "Best secrecy rate: 14.897078305142045\n",
      "iteration = 115\n",
      "Best secrecy rate: 14.897078305142045\n",
      "Best secrecy rate: 14.91674794669532\n",
      "iteration = 116\n",
      "Best secrecy rate: 14.91674794669532\n",
      "Best secrecy rate: 14.91674794669532\n",
      "iteration = 117\n",
      "Best secrecy rate: 14.91674794669532\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 118\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 119\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 120\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 121\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 122\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 123\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 124\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 125\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 126\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 127\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 128\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 129\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 130\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 131\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 132\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.966255283428751\n",
      "iteration = 133\n",
      "Best secrecy rate: 14.966255283428751\n",
      "Best secrecy rate: 14.982500319615259\n",
      "iteration = 134\n",
      "Best secrecy rate: 14.982500319615259\n",
      "Best secrecy rate: 14.98257106571175\n",
      "iteration = 135\n",
      "Best secrecy rate: 14.98257106571175\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 136\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 137\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 138\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 139\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 140\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 141\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 142\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 143\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 144\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 145\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 146\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 147\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 148\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 149\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 150\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 151\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 152\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 153\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 154\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 155\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 156\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 157\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 158\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 159\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 160\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 161\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 162\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 163\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 164\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 165\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 166\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 167\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 168\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 169\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 170\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 14.982909148559374\n",
      "iteration = 171\n",
      "Best secrecy rate: 14.982909148559374\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 172\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 173\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 174\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 175\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 176\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 177\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 178\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 179\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 180\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 181\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 182\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 183\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 184\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 185\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 186\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 187\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 188\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 189\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 190\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 191\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 192\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 193\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 194\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 195\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 196\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 197\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 198\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "iteration = 199\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Best secrecy rate: 15.0237604487949\n",
      "Initial Secrecy Rate GA-GD: 8.664443500201392\n",
      "[np.float64(8.664443500201392), np.float64(12.059064195910675), np.float64(12.619843571350259), np.float64(13.220095682605065), np.float64(13.594626239881602), np.float64(13.718158952796275), np.float64(14.064934797819307), np.float64(14.06639865714974), np.float64(14.064934797819307), np.float64(14.064934797819307), np.float64(14.173885691516483), np.float64(14.173902225969815), np.float64(14.41169912155339), np.float64(14.51083157129954), np.float64(14.59075023751646), np.float64(14.68491780083069), np.float64(14.542109558577897), np.float64(14.542109558577897), np.float64(14.542109558577897), np.float64(14.542109558577897), np.float64(14.595768217624187), np.float64(14.542109558577897), np.float64(14.542109558577897), np.float64(14.542109558577897), np.float64(14.60114044575083), np.float64(14.557564588546295), np.float64(14.626575126567843), np.float64(14.665989511217802), np.float64(14.588463590619844), np.float64(14.588463590619844), np.float64(14.588463590619844), np.float64(14.807641928985053), np.float64(14.63741103446087), np.float64(14.59073970129223), np.float64(14.59073970129223), np.float64(14.592140151091515), np.float64(14.592140151091515), np.float64(14.592140151091515), np.float64(14.59588053854782), np.float64(14.59588053854782), np.float64(14.59679333788159), np.float64(14.634757390433043), np.float64(14.634757390433043), np.float64(14.636217377242884), np.float64(14.639090385848103), np.float64(14.639090385848103), np.float64(14.639090385848103), np.float64(14.739869179913377), np.float64(14.763283381842434), np.float64(14.763283381842434), np.float64(14.763283381842434), np.float64(14.763283381842434), np.float64(14.763283381842434), np.float64(14.763283381842434), np.float64(14.763283381842434), np.float64(14.884340084913202), np.float64(14.763283381842434), np.float64(14.763283381842434), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.856336355785091), np.float64(14.859459516344884), np.float64(14.859588604738388), np.float64(14.860800753622568), np.float64(14.867241976828419), np.float64(14.869440204778252), np.float64(14.87027072241737), np.float64(14.870702497032624), np.float64(14.874535115429296), np.float64(14.878908088296987), np.float64(14.880424364976268), np.float64(14.880424364976268), np.float64(14.881701060697301), np.float64(14.881701060697301), np.float64(14.881701060697301), np.float64(14.884324256659923), np.float64(14.884324256659923), np.float64(14.885521223385966), np.float64(14.886092553960006), np.float64(14.886669143389009), np.float64(14.886669143389009), np.float64(14.88700438552472), np.float64(14.887175890188772), np.float64(14.897078305142045), np.float64(14.897078305142045), np.float64(14.897078305142045), np.float64(14.897078305142045), np.float64(14.897078305142045), np.float64(14.897078305142045), np.float64(14.897078305142045), np.float64(14.897078305142045), np.float64(14.897078305142045), np.float64(14.91674794669532), np.float64(14.91674794669532), np.float64(14.966255283428751), np.float64(14.966255283428751), np.float64(14.966255283428751), np.float64(14.966255283428751), np.float64(14.966255283428751), np.float64(14.966255283428751), np.float64(14.966255283428751), np.float64(14.966255283428751), np.float64(14.966255283428751), np.float64(14.966255283428751), np.float64(14.966255283428751), np.float64(14.966255283428751), np.float64(14.966255283428751), np.float64(14.966255283428751), np.float64(14.966255283428751), np.float64(14.966255283428751), np.float64(14.982500319615259), np.float64(14.98257106571175), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(14.982909148559374), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949), np.float64(15.0237604487949)]\n",
      "Final Secrecy Rate GA-GD: 15.0237604487949\n"
     ]
    }
   ],
   "source": [
    "# Reseed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# GA-GD\n",
    "population_size = 50\n",
    "num_generations = 200\n",
    "num_iter_gd = 50\n",
    "crossover_rate = 0.9\n",
    "mutation_rate = 0.3\n",
    "learning_rate = 0.01\n",
    "\n",
    "GA_GD_results = GA_GD_optimize_w_theta(population_size, num_generations, num_iter_gd, crossover_rate, mutation_rate)\n",
    "print(\"Initial Secrecy Rate GA-GD:\", GA_GD_results[0])\n",
    "print(GA_GD_results)\n",
    "print(\"Final Secrecy Rate GA-GD:\", GA_GD_results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PSO_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Extend the results to the same length\u001b[39;00m\n\u001b[0;32m      5\u001b[0m GD_results_draw \u001b[38;5;241m=\u001b[39m GD_results[:\u001b[38;5;241m200\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m PSO_results_draw \u001b[38;5;241m=\u001b[39m \u001b[43mPSO_results\u001b[49m[:\u001b[38;5;241m200\u001b[39m]\n\u001b[0;32m      7\u001b[0m GA_results_draw \u001b[38;5;241m=\u001b[39m GA_results[:\u001b[38;5;241m200\u001b[39m]\n\u001b[0;32m      8\u001b[0m PSO_GD_results_draw \u001b[38;5;241m=\u001b[39m PSO_GD_results[:\u001b[38;5;241m200\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PSO_results' is not defined"
     ]
    }
   ],
   "source": [
    "# iterations = range(0, num_cycles+10, 10)\n",
    "\n",
    "iterations = range(0, 200)\n",
    "# Extend the results to the same length\n",
    "GD_results_draw = GD_results[:200]\n",
    "PSO_results_draw = PSO_results[:200]\n",
    "GA_results_draw = GA_results[:200]\n",
    "PSO_GD_results_draw = PSO_GD_results[:200]\n",
    "GA_GD_results_draw = GA_GD_results[:200]\n",
    "\n",
    "\n",
    "#plt.plot(iterations, GD_results_draw, label='Gradient Descent')\n",
    "plt.plot(iterations, PSO_results_draw, label='PSO')\n",
    "plt.plot(iterations, GA_results_draw, label='Genetic Algorithm')\n",
    "plt.plot(iterations, PSO_GD_results_draw, label='PSO-GD')\n",
    "plt.plot(iterations, GA_GD_results_draw, label='GA-GD')\n",
    "\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Secrecy rate (bps/Hz)')\n",
    "plt.title('gamma =' + str(gamma))\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Secrecy Rate GD: 12.519599943492928\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PSO_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Best results of each methods\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Secrecy Rate GD:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mmax\u001b[39m(GD_results))\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Secrecy Rate PSO:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mmax\u001b[39m(\u001b[43mPSO_results\u001b[49m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Secrecy Rate GA:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mmax\u001b[39m(GA_results))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Secrecy Rate PSO-GD:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mmax\u001b[39m(PSO_GD_results))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PSO_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Best results of each methods\n",
    "print(\"Best Secrecy Rate GD:\", max(GD_results))\n",
    "print(\"Best Secrecy Rate PSO:\", max(PSO_results))\n",
    "print(\"Best Secrecy Rate GA:\", max(GA_results))\n",
    "print(\"Best Secrecy Rate PSO-GD:\", max(PSO_GD_results))\n",
    "print(\"Best Secrecy Rate GA-GD:\", max(GA_GD_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('results') == False:\n",
    "    os.mkdir('results')\n",
    "os.chdir('results')\n",
    "if os.path.exists('general') == False:\n",
    "    os.mkdir('general')\n",
    "os.chdir('general')\n",
    "times = RANDOM_SEED\n",
    "if os.path.exists(f'{times}_run') == False:\n",
    "    os.mkdir(f'{times}_run')\n",
    "    os.chdir(f'{times}_run')\n",
    "    np.save('GD_results', GD_results)\n",
    "    np.save('PSO_results', PSO_results)\n",
    "    np.save('GA_results', GA_results)\n",
    "    np.save('PSO_GD_results', PSO_GD_results)\n",
    "    np.save('GA_GD_results', GA_GD_results)\n",
    "    os.chdir('../')\n",
    "os.chdir('../../')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
